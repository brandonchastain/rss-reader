<?xml version="1.0" encoding="UTF-8"?>
<rss
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"
	xmlns:media="http://search.yahoo.com/mrss/">
	<channel>
		<title>
			<![CDATA[Ed Zitron's Where's Your Ed At]]>
		</title>
		<description>
			<![CDATA[The Words of Ed Zitron, a PR person and writer.]]>
		</description>
		<link>https://www.wheresyoured.at/</link>
		<image>
			<url>https://www.wheresyoured.at/favicon.png</url>
			<title>Ed Zitron&apos;s Where&apos;s Your Ed At</title>
			<link>https://www.wheresyoured.at/</link>
		</image>
		<generator>Ghost 6.0</generator>
		<lastBuildDate>Sat, 09 Aug 2025 03:15:06 GMT</lastBuildDate>
		<atom:link href="https://www.wheresyoured.at/rss/" rel="self" type="application/rss+xml"/>
		<ttl>60</ttl>
		<item>
			<title>
				<![CDATA[The Enshittification of Generative AI]]>
			</title>
			<description>
				<![CDATA[<p><em>Thanks for subscribing to Where&#x2019;s Your Ed At Premium, please shoot me an email at </em><a href="mailto:ez@betteroffline.com"><em><u>ez@betteroffline.com</u></em></a><em> if you ever have any questions.</em></p><p>Yesterday, <a href="https://www.wired.com/story/openais-gpt-5-is-here/?ref=wheresyoured.at"><u>OpenAI launched GPT-5</u></a>, a new &#x201C;flagship&#x201D; model of some sort that&#x2019;s allegedly better at coding and writing, but upon</p>]]>
			</description>
			<link>https://www.wheresyoured.at/the-enshittification-of-generative-ai/</link>
			<guid isPermaLink="false">689624ebd76da90001b81591</guid>
			<dc:creator>
				<![CDATA[Edward Zitron]]>
			</dc:creator>
			<pubDate>Fri, 08 Aug 2025 17:02:20 GMT</pubDate>
			<content:encoded>
				<![CDATA[<p><em>Thanks for subscribing to Where&#x2019;s Your Ed At Premium, please shoot me an email at </em><a href="mailto:ez@betteroffline.com"><em><u>ez@betteroffline.com</u></em></a><em> if you ever have any questions.</em></p><p>Yesterday, <a href="https://www.wired.com/story/openais-gpt-5-is-here/?ref=wheresyoured.at"><u>OpenAI launched GPT-5</u></a>, a new &#x201C;flagship&#x201D; model of some sort that&#x2019;s allegedly better at coding and writing, but upon closer inspection it feels like the same old shit it&#x2019;s been shoveling for the last year or two.&#xA0;</p><p>Sure, I&#x2019;m being dismissive, but three years and<a href="https://www.wsj.com/tech/ai/openai-gpt5-orion-delays-639e7693?ref=wheresyoured.at"><u> multiple half-billion-dollar training runs later</u></a>, OpenAI has delivered us a model that is some indeterminate level of &#x201C;better&#x201D; <a href="https://www.tomsguide.com/ai/openais-ceo-sam-altman-says-gpt-5-is-so-fast-it-actually-scares-him-maybe-its-great-maybe-its-bad-but-what-have-we-done?ref=wheresyoured.at"><u>that &#x201C;scared&#x201D; Sam Altman</u></a>, and immediately began doing what some Twitter users called &#x201C;<a href="https://x.com/kylecompute/status/1953503491701252419?ref=wheresyoured.at"><u>chart crimes</u></a>&#x201D; with its supposed coding benchmark charts.&#xA0;</p><p>This also begs the question: what <em>is</em> GPT-5? WIRED calls it a &#x201C;flagship language model,&#x201D; but <a href="https://openai.com/index/introducing-gpt-5/?ref=wheresyoured.at"><u>OpenAI </u></a>itself calls it a &#x201C;unified system with a smart, efficient model that answers most questions, a deeper reasoning model, and a real-time router that quickly decides which[model]&#xA0; to use based on conversation type, complexity, tool needs, and your explicit intent.&#x201D; That sure sounds like two models to me, and not necessarily new ones! Altman, <a href="https://x.com/sama/status/1889755723078443244?lang=en&amp;ref=wheresyoured.at"><u>back in February</u></a>, said that GPT-5 was &#x201C;a system that integrates a lot of our technology, including o3.&#x201D;</p><p>It is a little unclear what GPT-5 &#x2014; or at least the one accessed through ChatGPT &#x2014; <em>is. </em><a href="https://simonwillison.net/2025/Aug/7/gpt-5/?ref=wheresyoured.at"><u>According to Simon Willison</u></a>, there&#x2019;s three sub-models &#x2014; a regular, mini and a nano model, &#x201C;which can each be run at one of four reasoning levels&#x201D; if you configure them using the API.</p><p>When it comes to what you access on ChatGPT, however, you&#x2019;ve got two options &#x2014; GPT-5 and GPT-5-Thinking, with the entire previous generation of GPT models no longer available for most users to access.</p><p>I believe GPT-5 is part of a larger process happening in generative AI &#x2014; <a href="https://en.wikipedia.org/wiki/Enshittification?ref=wheresyoured.at"><u>enshittification</u></a>, Cory Doctorow&#x2019;s term for when platforms start out burning money offering an unlimited, unguarded experience to attract their users, then degrade and move features to higher tiers as a means of draining the blood from users.&#xA0;</p><p>With the launch of GPT-5, OpenAI has fully committed to enshittifying its consumer and business subscription products, arbitrarily moving free users to a cheaper model and limiting their ability to generate images, and removing the ability to choose which model you use in its $20, $35 and &#x201C;enterprise&#x201D; subscriptions, moving any and all choice to its &#x201C;team&#x201D; and $200-a-month &#x201C;pro&#x201D; subscriptions.&#xA0;</p><p><a href="https://openai.com/index/introducing-gpt-5/?ref=wheresyoured.at"><u>OpenAI&#x2019;s justification is an exercise in faux-altruism</u></a>, framing &#x201C;taking away all choice&#x201D; as a &#x201C;real-time router that quickly decides which [model] to use.&#x201D; ChatGPT Plus and Team members now mostly have access to two models &#x2014; GPT-5 and GPT-5-Thinking &#x2014; down from the six they had before.&#xA0;</p><p>This distinction is quite significant. Where users once could get hundreds of messages a day on OpenAI&#x2019;s o4-mini-high and o4-mini reasoning models, GPT-5 for ChatGPT Plus subscribers offers 200 reasoning (GPT-5-thinking) messages a <em>week</em>, with 80 GPT-5 messages every 3 hours which allow you to ask it to &#x201C;think&#x201D; about its answer, shoving you over to an undisclosed reasoning model. This may seem like a good deal, OpenAI is likely putting you on the cheapest model whenever it can in the name of &#x201C;the best choice.&#x201D;</p><p>While Team accounts have &#x201C;unlimited&#x201D; access to GPT-5, they still face the same <a href="https://help.openai.com/en/articles/11909943-gpt-5-in-chatgpt?ref=wheresyoured.at#:~:text=you%E2%80%99re%20on%20Plus-,or%20Team,-%2C%20you%20can%20also"><u>200-reasoning-messages-a-week limit</u></a>, and while yes, you could ask it to &#x201C;think&#x201D; more, do you think that OpenAI is going to give you their best reasoning models? Or will they, as they said, &#x201C;bring together the best of their previous models&#x201D; and &#x201C;choose the right one for the job&#x201D;?</p><p>Furthermore, <a href="https://help.openai.com/en/articles/11481834-chatgpt-rate-card?ref=wheresyoured.at"><u>OpenAI is permanently sunsetting ChatGPT access to every model that doesn&#x2019;t start with GPT-5 on August 14th</u></a> except for customers of its most expensive subscription tier. OpenAI will (and it appears this applies to the $200-a-month &quot;Pro&quot; plan too, I&apos;m told by <a href="https://joannastern.beehiiv.com/?ref=wheresyoured.at" rel="noreferrer">reporter Joanna Stern</a>)- reduce your model options to two or three choices (Chat, Thinking and Pro), and will choose whatever sub-model it sees fit in the most opaque way possible. GPT-5 is, by definition, a &#x201C;trust me bro&#x201D; product.&#xA0;</p><p>OpenAI is trying to reduce the burden of any particular user on the system under the guise of providing the &#x201C;smartest, fastest model,&#x201D; with &#x201C;smartest&#x201D; defined internally in a way that benefits the company, marketed as &#x201C;choosing the best model for the job.&#x201D;&#xA0; 	</p><p>Let&apos;s see how users feel! <a href="https://www.reddit.com/r/BetterOffline/comments/1mkmqwn/comment/n7jwvz3/?ref=wheresyoured.at" rel="noreferrer">An intrepid Better Offline listener pulled together some snippets from r/ChatGPT</a>, where users are <a href="https://www.reddit.com/r/ChatGPT/comments/1mkhhpk/can_we_all_just_agree_4o_was_the_best_weve_ever/?utm_source=share&amp;utm_medium=web3x&amp;utm_name=web3xcss&amp;utm_term=1&amp;utm_content=share_button" rel="noreferrer">mourning the loss of GPT-4o</a>, <a href="https://www.reddit.com/r/ChatGPT/comments/1mkbpsp/where_are_the_other_models/?ref=wheresyoured.at" rel="noreferrer">furious at the loss of other models</a> and calling GPT-5, in one case, &quot;<a href="https://www.reddit.com/r/ChatGPT/comments/1mkuj81/gpt5_is_the_biggest_peice_of_garbage_even_as_a/?ref=wheresyoured.at" rel="noreferrer">the biggest peice (sic) of garbage even as a paid user</a>,&quot; who says that &quot;projects are absolutely brain-dead now.&quot; One user said that GPT-5 is &quot;<a href="https://www.reddit.com/r/ChatGPT/comments/1mkobei/openai_just_pulled_the_biggest_baitandswitch_in/?utm_source=share&amp;utm_medium=web3x&amp;utm_name=web3xcss&amp;utm_term=1&amp;utm_content=share_button" rel="noreferrer">the biggest bait-and-switch in AI history</a>,&quot; another said that OpenAI &quot;<a href="https://www.reddit.com/r/ChatGPT/comments/1mkm68y/deleted_my_subscription_after_two_years_openai/?utm_source=share&amp;utm_medium=web3x&amp;utm_name=web3xcss&amp;utm_term=1&amp;utm_content=share_button" rel="noreferrer">deleted a workfow of 8 models overnight, with no prior warning</a>,&quot; and another said that &quot;<a href="https://www.reddit.com/r/ChatGPT/comments/1mkt8hv/chatgpt_5_is_the_worst_model_ever_feeling_really/?utm_source=share&amp;utm_medium=web3x&amp;utm_name=web3xcss&amp;utm_term=1&amp;utm_content=share_button" rel="noreferrer">ChatGPT 5 is the worst model ever</a>.&quot; In fact, <a href="https://www.reddit.com/r/ChatGPT/comments/1mkhfep/all_i_wanted_was_an_option_to_keep_4o/?utm_source=share&amp;utm_medium=web3x&amp;utm_name=web3xcss&amp;utm_term=1&amp;utm_content=share_button" rel="noreferrer">there</a><a href="https://www.reddit.com/r/ChatGPT/comments/1mkiwvt/glad_im_not_the_only_one/?utm_source=share&amp;utm_medium=web3x&amp;utm_name=web3xcss&amp;utm_term=1&amp;utm_content=share_button" rel="noreferrer">are</a><a href="https://www.reddit.com/r/ChatGPT/comments/1mkyjsv/chatgpt5_rollout_is_an_unmitigated_disaster/?utm_source=share&amp;utm_medium=web3x&amp;utm_name=web3xcss&amp;utm_term=1&amp;utm_content=share_button" rel="noreferrer">so</a><a href="https://www.reddit.com/r/ChatGPT/comments/1mkvhck/its_over_boys_and_girls_everything_that_i_and/?utm_source=share&amp;utm_medium=web3x&amp;utm_name=web3xcss&amp;utm_term=1&amp;utm_content=share_button" rel="noreferrer">many</a><a href="https://www.reddit.com/r/ChatGPT/comments/1mkm47a/gpt5_is_not_an_upgrade_it_is_a_forced_downgrade/?utm_source=share&amp;utm_medium=web3x&amp;utm_name=web3xcss&amp;utm_term=1&amp;utm_content=share_button" rel="noreferrer">of</a><a href="https://www.reddit.com/r/ChatGPT/comments/1mkadb3/bring_back_o3_o3pro_45_4o/?utm_source=share&amp;utm_medium=web3x&amp;utm_name=web3xcss&amp;utm_term=1&amp;utm_content=share_button" rel="noreferrer">these</a><a href="https://www.reddit.com/r/ChatGPT/comments/1mkim8h/gpt5_is_a_disaster/?utm_source=share&amp;utm_medium=web3x&amp;utm_name=web3xcss&amp;utm_term=1&amp;utm_content=share_button" rel="noreferrer">posts</a> that I could find posts to link to for every word of this paragraph in under five minutes. </p><p>Yet OpenAI isn&#x2019;t just screwing over consumers. Developers that want to integrate OpenAI&#x2019;s model now have access to &#x201C;priority processing&#x201D; &#x2014; previously an enterprise-only feature (<a href="https://web.archive.org/web/20250721161332/https://openai.com/api-priority-processing/"><u>see this archive from July 21st 2025</u></a>) to guarantee low latency and uptime. While this sounds like something altruistic, or a new beneficial feature, I&#x2019;m not convinced. I believe there&#x2019;s only one reason to do this: that OpenAI intends to, or will be forced to due to capacity constraints, start degrading access to its API.&#xA0;</p><p>As with every model developer, we have no real understanding of what may or may not lead to needing &#x201C;reliable, high-speed performance&#x201D; from API access, but the suggestion here is that failing to pay OpenAI&#x2019;s troll toll will put your API access in the hole. That toll is harsh, too, nearly <a href="https://platform.openai.com/docs/pricing?latest-pricing=standard&amp;ref=wheresyoured.at"><u>doubling the API price on each model</u></a>, and while<a href="https://openai.com/api-priority-processing/?ref=wheresyoured.at"><u> the Priority Processing Page</u></a> has pricing for all manner of models, its pricing page <a href="https://platform.openai.com/docs/pricing?latest-pricing=priority&amp;ref=wheresyoured.at"><u>reduces the options down to two models</u></a> &#x2014; GPT-5 and GPT-5-mini, suggesting it may not intend to provide priority access in perpetuity.&#xA0;</p><p>OpenAI is far from alone in turning the screws on its customers. As I&#x2019;ll explain, effectively every consumer generative AI company has started some sort of $200-a-month &#x201C;pro&#x201D; plan &#x2014; Perplexity Max, Gemini ($249.99 a month before discounts), Cursor Ultra, Grok Heavy (which is $300 a month!), and, of course, Anthropic, whose $100-a-month and $200-a-month plans <a href="https://www.wheresyoured.at/anthropic-is-bleeding-out/"><u>allowed Claude Code users to spend anywhere from 100% to 10,000% of their monthly subscription in API calls</u></a>. This <a href="https://x.com/AnthropicAI/status/1949898502688903593?ref=wheresyoured.at"><u>led to rate limits starting August 28 2025</u></a> &#x2014; a conveniently-placed date to <a href="https://www.cnbc.com/2025/07/29/anthropic-in-talks-to-raise-fresh-capital-at-170-billion-valuation.html?ref=wheresyoured.at"><u>allow Anthropic to close as much as $5 billion in funding</u></a> before its users churn.&#xA0;</p><p>Worse still, Anthropic burned all of that cash to get Claude Code to $400 million in annualized revenue <a href="https://www.theinformation.com/articles/anthropic-revenue-pace-nears-5-billion-run-mega-round?rc=kz8jh3&amp;ref=wheresyoured.at"><u>according to The Information</u></a> &#x2014; around $33 million in monthly revenue that will almost certainly evaporate as its customers hit week-long rate limits on a product that&#x2019;s billed monthly.&#xA0;</p><p>These are not plans created for &#x201C;power users.&#x201D; They are the actual price points at which these things need to be to be remotely sustainable, though Sam Altman <a href="https://fortune.com/2025/01/07/sam-altman-openai-chatgpt-pro-subscription-losing-money-tech/?ref=wheresyoured.at"><u>said earlier in the year that ChatGPT Pro&#x2019;s $200-a-month subscription was losing OpenAI money</u></a>. And with GPT-5, meaningful functionality &#x2014; the ability to choose the specific model you want for a task &#x2014; <a href="https://www.theverge.com/openai/748017/gpt-5-chatgpt-openai-release?ref=wheresyoured.at"><u>is being completely removed for ChatGPT Plus and Team subscribers</u></a>.</p><p>This is part of an industry-wide enshittification of generative AI, where the abominable burn rates behind these products are forcing these companies to take measures ranging from minor to drastic.&#xA0;</p><p>The problem, however, is that these businesses have yet to establish truly essential products, and even when they create something popular &#x2014; like Claude Code &#x2014; they can&#x2019;t make it popular without burning horrendous amounts of cash. The same goes for Cursor, and I believe just about every other major product built on top of Large Language Models. And I believe that when they try to adjust pricing to reflect their actual costs, that popularity will begin to wane. I believe we&#x2019;re already seeing that with Claude Code, based on the sentiment I&#x2019;ve seen on the tool&#x2019;s Reddit page, although I&#x2019;m also wary of making any sweeping statements right now, as it&#x2019;s just too early to say.&#xA0;</p><p>The great enshittification of AI has begun.</p>]]>
			</content:encoded>
		</item>
		<item>
			<title>
				<![CDATA[AI Is A Money Trap]]>
			</title>
			<description>
				<![CDATA[<p>In the last week, we&#x2019;ve had no less than <a href="https://www.wsj.com/economy/the-ai-booms-hidden-risk-to-the-economy-731b00d6?gaa_at=eafs&amp;gaa_n=ASWzDAjwWxWRxNasxsIoaicPhYpm7kiuCYAAHHii2wCYod_8HB6Cb5ej4R0SXIPhYP4%3D&amp;gaa_ts=68912948&amp;gaa_sig=8MMWlPyQcWukZjLy6R03M7NAof_0SIJAaUFuhzBzNwwk0s4iud9l3I8-8THVWPocslUCADw4PCkiNz-Dn-MiPw%3D%3D&amp;ref=wheresyoured.at"><u>three</u></a><a href="https://www.wsj.com/tech/ai/silicon-valley-ai-infrastructure-capex-cffe0431?gaa_at=eafs&amp;gaa_n=ASWzDAgZJjiacbFkrupZnkbfEDplfFwDDxhrNBUcwsiwAa-1PumucfP1n43IxKz3Xso%3D&amp;gaa_ts=68912976&amp;gaa_sig=4PsowgV0gZtCLX6D606qOSx-eeC7mEE9F3SBlb2_4Ge4OzKNx2_gq5bUNBPkF4IcBaPhIEPcna5Zq1wJ8q8xeA%3D%3D&amp;ref=wheresyoured.at"><u>different</u></a><a href="https://www.ft.com/content/7052c560-4f31-4f45-bed0-cbc84453b3ce?ref=wheresyoured.at"><u>pieces</u></a> asking whether the massive proliferation of data centers is a massive bubble, and though they, at times, seem to take the default position of AI&#x2019;s inevitable value, they&#x2019;ve begun to sour on</p>]]>
			</description>
			<link>https://www.wheresyoured.at/ai-is-a-money-trap/</link>
			<guid isPermaLink="false">689384c964d4560001705590</guid>
			<dc:creator>
				<![CDATA[Edward Zitron]]>
			</dc:creator>
			<pubDate>Wed, 06 Aug 2025 20:02:39 GMT</pubDate>
			<content:encoded>
				<![CDATA[<p>In the last week, we&#x2019;ve had no less than <a href="https://www.wsj.com/economy/the-ai-booms-hidden-risk-to-the-economy-731b00d6?gaa_at=eafs&amp;gaa_n=ASWzDAjwWxWRxNasxsIoaicPhYpm7kiuCYAAHHii2wCYod_8HB6Cb5ej4R0SXIPhYP4%3D&amp;gaa_ts=68912948&amp;gaa_sig=8MMWlPyQcWukZjLy6R03M7NAof_0SIJAaUFuhzBzNwwk0s4iud9l3I8-8THVWPocslUCADw4PCkiNz-Dn-MiPw%3D%3D&amp;ref=wheresyoured.at"><u>three</u></a><a href="https://www.wsj.com/tech/ai/silicon-valley-ai-infrastructure-capex-cffe0431?gaa_at=eafs&amp;gaa_n=ASWzDAgZJjiacbFkrupZnkbfEDplfFwDDxhrNBUcwsiwAa-1PumucfP1n43IxKz3Xso%3D&amp;gaa_ts=68912976&amp;gaa_sig=4PsowgV0gZtCLX6D606qOSx-eeC7mEE9F3SBlb2_4Ge4OzKNx2_gq5bUNBPkF4IcBaPhIEPcna5Zq1wJ8q8xeA%3D%3D&amp;ref=wheresyoured.at"><u>different</u></a><a href="https://www.ft.com/content/7052c560-4f31-4f45-bed0-cbc84453b3ce?ref=wheresyoured.at"><u>pieces</u></a> asking whether the massive proliferation of data centers is a massive bubble, and though they, at times, seem to take the default position of AI&#x2019;s inevitable value, they&#x2019;ve begun to sour on the idea that it&#x2019;s going to happen soon.</p><p>Meanwhile, quirked-up threehundricorn <a href="https://www.cnbc.com/2025/08/04/openai-chatgpt-700-million-users.html?ref=wheresyoured.at"><u>OpenAI has either raised or is about to raise another $8.3 billion in cash</u></a>, less than two months since it raised $10 billion from SoftBank and a selection of venture capital firms.&#xA0;</p><p>I hate to be too crude, but where the fuck is this money going? Is OpenAI just incinerating capital? Is it compute? Is it salaries? Is it compute? Is it to build data centers, <a href="https://www.wheresyoured.at/softbank-openai/"><u>because SoftBank isn&#x2019;t actually building anything for Stargate</u></a>?&#xA0;</p><p><a href="https://www.theinformation.com/articles/founders-fund-dragoneer-commit-1-billion-plus-openai-deal?rc=kz8jh3&amp;ref=wheresyoured.at"><u>The Information suggested OpenAI is using the money to build data centers</u></a> &#x2014; possibly the only worse investment it can make other than generative AI, and it&#x2019;s one that it can&#x2019;t avoid because OpenAI also is somehow running out of compute.&#xA0;And now they&apos;re in &quot;<a href="https://www.reuters.com/business/openai-eyes-500-billion-valuation-potential-employee-share-sale-source-says-2025-08-06/?ref=wheresyoured.at" rel="noreferrer">early-stage discussions</a>&quot; about an employee share sale that would value the company at $500 billion, a ludicrous number that shows we&apos;re leaving the realm of reality. To give you some context, Shopify&apos;s market cap is $197 billion, Salesforce&apos;s is $248 billion, and Netflix&apos;s is $499 billion. <em>Do you really think that OpenAI is worth more than these companies? Do you think they&apos;re worth more than AMD at a $264 billion market cap?  <strong>Do you? </strong></em></p><p><strong><em>AHhhhhhhh-</em></strong></p><p>Amongst this already-ridiculous situation sits the issue of OpenAI and Anthropic&#x2019;s actual revenues, <a href="https://www.wheresyoured.at/howmuchmoney/"><u>which I wrote about last week</u></a>, and have roughly estimated to be $5.26 billion and $1.5 billion respectively (as of July). In any case, these estimates were made based on both companies&#x2019; predilection for leaking their &#x201C;annualized revenues,&#x201D; or monthx12.&#xA0;</p><p>This extremely annoying term is one that I keep bringing up because it&#x2019;s become the de-facto way for generative AI companies to express their revenue, and both OpenAI and Anthropic are leaking them intentionally, and doing so in a way that suggests they&#x2019;re not using even the traditional ways of calculating them. <a href="https://www.theinformation.com/articles/openai-hits-12-billion-annualized-revenue-breaks-700-million-chatgpt-weekly-active-users?rc=kz8jh3&amp;ref=wheresyoured.at"><u>OpenAI leaked on July 30 2025&#xA0; that it was at $12 billion annualized revenue</u></a> &#x2014; so around $833 million in a 30-day period &#x2014; <a href="https://www.nytimes.com/2025/08/01/business/dealbook/openai-ai-mega-funding-deal.html?ref=wheresyoured.at"><u>yet two days later on August 1 2025 the New York Times reported they were at $13 billion annualized revenue</u></a>, or $1.08 billion of monthly revenue.</p><p>It&#x2019;s very clear OpenAI is not talking in actual calendar months, at which point we can assume something like a trailing 30 day window (as in the &#x201C;month&#x201D; is just 30 days rather than a calendar month). We can, however, declaratively say that it&#x2019;s not doing &#x201C;the month of June&#x201D; or &#x201C;the month of July&#x201D; because if it was, OpenAI wouldn&#x2019;t have given two vastly different god damn numbers in the same two day period. That doesn&#x2019;t make any sense. There are <em>standard</em> ways to handle annualized revenue, and it&apos;s clear they&apos;re not following them.</p><p>And to be even clearer, while I can&#x2019;t say for certain, I believe these leaks are deliberate. OpenAI&#x2019;s timing matches exactly with fundraising.&#xA0;</p><p>On Anthropic&#x2019;s side, these revenues are beginning to get really weird. Anthropic went from making $72 million (<a href="https://www.reuters.com/technology/artificial-intelligence/anthropic-raise-2-bln-deal-valuing-ai-startup-60-bln-wsj-reports-2025-01-07/?ref=wheresyoured.at"><u>$875 million annualized</u></a>) in January to $433 million in July &#x2014; or at least, it leaked on July 1, 2025 that it was at <a href="https://www.theinformation.com/articles/anthropic-revenue-hits-4-billion-annual-pace-competition-cursor-intensifies?rc=kz8jh3&amp;ref=wheresyoured.at"><u>$4 billion annualized to The Information</u></a> ($333 million a month) and claimed it had reached $5 billion annualized revenue ($416 million) <a href="https://finance.yahoo.com/news/anthropic-nears-funding-170-billion-005055848.html?ref=wheresyoured.at"><u>to Bloomberg on July 29 2025</u></a> .&#xA0;</p><p>How&#x2019;d it get there? I&#x2019;m guessing it was from cranking up prices on Cursor, and we&#x2019;ve had the confirmation that&#x2019;s the case thanks to <a href="https://www.theinformation.com/articles/anthropic-revenue-pace-nears-5-billion-run-mega-round?rc=kz8jh3&amp;ref=wheresyoured.at"><u>The Information reporting that $1.4 billion of its annualized revenue is from its top two customers</u></a> (so around $116 million a month), the biggest of which is Cursor. Confusingly, The Information also says that Anthropic&#x2019;s Claude Code is &#x201C;generating nearly $400 million in annualized revenue, roughly doubling from just a few weeks ago,&#x201D; meaning about $33 million of monthly revenue.&#xA0;</p><p>In any case, I think Cursor is a huge indicator of the current fragility of the bubble &#x2014; and the fact that for most AI startups, there&#x2019;s simply no way out, because being acquired or going public does not appear to be a viable route.&#xA0;</p><h3 id="cursor-is-a-systemic-risk-to-the-ai-industry"><strong>Cursor Is A Systemic Risk To The AI Industry</strong></h3><p>I know it sounds a little insane, but I believe that Cursor is the weak point of the entire AI bubble, and I&#x2019;ll explain why, and how this could go. This is, by no means, inevitable, but I cannot work out what Cursor does other than this.</p><ol><li>Cursor makes &#x2014; before, at least, their massive changes to their service &#x2014; $500 million in annualized revenue, so around $42 million a month. This makes it the single-highest earning generative AI company that isn&#x2019;t called OpenAI or Anthropic, and the highest-earning company built on top of (primarily) Anthopic&#x2019;s technology. Its success is symbolic to the greater movement, and just as it hit its peak, Anthropic (and OpenAI, to a lesser extent) decided to add priority processing and priority service tiers, demanding more money up front and causing Cursor to have to massively degrade its service. I <a href="https://www.wheresyoured.at/anthropic-and-openai-have-begun-the-subprime-ai-crisis/"><u>explain in detail in my premium piece from a few weeks ago</u></a>.<ol><li>To explain in short, Cursor&#x2019;s AI-powered coding editor used to have fairly unrestrained access to the various models provided by these companies. In mid-June &#x2014; a few weeks after Anthropic introduced &#x201C;<a href="https://docs.anthropic.com/en/api/service-tiers?ref=wheresyoured.at#get-started-with-priority-tier"><u>priority tiers</u></a>&#x201D; that required companies to pay up-front and guarantee a certain throughput of tokens and increased costs on using prompt caching, a big part of AI coding &#x2014; <a href="https://techcrunch.com/2025/07/07/cursor-apologizes-for-unclear-pricing-changes-that-upset-users/?ref=wheresyoured.at"><u>Cursor massively changed the amount its users could use the product, and introduced a $200-a-month subscription.</u></a>&#xA0;<ol><li>As an aside to this, Anthropic also competes with Cursor&#x2019;s AI coding product with their own service, Claude Code.&#xA0;</li></ol></li></ol></li><li>Cursor, as Anthropic&#x2019;s largest client (<a href="https://www.theinformation.com/articles/anthropic-revenue-pace-nears-5-billion-run-mega-round?rc=kz8jh3&amp;ref=wheresyoured.at"><u>the second largest being Github Copilot</u></a>), represents a material part of its revenue, and its surging popularity meant that they were sending more and more revenue Anthropic&#x2019;s way.</li><li>Anthropic used this opportunity to raise prices on accessing its models to continue providing service at an acceptable level to Cursor&#x2019;s customers by introducing &#x201C;<a href="https://docs.anthropic.com/en/api/service-tiers?ref=wheresyoured.at#get-started-with-priority-tier"><u>Priority Tier</u></a>&#x201D; access on May 30 2025.</li><li>This has allowed Anthropic to juice its revenues, and due to the upfront nature of these contracts, Cursor is locked-in regardless of how well it does. The net result of these cost increases means that Cursor&#x2019;s product is less attractive to its customers, and will thus make it less money.</li><li>At this point, one has to ask &#x2014; how does Cursor survive? Their product isn&#x2019;t profitable, and the means it used to make their company so successful have become untenable. It has guaranteed a certain throughput of tokens-per-second to the major model developers, chief of them Anthropic, but <a href="https://cursor.com/blog/new-tier?ref=wheresyoured.at"><u>Cursor itself said it&#x2019;s signed multi-year deals with multiple cloud providers like OpenAI, xAI and Google</u></a>.</li><li>Cursor&#x2019;s product is now worse. People are going to cancel their subscriptions. Its annualized revenue will drop, and its ability to raise capital will suffer as a direct result. It will, regardless of this drop in revenue, have to pay the cloud companies what it owes them, as if it had the business it used to. I have spoken to a few different people, including a company with an enterprise contract, that are either planning to cancel or trying to find a way out of their agreements with Cursor.</li><li>If Cursor is allowed to die, it will be unable to pay a chunk of Anthropic&#x2019;s revenue &#x2014; and yes, the revenue of other providers too. It will also bring into question whether it&#x2019;s possible to build &#x2014; putting aside any questions of profitability &#x2014; a business of any kind offering services built on top of generative AI, and in turn bring into doubt the veracity of investing in this sector.</li><li>It will also call into question whether any other generative AI company is a real business.&#xA0;</li><li>This will naturally lead to the question of why we&#x2019;re building all these <em>god damn data centers!</em></li></ol><p>Cursor, at this point, faces two options: die, or get acquired. This is not an attack on anyone who works at the company, nor anything personal. The unit economics of this business do not make sense and yet, on some level, its existence is deeply important to the valley&#x2019;s future.&#xA0;</p><h3 id="so-who-could-acquire-cursor"><strong>So, who could acquire Cursor?&#xA0;</strong></h3><p><strong>OpenAI?</strong><a href="https://techcrunch.com/2025/07/11/windsurfs-ceo-goes-to-google-openais-acquisition-falls-apart/?ref=wheresyoured.at"><u>OpenAI couldn&#x2019;t acquire Windsurf because it was too worried Microsoft would get the somehow-essential IP of one of what feels like a hundred different AI-powered coding environments</u></a>. It also already<a href="https://techcrunch.com/2025/04/22/why-openai-wanted-to-buy-cursor-but-opted-for-the-fast-growing-windsurf/?ref=wheresyoured.at"><u> tried and failed to buy Cursor</u></a>, and if I&#x2019;m honest, I bet Cursor would sell now. Honestly, Cursor fucked up bad not selling then. It could have got $10 billion and Sam Altman would&#x2019;ve had to accelerate the funding clause. It would&#x2019;ve been so god-damn sick, but now the only &#x201C;sick&#x201D; thing here is Cursor&#x2019;s fragile, plagued business model.&#xA0;</p><p><strong>How about Anthropic?</strong> Eh! It already has their own extremely-expensive coding environment, Claude Code, <a href="https://www.wheresyoured.at/anthropic-is-bleeding-out/"><u>which I estimated loses the company 100% to 10,000% of a subscription per-customer a few weeks ago</u></a>, and <a href="https://techcrunch.com/2025/07/28/anthropic-unveils-new-rate-limits-to-curb-claude-code-power-users/?ref=wheresyoured.at"><u>now Anthropic is adding weekly limits on accounts</u></a>, which will, I believe, create some of the most gnarly churn in SaaS history. Also, does Anthropic really want to acquire its largest customer? Also, with what money? It&#x2019;s not <a href="https://www.cnbc.com/2025/07/29/anthropic-in-talks-to-raise-fresh-capital-at-170-billion-valuation.html?ref=wheresyoured.at"><u>raising $5 billion</u></a> to bail out Cursor. Anthropic needs that to feed directly into Andy Jassy&#x2019;s pocket to keep offering increasingly-more-complex models that never quite seem to be good enough.&#xA0;</p><p><strong>Google</strong>? <a href="https://www.reuters.com/business/google-hires-windsurf-ceo-researchers-advance-ai-ambitions-2025-07-11/?ref=wheresyoured.at"><u>It just sort-of-bought Windsurf</u></a>! It can&#x2019;t do that again. It&#x2019;s already given out the participation trophy multiple billions of dollars to investors and founders so nobody has to get embarrassed about this, and <a href="https://www.cnbc.com/2025/07/14/cognition-to-buy-ai-startup-windsurf-days-after-google-poached-ceo.html?ref=wheresyoured.at"><u>then allowed Cognition to pick up the scraps</u></a> of a business <a href="https://cognition.ai/blog/windsurf?ref=wheresyoured.at"><u>that made $6.83 million a month</u></a> after <a href="https://www.crunchbase.com/organization/windsurf-codeium?ref=wheresyoured.at#financials"><u>burning $143 million of investor capital</u></a> (TechCrunch reports Windsurf was left with $100 million in cash post-acquisition). TechCrunch also reports that <a href="https://techcrunch.com/2025/08/01/more-details-emerge-on-how-windsurfs-vcs-and-founders-got-paid-from-the-google-deal/?ref=wheresyoured.at"><u>Cognition paid $250 million for what remained</u></a>, and that this deal didn&#x2019;t actually pay out the majority of Windsurf&#x2019;s employees,</p><p><strong>Meta</strong>? If I&#x2019;m Cursor&#x2019;s CEO, I am calling Mark Zuckerberg and pretending that I think the only person in the world who can usher in the era of Superintelligence is the guy who <a href="https://finance.yahoo.com/news/metas-reality-check-inside-the-45-billion-cash-burn-at-reality-labs-125717347.html?ref=wheresyoured.at"><u>burned more than $45 billion on the metaverse</u></a> and <a href="https://www.wsj.com/tech/ai/mark-zuckerberg-just-declared-war-on-the-iphone-30163885?gaa_at=eafs&amp;gaa_n=ASWzDAhaLDLgCATmgYUN0yObvzA6yBABgja0GxA0r1rQShz3cEtto5pdRUTev2rZzlQ%3D&amp;gaa_ts=68913102&amp;gaa_sig=nqzSDw047kGV8_BAdK51floMO-EQD0gwkQ2doDtGcfaeFPkgPPkfRGK3wDqX8kAiVT8sQfQM0uL13LFFNVnJEA%3D%3D&amp;ref=wheresyoured.at"><u>believes that not wearing AI glasses in the future will be a disadvantage</u></a>. I would be saying all manner of shit about the future, and that the only way to do this was to buy my AI-powered coding startup that literally can&#x2019;t afford to exist.</p><p>And that really is the problem. These companies are all going through the same motions that every company before them did &#x2014; raise as much money as possible, get as big as possible, and eventually scale to the point you&#x2019;re fat with enterprise cash.&#xA0;</p><p>Except the <em>real</em> problem is that, just like big tech&#x2019;s new gluttony of physical real estate it&apos;s taken on, generative AI companies are burdened with a constant and aggressive form of cloud debt &#x2014; the endless punishment of the costs of accessing the API for generative AI models that always seem to get a little better, but never in such a way that anything really changes other than how much Anthropic and OpenAI are going to need at the end of the month or they break your startup&#x2019;s legs.</p><p>I&#x2019;m not even trying to be funny! Anthropic raised its prices on Cursor so severely it broke its already-unprofitable business model. These products &#x2014; while also, for the most part, not producing that much revenue &#x2014; need to be sold with users being aware of (and sensitive to) the cost of providing them, and Cursor&#x2019;s original product was $20-a-month for 500 &#x201C;fast requests&#x201D; of different models, in the same way that accessing Claude Code on any subscription is either $20, $100, or $200 a month rather than paying per API call, because these companies all sell products that shield the customer from the actual costs of running the services.</p><p>The irony is that, despite being willing to kill these companies by fundamentally changing the terms upon which they access these models, Anthropic is also, in some way, dependent on Cursor, Replit, and other similar firms continuing to buy tokens at the same rate as before, as that consumption is baked into its ARR figures, as well as the forward-looking revenue projections.&#xA0;</p><p>It is, in some sense, a <a href="https://en.wikipedia.org/wiki/Kobayashi_Maru?ref=wheresyoured.at"><u>Kobayashi Maru</u></a>. Anthropic has an existential need to screw over its customers by hiking rates and imposing long-term commitments, but its existence is also, in some way, predicated on these companies continuing to exist. If Cursor and Replit both die, that&#x2019;s a significant chunk of Anthropic&apos;s API business gone in a flash &#x2014; and, <em>may</em> I remind you, that significantly overshadows its subscription business (making it almost like an inverse of OpenAI, where subscriptions drive the bulk of revenue).&#xA0;</p><p>Anthropic&#x2019;s future is wedded to Cursor, and I just don&#x2019;t see how Cursor survives, let alone exits, or gets subsumed by another company in a way that mirrors how acquisitions have worked since&#x2026;ever.&#xA0;&#xA0;</p><p>If Cursor does not sell for a healthy amount &#x2014; I&#x2019;m talking $10 billion plus, and I mean actually sell, not &#x201C;the founders are hired in a strange contractual agreement that pays out investors and its assets are sold to Rick from Pawn Stars&#x201D; &#x2014; it will prove that no generative AI company, to this date, has actually been successful. In reality, I expect a <a href="https://www.youtube.com/watch?v=T7UFaaB8QqE&amp;ref=wheresyoured.at"><u>Chumlee-esque deal</u></a> that helps CEO Michael Truell buy a porsche while his staff makes nothing.</p><p>Is Cursor worth $10 billion? Nope! No matter how good its product may or may not be, it is not good enough to be sold at a price that doesn&#x2019;t require Cursor to incinerate hundreds of millions of dollars with no end in sight.</p><p>And this ultimately gives us the real conundrum &#x2014; why aren&#x2019;t generative AI startups selling?&#xA0;&#xA0;</p><h2 id="no-really-why-are-there-so-few-generative-ai-acquisitions"><strong>No, Really, Why Are There So Few Generative AI Acquisitions?</strong></h2><p>Before we go any further, there have been <em>some </em>acquisitions, but they are sparse, and seem almost entirely&#xA0;centered around bizarre acqui-hires and confusing fire sales.</p><p>AMD bought Silo AI, &#x201C;the largest private AI lab in Europe,&#x201D; <a href="https://www.amd.com/en/newsroom/press-releases/2024-8-12-amd-completes-acquisition-of-silo-ai-to-accelerate.html?ref=wheresyoured.at"><u>in August 2024 for $665 million</u></a>, which appears to be the only real acquisition in generative AI history, and <a href="https://www.tomshardware.com/tech-industry/artificial-intelligence/lisa-su-formally-welcomes-silo-ai-team-to-amd-after-completing-dollar665-million-acquisition?ref=wheresyoured.at"><u>appears to be partially based on Silo&#x2019;s use of AMD&#x2019;s GPUs</u></a>.&#xA0;</p><p>Elsewhere, <a href="https://www.forbes.com/sites/janakirammsv/2024/09/30/nvidia-acquires-octoai-to-dominate-enterprise-generative-ai-solutions/?ref=wheresyoured.at"><u>NVIDIA bought OctoAI for an estimated $250 million in September 2024</u></a>, <a href="https://www.marketscreener.com/quote/stock/NVIDIA-CORPORATION-57355629/news/NVIDIA-Corporation-acquired-Brev-dev-Inc-47416700/?ref=wheresyoured.at"><u>after buying Brev.dev in July 2024 for an undisclosed sum</u></a>, and then <a href="https://www.wired.com/story/nvidia-gretel-acquisition-synthetic-training-data/?ref=wheresyoured.at"><u>Gretel in March 2025</u></a>. Yet in all three cases these are products to <em>deploy </em>generative AI, and not products built on top of generative AI or AI models. Canva bought &#x201C;generative AI content and research company&#x201D; <a href="http://leonardo.ai/?ref=wheresyoured.at"><u>Leonardo.AI</u></a><a href="https://www.businesswire.com/news/home/20240729977410/en/Canva-to-Acquire-Generative-AI-Platform-Leonardo.AI-to-Bring-Leading-Visual-AI-to-Every-Organization?ref=wheresyoured.at"><u>in July 2024</u></a> for an undisclosed sum.</p><p>Really, the only significant one I&#x2019;ve seen was on July 29 2025 &#x2014; publicly-traded <a href="http://dallasinnovates.com/cognigy-moved-its-u-s-hq-to-north-texas-in-april-now-the-german-ai-co-is-being-acquired-for-nearly-1-billion/?ref=wheresyoured.at"><u>customer service platform NICE buying AI-powered customer service company Cognigy in a $955 million deal</u></a>. According to Cxtoday, <a href="https://www.cxtoday.com/contact-center/why-is-nice-spending-almost-1bn-on-cognigy-a-deep-dive/?ref=wheresyoured.at"><u>Cognigy expects about $85 million in revenue this year</u></a>, though nobody appears to be talking about costs. However, Cognigy, according to <a href="https://www.capterra.com/p/176610/Cognigy-AI/?ref=wheresyoured.at"><u>some</u></a><a href="https://aws.amazon.com/marketplace/pp/prodview-6c25zypcl2fro?ref=wheresyoured.at"><u>sources</u></a>, charges tens or hundreds of thousands per contract for its &#x201C;AI voice agents&#x201D; that can &#x201C;understand and respond to user input in a natural way.&#x201D;</p><p>Great! We&#x2019;ve got one real-deal &#x201C;company built on models&#x201D; acquisition, and it&#x2019;s a company that most people haven&#x2019;t heard of making around $7 million a month.&#xA0;</p><p>Let&#x2019;s take a look at the others.&#xA0;</p><ul><li>Inflection AI to Microsoft, which was not an acquisition but a &#x201C;<a href="https://www.reuters.com/technology/microsoft-agreed-pay-inflection-650-mln-while-hiring-its-staff-information-2024-03-21/?ref=wheresyoured.at"><u>$650 million licensing </u></a>deal&#x201D; that, according to FastCompany, <a href="https://www.fastcompany.com/91069182/microsoft-inflection-ai-exclusive?ref=wheresyoured.at"><u>may be more like $1 billion</u></a> when you include things like how much it paid Inflection CEO and former Deepmind co-founder Mustafa Suleyman.<ul><li>According to FastCompany, the deal involves a license to sell Inflection&#x2019;s models, a waiver against any employee claims against Inflection or Microsoft, paying off investors, and some sort of unnamed compensation for employees.&#xA0;</li><li>Oof! That&#x2019;s a stinky deal.</li></ul></li><li>Windsurf to Google (and Cognition), which was also not an acquisition. <a href="https://www.reuters.com/business/google-hires-windsurf-ceo-researchers-advance-ai-ambitions-2025-07-11/?ref=wheresyoured.at"><u>Windsurf&#x2019;s c-suite went to Google for $2.4 billion</u></a>, which paid them off along with its investors, and then the rest of the staff and the product got acquired by Cognition <a href="https://techcrunch.com/2025/08/01/more-details-emerge-on-how-windsurfs-vcs-and-founders-got-paid-from-the-google-deal/?ref=wheresyoured.at"><u>for $250 million</u></a>.<ul><li>According to TechCrunch, investors made $1.2 billion on the deal, with Windsurf co-founders Varun Mohan and Douglas Chen making another $1.2 billion, and its staff getting to start a new job at a different company building something else, with, according to TechCrunch &#x201C;a large portion of Windsurf&#x2019;s approximately 250 employees&#x201D; not benefiting from the deal.</li><li>As an aside, Mohan and Chen fucking suck. Couldn&#x2019;t afford to break off some of those billions for your people, huh? What a pair of fucking assholes.</li></ul></li><li><a href="https://www.theverge.com/news/703114/openai-io-jony-ive-sam-altman-ai-hardware?ref=wheresyoured.at"><u>Io Products to OpenAI, an all-stock acquisition</u></a>. This deal is a farce and it&#x2019;s unclear if OpenAI actually bought anything. $6.4 billion in stock? For what? Jony Ive&#x2019;s weird face staring at you lovingly as he says stuff like &#x201C;I Think We Should Make It Look Like A Circle&#x201D; while taking a $5 million dollar salary? Get outta here. Not real money.&#xA0;</li><li><a href="http://character.ai/?ref=wheresyoured.at"><u>Character.ai</u></a> to Google. This too was not an acquisition. Google, to quote the Wall Street Journal, &#x201C;<a href="https://www.wsj.com/tech/ai/noam-shazeer-google-ai-deal-d3605697?gaa_at=eafs&amp;gaa_n=ASWzDAgOuaOSstYgzRLVzGAs3JC5o23ZVE7WRjWHc3FZBqSiJzus-KZpbI6mSCKWhvE%3D&amp;gaa_ts=689133d3&amp;gaa_sig=lHy6h2kFPXTlpJ7w9cSNU58mr-q9YTL7apYSFIPSYqJ4VrTLT7W9kefybpJa2UH-19b2H6jLGEglVXKJoqeskA%3D%3D&amp;ref=wheresyoured.at"><u>paid $2.7 billion to bring back an AI Genius who quit in frustration</u></a>.&#x201D; While I don&#x2019;t like the term &#x201C;genius,&#x201D; Shazeer was one of the authors of the original &#x201C;<a href="https://arxiv.org/abs/1706.03762?ref=wheresyoured.at"><u>Attention Is All You Need</u></a>&#x201D; paper that began the Large Language Model era. Nevertheless, much like Inflection, Google paid a licensing fee to <a href="http://character.ai/?ref=wheresyoured.at"><u>Character.ai</u></a> for its models and hired, <a href="https://www.theinformation.com/articles/google-hires-character-ai-cofounders-and-licenses-its-models?rc=kz8jh3&amp;ref=wheresyoured.at"><u>according to The Information</u></a>, &#x201C;its cofounders and many of its engineers,&#x201D; creating a fund that would pay out any vesting shares (as in the shares you are given when you join a company that you accrue over the time you work there) until July 2026.&#xA0;</li></ul><p>Outside of one very industry-specific acquisition, there just doesn&#x2019;t seem to be the investor hunger to buy a company <a href="https://techcrunch.com/2025/06/05/cursors-anysphere-nabs-9-9b-valuation-soars-past-500m-arr/?ref=wheresyoured.at"><u>valued at $9.9 billion</u></a>.</p><p>And you have to ask why. If AI is, as promised, the thing that&#x2019;ll radically change our economy, and these companies are building the tools that&#x2019;ll bring about that change, why does nobody want to buy them?&#xA0;</p><p>And, in the broader term, what does it mean when these companies &#x2014; those with $10bn, or in the case of OpenAI, $300bn valuations &#x2014; can&#x2019;t be bought, and can&#x2019;t go public? Where does this go? What happens next? What&#x2019;s the gameplan here? How will the venture firms that ploughed billions of capital into these businesses bring a return for their LPs if there are no IPOs or buyouts?&#xA0;</p><p>The economic implications of these questions are, quite frankly, terrifying &#x2014; especially when you consider the importance that VC has historically held in building the US tech ecosystem, and they raise further questions about the impact of an AI bubble on companies that are promising, and do have a viable business model, and a product with actual fit, but won&#x2019;t be able to actually raise any cash.&#xA0;</p><h3 id="%E2%80%9Cbut-ed-what-if-cursor-turns-profitable-now%E2%80%9D"><strong>&#x201C;But Ed, what if Cursor turns profitable now?&#x201D;</strong></h3><p>Great! I would believe it was possible if it had ever, ever happened, which it has not.&#xA0;</p><p>I&#x2019;m not even being sarcastic or rude. It has just not happened. No company that actually stakes their entire product on generative AI appears to be able to make money. Glean, a company that makes at best $8.3 million a month ($100 million annualized revenue) <a href="https://www.glean.com/blog/glean-series-e-prompting-launch?ref=wheresyoured.at"><u>said it had $550 million in cash December of last year</u></a>, and then <a href="https://www.glean.com/blog/glean-series-f-announcement?ref=wheresyoured.at"><u>had to raise $150 million in June of this year</u></a>. Where did that money go? Why does a generative search engine product with revenues that are less than a third of the Cincinnati Reds baseball team need half a billion dollars to make $8.3 million a month?&#xA0;</p><p>I&#x2019;m not saying these companies are unnecessary, so much as they may very well be impossible to run as real businesses. This isn&#x2019;t even a qualitative judgment of any one generative AI company. I&#x2019;m just saying, if any of these were good businesses, they would be either profitable or being acquired in actual deals, and there would be good businesses by now.&#xA0;</p><p>The amount of cash they are burning does not suggest they&#x2019;re rapidly approaching any kind of sane burn rate, or we would have heard. Putting aside any kind of skepticism I have, anything you may hold against me for what I say or the way I say it, where are the profitable companies? Why isn&#x2019;t there one, outside of the companies creating data to train the AI models, or Nvidia? We&#x2019;re three years in, and we haven&#x2019;t had one.</p><p>We also have had no exits and no IPOs. There has been no cause for celebration, no validation of a business model through another company deciding that it was necessary to continue its dominance by raising funds on the public market, or allowing actual investors &#x2014; flawed though they may be &#x2014; act as the determiner of their value.&#xA0;</p><p>It is unclear what the addition of Windsurf&#x2019;s intellectual property adds to Cognition, much like it&#x2019;s a little unclear what differentiates Cognition&#x2019;s so-called AI-powered software engineer &#x201C;Devin&#x201D; from anything else on the market. <a href="https://qz.com/goldman-sachs-ai-coder-devin-cognition?ref=wheresyoured.at"><u>I hear Goldman is paying for it</u></a>, and said the stupidest shit I&#x2019;ve ever heard to CNBC that nevertheless shows how little it&#x2019;s actually paying for:</p><p>&#x201C;We&#x2019;re going to start augmenting our workforce with Devin, which is going to be like our new employee who&#x2019;s going to start doing stuff on the behalf of our developers,&#x201D; Argenti told CNBC. &#x201C;Initially, we will have hundreds of Devins [and] that might go into the thousands, depending on the use cases.&#x201D;&#xA0;</p><p>Hundreds of Devins = hundreds of seats. At a very optimistic 500 users at the highest-end pricing of <a href="https://devin.ai/pricing?ref=wheresyoured.at"><u>$500-a-month</u></a> (if it&#x2019;s $20-a-month, Cognition is making a whole, at most, less than $20,000 a month) &#x2014; and let&#x2019;s assume that it does a discount at enterprise scale, because that always happens &#x2014; that&#x2019;s $250,000 a month! Wow! $3 million in revenue? On a trial basis? Amazing!</p><blockquote><strong>Sidenote</strong>: I&apos;m so impressed! To be clear, it&#x2019;s probably far fewer seats and far fewer dollars a month.&#xA0;</blockquote><p>In fact, I can&#x2019;t find a shred of evidence that Cognition otherwise makes much money. <a href="https://www.forbes.com/sites/richardnieva/2025/07/24/ai-coding-startup-cognition-is-in-talks-to-raise-at-a-10-billion-valuation/?ref=wheresyoured.at"><u>Despite currently raising $300 million at a $10 billion valuation</u></a>, I can find no information about Cognition&#x2019;s revenues beyond one comment from <a href="https://www.theinformation.com/articles/six-month-old-ai-coding-startup-valued-at-2-billion-by-founders-fund?rc=kz8jh3&amp;ref=wheresyoured.at"><u>The Information from July 2024, when Cognition raised at a $2 billion valuation</u></a>:</p><p>Cognition&#x2019;s fundraise is the latest example of AI startups raising capital at sky-high valuations despite having little or no revenue.&#x201D;&#xA0;</p><p>In a further move <a href="https://www.theinformation.com/articles/cognition-offers-buyouts-newly-acquired-windsurf-staff?rc=kz8jh3&amp;ref=wheresyoured.at"><u>per The Information</u></a> that is both a pale horse and a deeply scummy thing to do, Cognition has now laid off 30 people from the Windsurf team, and is now offering the remaining 200 buyouts equal to 9 months of salary and, I assume, the end of any chance to accrue further stock in Cognition. CEO Scott Wu said the following in the email telling Windsurf employees about the layoffs and buyouts:</p><p><em>&#x201C;We don&#x2019;t believe in work-life balance&#x2014;building the future of software engineering is a mission we all care so deeply about that we couldn&#x2019;t possibly separate the two,&#x201D; he said. &#x201C;We know that not everyone who joined Windsurf had signed up to join Cognition where we spend 6 days at the office and clock 80+ hour weeks.&#x201D;</em></p><p>All that piss, vinegar, and burning of the midnight oil does not appear to have created a product that actually matters. I realize this is a little cold, but if you&#x2019;re braying and smacking your chest about your hard-charging, 6-days-a-week office culture, you should be able to do better than &#x201C;we have one publicly-known customer and nobody knows our revenue.&#x201D; Maybe it&#x2019;s a little simpler: Cognition paid $250 million to acquire Windsurf so that it could, after the transaction, say they have $82 million in annualized revenue.</p><p>If that&#x2019;s the case, this is one of the dodgiest, weirdest acquisitions I&#x2019;ve seen in my life &#x2014; two founders getting a few hundred million dollars between them and their investors, and a few of their colleagues moving with them to Google, leaving the rest of the staff effectively jobless or in Hell with little payoff for their time working at Windsurf.</p><p>I can only imagine how it must have felt to go from being <a href="https://devops.com/openai-acquires-windsurf-for-3-billion/?ref=wheresyoured.at"><u>supposedly acquired by OpenAI</u></a> to this farcical &#x201C;rich get richer&#x201D; bullshit. It also suggests that the actual underlying value of Windsurf&#x2019;s IP was <em>$250 million</em>.</p><p>So, I ask, why, exactly, is Cognition worth $10 billion? And why did it have to raise $300 million after raising &#x201C;hundreds of millions&#x201D; <a href="https://www.bloomberg.com/news/articles/2025-03-18/cognition-ai-hits-4-billion-valuation-in-deal-led-by-lonsdale-s-firm?ref=wheresyoured.at"><u>according to Bloomberg</u></a> in March? Where is the money going? It doesn&#x2019;t seem to have great revenue, <a href="https://www.youtube.com/watch?v=tNmgmwEtoWE&amp;t=13&amp;ref=wheresyoured.at"><u>Carl Brown of the Internet of Bugs revealed it faked the demo of &#x201C;Devin the AI powered software developer&#x201D; last year</u></a>, and Devin doesn&#x2019;t even rank on <a href="https://www.swebench.com/?ref=wheresyoured.at"><u>SWE-benchmark</u></a>, the industry standard for model efficacy at coding tasks.&#xA0;</p><p>At best, it&#x2019;s now acquired their own unprofitable coding environment and the smidgen of revenue associated. How would Cognition go public? What is the actual exit path for Cognition, or any other generative AI startup?&#xA0;</p><h2 id="get-acquired-go-public-or-die"><strong>Get Acquired, Go Public, Or Die</strong></h2><p>And that, right there, is Silicon Valley&#x2019;s own housing crisis, except instead of condos houses they can&#x2019;t afford with sub-prime adjustable rate mortgages, venture capitalists have invested in unprofitable, low-revenue startups with valuations that they can never sell at. And, like homeowners in the dismal years of 2008 and 2009, they&#x2019;re almost certainly underwater &#x2014; they just haven&#x2019;t realized it yet.</p><p>Where consumers were unable to refinance their mortgages to bring their monthly payments down, generative AI startups face pressure to continually raise at higher and higher valuations to keep up with their costs, with each one making it less likely their company will survive.&#xA0;</p><p>The other difference is that, in the case of the housing crisis, those who were able to hold onto their properties eventually saw their equity recover to their pre-crash levels, in part because housing is essential and because its price is influenced just as much by supply and demand, as it is the ability for people to finance the purchase of properties, and when the population increases, so too does the demand for housing. None of that is true with AI. There&#x2019;s a finite number of investors, a finite number of companies, and a finite amount of capital &#x2014; and those companies are only as valuable as the expectations that investors have for them, and as the broader sentiment towards AI.&#xA0;</p><p>Who is going to buy Cognition? Because the only other opportunity for the investors who put the money into this company to make money here &#x2014; let alone to recoup their initial investment &#x2014;&#xA0; is for Cognition to go public. Do you think Cognition will go public? How about Cursor? It&#x2019;s worth $9.9 billion, and <a href="https://www.theinformation.com/briefings/investors-court-anysphere-18-20-billion-valuation?rc=kz8jh3&amp;ref=wheresyoured.at"><u>there was a rumour that it was raising at a valuation of $18 billion to $20 billion back in June</u></a>.</p><p>Do you see Perplexity, <a href="https://finance.yahoo.com/news/perplexity-ai-achieves-18bn-valuation-113151944.html?ref=wheresyoured.at"><u>at a valuation of $18 billion</u></a>, selling to another company? The alternative, as discussed, is that Perplexity, a company with 15 million users and, <a href="https://www.ft.com/content/4e05a5c5-84ad-4f8a-991a-d7f3842de76d?ref=wheresyoured.at"><u>at $150 million annualized revenue</u></a>, is still making less than half of the revenue of the Cincinnati Reds baseball team (<a href="https://www.forbes.com/teams/cincinnati-reds/?ref=wheresyoured.at"><u>$325 million</u></a> in annual revenue, and that&#x2019;s real money, not &#x201C;annualized revenue&#x201D;), must go public. Perplexity has, at this point, <a href="https://www.crunchbase.com/organization/perplexity-ai?ref=wheresyoured.at"><u>raised over a billion dollars</u></a> to <a href="https://www.theinformation.com/articles/google-challenger-perplexity-growth-comes-high-cost?ref=wheresyoured.at&amp;rc=kz8jh3"><u>lose $68 million in 2024</u></a> on $34 million of revenue.&#xA0;</p><p>By comparison, the Cincinnati Reds is a great business, with a net monthly income of $29 million, all to provide a service that upsets and humiliates millions of people from Ohio every year for the pleasure of America.&#xA0;</p><p>Putting aside the Reds, what exactly is it that Perplexity could offer to the public markets as a stock, or to an acquirer? <a href="https://www.bloomberg.com/news/articles/2025-06-20/apple-executives-have-held-internal-talks-about-buying-ai-startup-perplexity?ref=wheresyoured.at"><u>Apple considered acquiring it in June</u></a>, but Apple tends to acquire the companies it wants to integrate into the core business (<a href="https://techcrunch.com/2010/04/28/apple-siri-200-million/?ref=wheresyoured.at"><u>as was the case with Siri</u></a>), which makes me think that Perplexity leaked information about a deal that was never really serious. Hell, <a href="https://www.cnbc.com/2025/06/20/meta-perplexity-scale-ai-deal.html?ref=wheresyoured.at"><u>Meta talked about acquiring it too</u></a>. Isn&#x2019;t it weird that two different companies talked about buying Perplexity but neither of them did it? CEO Aravind Srivinas said in July that he wanted to &#x201C;<a href="https://www.businessinsider.com/perplexitys-ceo-does-not-want-acquired-by-big-tech-2025-7?ref=wheresyoured.at"><u>remain independent</u></a>,&#x201D; which is a weird thing to say after talking to two giant multi-trillion-dollar market cap tech firms about selling to them.&#xA0;</p><p>It&#x2019;s almost as if nobody actually wants to buy Perplexity, or any of these sham companies, which I know sounds mean, but if you are worth billions or tens of billions of dollars and you can&#x2019;t make more than a bottom-tier baseball team in <em>fucking Ohio</em>, you are neither innovative nor deserving of said valuation.&#xA0;</p><p>But really, my pissiness and baseball comparisons aside, what exactly is the plan for these companies? They don&#x2019;t make enough money to survive without a continuous flow of venture capital, and they don&#x2019;t seem to make impressive sums of money even when allowed to burn as much as they&#x2019;d like. These companies are not being forced to live frugally, or at least have yet to be made to, perhaps because they&#x2019;re all actively engaged at spending as much money as possible in pursuit of finding an idea that makes more money than it loses. This is not a rational or reasonable way to proceed.</p><p>Yes, there are startups that can justify burning capital. Yes, there are companies that have burned hundreds of millions of dollars to find their business models, or <em>billions</em> in the case of Uber, but none of these companies are like those companies in the generative AI space. GenAI businesses don&#x2019;t have the same economics, nor do they have the same total addressable markets. If you&#x2019;re going to say &#x201C;Amazon Web Services,&#x201D; <a href="https://www.wheresyoured.at/the-haters-gui/#:~:text=Ed!%20Amazon%20Web%20Services%20Took%20Years%20To%20Become%20Profitable!%20People%20Said%20Amazon%20Would%20Fail!"><u>I already explained why you&#x2019;re wrong a few weeks ago</u></a>.</p><p>These startups are their VC firms&#x2019; subprime mortgages, overstuffed valuations with no exit route, and no clear example of how to sell them or who to sell them to.</p><p>The closest they&#x2019;ve got is using generative AI startups as beauty pageants for guys wearing Patagonia, finding ways to pretend that the guy who runs an AI startup &#x2014; sorry, <em>AI lab</em> &#x2014; is some sort of mysterious genius versus just another founder in just another bubble with just another overstuffed valuation.&#xA0;</p><p>The literal only liquidity mechanism (outside of Cognigy) that generative AI has had so far is &#x201C;selling AI talent to big tech at a premium.&#x201D; Nobody has gone or is going public, and if they are not going public, the only route for these companies is to either become profitable &#x2014; which they haven&#x2019;t &#x2014; or sell to somebody, which they do not.</p><p>But I&#x2019;ve been dancing around the real reason they won&#x2019;t sell: because, <strong>fundamentally, generative AI does not let companies build something new</strong>. Anyone that builds a generative AI product is ultimately just prompting the model, albeit in increasingly more-complex ways at the scale of something like Claude Code &#x2014; though Anthropic has the advantage of being one of the main veins of infrastructure. This means that a generative AI company owns very few unique things beyond their talent, and will forever be at the mercy of any and all decisions that their model provider makes, such as increasing prices or creating competing products.&#xA0;</p><p>I know it sounds ludicrous, but this is the reality of these companies. While there are some companies that have some unique training and models, none of them seem to be building interesting or unique products as a result.&#xA0;</p><p>If your argument is that these things take some time &#x2014; how long do they have?&#xA0;</p><p>No, really! So many of you have said that &#x201C;this is what happens, they burn a bunch of money, they grow, and then&#x2026;&#x201D; and then you stop short because the next thing you say is &#x201C;turn profitable by getting enterprise customers.&#x201D; Nobody can do the first part and few can do the second part in anything approaching a consistent fashion.&#xA0;</p><p>But really, how long should we give them? Three years?&#xA0;</p><p>Perplexity&#x2019;s had three years and a billion dollars, it doesn&#x2019;t seem to be close to profitable. How long does Perplexity deserve, exactly? An eternity?&#xA0;</p><p>Every single example of a company that has &#x201C;burned a lot of money and then not done so in the end&#x201D; has been a company with a physical thing or connections to the real world, with the exception of Facebook, which was never the kind of cash-burning monstrosity that generative AI is.&#xA0;</p><p>There has never been a software company that has just chewed through hundreds of millions &#x2014; or billions &#x2014; of dollars and then suddenly became profitable, mostly because the magical valuations of software have been in their ability to transcend infrastructure. One&#x2019;s unit economics in the sales of software like Microsoft Office or providing access to Instagram do not require the most powerful graphics processing units run at full tilt at all times, and those are products that people like and want to use every day.&#xA0;</p><p>I get people saying &#x201C;they&#x2019;re in the growth stage!&#x201D; about a few companies, but when all of them are unprofitable, and even the unprofitable ones outside of OpenAI and Anthropic aren&#x2019;t really making impressive amounts of money anyway? C&#x2019;mon! This isn&#x2019;t anything like any boom that leads to something, and it&#x2019;s because the economics do not make sense.</p><p>And that&#x2019;s before we get to OpenAI and Anthropic!</p><h2 id="openai-and-anthropic-and-the-impossible-road-ahead">OpenAI and Anthropic, And The Impossible Road Ahead</h2><p>So, as a reminder, OpenAI appears to have burned at least ten billion dollars in the last two months. <a href="https://www.cnbc.com/2025/08/01/openai-raise-chatgpt-users.html?ref=wheresyoured.at"><u>It is has just raised another $8.3 billion dollars</u></a> (<a href="https://www.nytimes.com/2025/08/01/business/dealbook/openai-ai-mega-funding-deal.html?ref=wheresyoured.at"><u>after raising $10 billion in <em>June</em> according to the New York Times</u></a>), and intends to receive around $22.5 billion by the end of year from SoftBank, and that is assuming it becomes a for-profit entity by the end of the year, and if that doesn&#x2019;t happen, the round gets cut to $20 billion total, meaning that SoftBank would only be on the hook for a further $1.7 billion.</p><p>I am repeating myself, but I need you to really get this:<strong> OpenAI <em>just got $10 billion in June 2025, and had to raise another $8.3 billion in August 2025. </em></strong>That is an unbelievable cash burn, one dwarfing any startup in history, rivalled only by xAI, makers of &#x201C;Grok, the racist LLM,&#x201D; <a href="https://finance.yahoo.com/news/musks-13b-ai-gamble-xai-164425784.html?ref=wheresyoured.at"><u>losing it over $1 billion a month</u></a>.</p><p>I should be clear that if OpenAI does not convert to a for-profit, there is no path forward. To continue raising capital, OpenAI must have the promise of an IPO. It <em>must go public</em>, because at a valuation of $300 billion, OpenAI can no longer be acquired, because nobody has that much money and, if let&#x2019;s be real, nobody actually believes OpenAI is worth that much. The only way to prove that anybody does is to take OpenAI public, and that will be impossible if it cannot convert.</p><p>And, ironically, Softbank&#x2019;s large and late-stage participation makes any exit harder, as early investors will see their holdings diluted as a percentage of total equity &#x2014; or whatever the hell we&#x2019;re calling it. While a normal company could just issue equity, and deal with the dilution that way, OpenAI&#x2019;s structure necessitates a negotiation where companies can obstruct the entire process if they see fit.&#xA0;</p><p>Speaking of companies that might obstruct that transition, let&#x2019;s talk about Microsoft.&#xA0; <a href="https://www.wheresyoured.at/why-did-microsoft-invest-in-openai/"><u>As I asked in my premium newsletter a few weeks ago</u></a>, what if Microsoft <em>doesn&#x2019;t</em> want OpenAI to convert? It owns all the IP, it owns access to all OpenAI&#x2019;s research, and already runs most of its infrastructure. While &#x2014; assuming a best-case scenario &#x2014; that it would end up owning a massive chunk of the biggest tech startup of all time (I&#x2019;m talking about equity, not OpenAI&#x2019;s current profit-sharing units), Microsoft might also believe that it stands more to gain by letting AI die and assuming its role in the AI ecosystem.&#xA0;</p><p><a href="https://en.wikipedia.org/wiki/Embrace,_extend,_and_extinguish?ref=wheresyoured.at"><u>Embrace. Extend. Extinguish.&#xA0;</u></a></p><p>But let&#x2019;s assume it converts, and OpenAI now&#x2026;has to continue raising money at a rate that will require it, allegedly, to <em>only</em> need to raise $17 billion in 2027.&#xA0;</p><p>That number doesn&#x2019;t make sense, considering it already had to bring forward its $8.3 billion fundraise by at least three months, but let&#x2019;s stick with that idea. OpenAI believes it will be profitable, somehow, by 2030, and even if we assume that, that means it intends to burn over a hundred billion dollars to get there.</p><p>Is the plan to take OpenAI public, dumping a toxic asset onto the public markets, only to let it flounder and convulse and die for all to see? Can you imagine OpenAI&#x2019;s S-1? How well do you think this company would handle a true financial audit from a major accounting firm?&#xA0;</p><p>If you want to know what that looks like, google &#x201C;WeWork,&#x201D; which went from tech industry darling to joke in a matter of days, in part because it was forced to disclose <em>how bad things actually were</em> on its S-1. No, really, <a href="https://www.cnbc.com/2019/08/17/wework-ipo-filing-strangest-and-most-alarming-things.html?ref=wheresyoured.at"><u>read this article</u></a>.</p><p>With that in mind, I feel similarly about Anthropic. Nobody is buying this company at $<a href="https://www.bloomberg.com/news/articles/2025-07-29/anthropic-nears-deal-to-raise-funding-at-170-billion-valuation?ref=wheresyoured.at"><u>170 billion</u></a>, and thus the only way to access liquidity would be to take it public, and show the world how a company that made <a href="https://www.reuters.com/technology/artificial-intelligence/anthropic-raise-2-bln-deal-valuing-ai-startup-60-bln-wsj-reports-2025-01-07/?ref=wheresyoured.at"><u>$72 million in January </u></a>2025 and then <a href="https://www.theinformation.com/articles/anthropic-revenue-pace-nears-5-billion-run-mega-round?rc=kz8jh3&amp;ref=wheresyoured.at"><u>more than $400 million in July 2025</u></a> also loses $3 billion or more after revenue, and then let the market decide on its fair price.&#xA0;</p><h2 id="no-really-what%E2%80%99s-the-plan">No, Really, What&#x2019;s The Plan?</h2><p>The arguments against my work always come down to &#x201C;costs will go down&#x201D; and &#x201C;these products will become essential.&#x201D; Outside of ChatGPT, there&#x2019;s really no proof that these products are anything remotely essential, and I argue there&#x2019;s very little about ChatGPT that Microsoft couldn&#x2019;t provide with rate limits via Copilot.&#xA0;</p><p>I&#x2019;d also argue that &#x201C;essential&#x201D; is a very subjective term. Essential &#x2014; in the sense that some people use it as search &#x2014; doesn&#x2019;t mean that it&#x2019;s useful for enterprises, or the majority of people.&#xA0;</p><p>And, I guess, <a href="https://fortune.com/2025/08/01/openai-funding-oversubscribed-early-investors-new-partners-dragoneer/?ref=wheresyoured.at"><u>ChatGPT somehow makes $1 billion a month in revenue</u></a> selling access to premium versions of ChatGPT &#x2014; though I&#x2019;m not 100% sure how. Assuming it has 20 million customers paying $20 a month, that&#x2019;s $400 million a month, then 5 million business customers paid an average of $100 each, that&#x2019;s $900 million&#x2026;and is that average really that good? Are that many people paying $35 a month, or $50, or $200? OpenAI doesn&#x2019;t break out the actual revenues behind these numbers for a reason, and I believe that reason is &#x201C;they don&#x2019;t look as good.&#x201D;</p><p>What&#x2019;s OpenAI&#x2019;s churn like? And does it really, <a href="https://www.wheresyoured.at/howmuchmoney/"><u>as I wrote last week</u></a>, end the year making more than Spotify at $1.5 billion a month?&#xA0;</p><p>We don&#x2019;t know, and OpenAI (much like Anthropic) has never shared actual revenues, choosing instead to leak to the media and hope to obfuscate the actual amounts of money being spent on its services.&#xA0;</p><p>Anyway, long story short, these companies are unprofitable with no end in sight, don&#x2019;t even make that much money in most cases, are valued more than anybody would ever buy them for, do not have much in the way of valuable intellectual property, and the two biggest players burn billions of dollars more than they make.</p><h3 id="but-ed-the-government-will-give-them-money-forever">But Ed! The Government Will Give Them Money Forever!</h3><p>Even if this were going to happen &#x2014; it will not! &#x2014; who would they give the money to and for how long? Would they give it to all the startups? Is every startup going to get a Paycheck Protection Program but for generative AI? How would that play out in rural red districts (where big tech has never been popular), which are being hit with both massive cuts to welfare, as well as the shockwaves of a trade war that has made American agricultural exports (like feedstocks, which previously went to China by the shipload) less appealing worldwide?&#xA0;</p><p>So they bail out OpenAI, then stuff it full of government contracts to the tune of $15 billion a year, right? Sorry, just to be clear, that&#x2019;s the low end of what this would take to do, and they&#x2019;ll have to keep doing it forever, until Sam Altman can build enough data centers to&#x2026;keep burning billions, because there&#x2019;s no actual plan to make this profitable.&#xA0;</p><p>Say this happens. Now what? America has a bullshit generative AI company attached to the state that doesn&#x2019;t really innovate and doesn&#x2019;t really matter in any meaningful way, except that it owns a bunch of data centers?&#xA0;</p><p>I don&#x2019;t think this happens! I think this is a silly idea, and the most likely situation would be that Microsoft would unhinge its jaw and swallow OpenAI and its customers whole. Hey,<a href="https://x.com/semianalysis_/status/1950999038867730764?ref=wheresyoured.at"><u>did you know that Microsoft&#x2019;s data center construction is down year-over-year</u></a>, and it&#x2019;s basically signed no new data center leases? I wonder why it isn&#x2019;t building these new data centers for OpenAI? Who knows.&#xA0;</p><p>Stargate isn&#x2019;t saving it, either. As I wrote previously, <a href="https://www.wheresyoured.at/softbank-openai/"><u>Stargate doesn&#x2019;t actually exist beyond the media hype it generated</u></a>.</p><p>And yes, <a href="https://www.bloomberg.com/news/articles/2025-08-06/openai-offers-chatgpt-for-1-a-year-to-us-government-workers?ref=wheresyoured.at" rel="noreferrer">OpenAI is offering ChatGPT at $1 for a year to US government workers</a> - and I cannot express how little this means other than that they are horribly desperate. This product doesn&apos;t do enough to make it essential, and this fire sale doesn&apos;t change anything. </p><p>Anyway, does the government do this for everybody? Because everyone else is gonna need it as none of these companies can go public as they all suffer from the burden of generative AI. And, if the government does it, will it also subsidize the compute of for-profit companies like Cursor? To what end? Where is the limit?</p><h2 id="what-if-generative-ai-just-isn%E2%80%99t-profitable">What If Generative AI Just Isn&#x2019;t Profitable?&#xA0;</h2><p>I think this is a question that we have to seriously consider at this point, because its ramifications are significant.</p><p>If I&#x2019;m honest, I think the future of LLMs will be client-side on egregiously-expensive personal setups for enthusiasts, and in a handful of niche enterprise roles. Large Language Models do not scale profitably, and their functionality is not significant enough to justify the costs of running them. By immediately applying old economics &#x2014; the idea that you would pay a monthly fee to have relatively-unlimited access &#x2014; companies like OpenAI and Anthropic immediately trained users to use their products in a way that was antithetical to their costs.&#xA0;</p><p>Then again, had these models been served in a way that was mindful of their costs, there would likely have been no way to even get this far. If OpenAI is making a billion dollars a month, it is possibly losing that much (or more) after revenue, and that&#x2019;s the money it can get selling the product in a form that can never turn profitable. If OpenAI charged in line with its actual costs, would it even be able to justify a freely-available version of ChatGPT, outside of a few free requests?&#xA0;</p><p>The revenue you see today is what people are willing to pay for a product that loses money, and I cannot imagine they would pay as much if the companies in question charged their costs. If I&#x2019;m wrong, Cursor will be just fine, and that&#x2019;s assuming that Cursor&#x2019;s current hobbled form is even profitable, which it has not said it is.</p><p>So, you&#x2019;ve got an entire industry of companies that struggle to do anything other than lose a lot of money. Great.&#xA0;</p><p>And now we have a massive expansive data centre buildout, the likes of which we&#x2019;ve never seen, all to capture demand for a product that nobody makes much money selling.</p><p>This, naturally, leads to an important question: how do these people building data centers actually make money?</p><h2 id="data-center-developers-aren%E2%80%99t-making-money-on-ai-either-and-big-tech%E2%80%99s-capex-is-the-majority-of-%E2%80%9Cai-capex%E2%80%9D">Data Center Developers Aren&#x2019;t Making Money On AI Either, And Big Tech&#x2019;s Capex Is The Majority Of &#x201C;AI Capex&#x201D;</h2><p>Last week, <a href="https://www.wsj.com/tech/ai/silicon-valley-ai-infrastructure-capex-cffe0431?mod=author_content_page_1_pos_1&amp;ref=wheresyoured.at"><u>the Wall Street Journal published one of the more worrying facts I&#x2019;ve seen in the last two years:</u></a></p><blockquote><em>Investor and tech pundit Paul Kedrosky says that, as a percentage of gross domestic product, spending on AI infrastructure has already exceeded spending on telecom and internet infrastructure from the dot-com boom&#x2014;and it&#x2019;s still growing. He also argues that one explanation for the U.S. economy&#x2019;s ongoing strength, despite tariffs, is that spending on IT infrastructure is so big that it&#x2019;s acting as a sort of private-sector stimulus program.&#x2026;Capex spending for AI contributed more to growth in the U.S. economy in the past two quarters than all of consumer spending, says Neil Dutta, head of economic research at Renaissance Macro Research, citing data from the Bureau of Economic Analysis.<br><br>A global accounting of this infrastructure spending would be even bigger, as it would include capex from these companies&#x2019; most important partners. Foxconn has recently spent big building out factories for Apple in India, which just supplanted China as the source of the majority of U.S.-destined iPhones, according to Canalys. And the world&#x2019;s largest chip manufacturer, TSMC, spent about $10 billion on capex in its most recent quarter.</em></blockquote><p>The massive buildout of data centers &#x2014; and the associated physical gear like chips, servers, and raw materials for building them &#x2014; has become a massive, dominant economic force&#x2026;building capacity for an industry that is yet to prove it can make real revenues.&#xA0;</p><p>And no, <a href="https://www.cnbc.com/2025/07/30/microsoft-msft-q4-earnings-report-2025.html?ref=wheresyoured.at"><u>Microsoft talking about its Azure revenue in its last quarterly earnings for the first time is not the same thing</u></a>, as it <a href="https://www.geekwire.com/2025/microsoft-earnings-2/?ref=wheresyoured.at"><u>stopped explicitly stating their AI revenue in January</u></a> (when it was $13 billion annualized).</p><p>Anyway, AI capex allegedly &#x2014; though I have some questions about this figure! &#x2014; <a href="https://www.cautiousoptimism.news/p/people-are-worried-about-the-cost?ref=wheresyoured.at"><u>accounts for 1.2% of the US GDP</u></a> in the first half of the year, and accounted for more than half of the (to quote the Wall Street Journal) &#x201C;already-sluggish&#x201D; 1.2% growth rate of the US economy.&#xA0;</p><p><a href="https://www.wsj.com/economy/the-ai-booms-hidden-risk-to-the-economy-731b00d6?gaa_at=eafs&amp;gaa_n=ASWzDAjwWxWRxNasxsIoaicPhYpm7kiuCYAAHHii2wCYod_8HB6Cb5ej4R0SXIPhYP4%3D&amp;gaa_ts=68912948&amp;gaa_sig=8MMWlPyQcWukZjLy6R03M7NAof_0SIJAaUFuhzBzNwwk0s4iud9l3I8-8THVWPocslUCADw4PCkiNz-Dn-MiPw%3D%3D&amp;ref=wheresyoured.at"><u>Another Wall Street Journal piece published a few days later</u></a> discussed how data center development is souring the free cash flow for big tech, turning them from the kind of &#x201C;asset-light&#x201D; businesses that the markets love into entities burdened by physical real estate and their associated costs:</p><blockquote><em>For years, investors loved those companies because they were &#x201C;asset-light.&#x201D; They earned their profits on intangible assets such as intellectual property, software, and digital platforms with &#x201C;network effects.&#x201D; Users flocked to Facebook, Google, the iPhone, and Windows because other users did. Adding revenue required little in the way of more buildings and equipment, making them cash-generating machines. <br><br>This can be seen in a metric called free cash flow, roughly defined as cash flow from operations minus capital expenditures. It excludes things such as noncash impairment charges that can distort net income. This is arguably the purest measure of a business&#x2019;s underlying cash-generating potential. Amazon, for example, tells investors: &#x201C;Our financial focus is on long-term, sustainable growth in free cash flow.&#x201D; <br><br>&#x2026;<br><br>From 2016 through 2023, free cash flow and net earnings of Alphabet, Amazon, Meta and Microsoft grew roughly in tandem. But since 2023, the two have diverged. The four companies&#x2019; combined net income is up 73%, to $91 billion, in the second quarter from two years earlier, while free cash flow is down 30% to $40 billion, according to FactSet data. Apple, a relative piker on capital spending, has also seen free cash flow lag behind.</em><br></blockquote><p>These numbers are all very scary, and I mean that sincerely, but they also fail to express why. How much was actually spent on AI capex in the US? One would think two different articles on this subject would include that number versus a single quarter&#x2019;s worth, but from my estimates, I expect capital expenditures from the Magnificent Seven alone to crest $200 billion in the first half of 2025, with <a href="https://archive.ph/BfmuH?ref=wheresyoured.at"><u>Axios estimating they&#x2019;d spend around $400 billion this year</u></a>.&#xA0;</p><p>Most articles are drafting off of <a href="http://paulkedrosky.com/honey-ai-capex-ate-the-economy/?ref=wheresyoured.at"><u>a blog from Paul Kedrosky</u></a>, <a href="https://airtable.com/app3KkmHRePl1Mhq2/shrv8k6wRlODtdCLF/tblJPTDXgygC2Vtb4?viewControls=on&amp;ref=wheresyoured.at"><u>who estimates total AI capex</u></a> would be somewhere in the region of $520 billion in total for the year, which felt conservative to me, so I did the smart thing and asked him. Kedrosky noted that these numbers focus entirely on the four big spenders &#x2014; Microsoft, Google, Meta and Amazon, and his own estimated $312 billion capex, and the 1.2% number came from the assumption that the US GDP in 2025 will be around $28 trillion (which, I add, is significantly lower than other forecasts, <a href="https://www.reuters.com/world/us/us-economic-growth-likely-rebounded-q2-with-weak-underlying-details-2025-07-30/?ref=wheresyoured.at"><u>which puts it closer to $30 trillion</u></a>).&#xA0;</p><p>Kedrosky, in his own words, was trying to be conservative, using public data and then building his analysis from there. I, personally, believe his estimate is <em>too</em> conservative &#x2014; because it doesn&#x2019;t factor in the capital expenditures from Oracle, <a href="https://www.theinformation.com/articles/pressure-rises-oracle-finish-openai-data-center?ref=wheresyoured.at"><u>which (along with Crusoe) is building the vast Abilene Texas data center for OpenAI</u></a>, or any private data center developers sinking cash into AI capex.&#xA0;</p><p>When I asked him to elaborate, he estimated that &#x201C;...AI spend, all-in, was around half of 3.0%&#xA0; Q2 real GDP growth, so 2-3x the lower bound, given multipliers, debt, etc. it could be half of US GDP full-year GDP growth.&#x201D;</p><p><em>That&#x2019;s so cool!</em> Half of the US economy&#x2019;s growth came from building data centers for generative AI, which has <a href="https://www.wheresyoured.at/the-haters-gui/#:~:text=The%20Magnificent%207%27s%20AI%20Story%20Is%20Flawed%2C%20With%20%24560%20Billion%20of%20Capex%20between%202024%20and%202025%20Leading%20to%20%2435%20billion%20of%20Revenue%2C%20And%20No%20Profit"><u>the combined revenue</u></a> of a little more than <a href="https://www.databridgemarketresearch.com/reports/global-smartwatch-market?ref=wheresyoured.at"><em><u>the fucking smart watch industry in 2024</u></em></a><em>. </em>&#xA0;</p><p>Another troubling point is that big tech doesn&#x2019;t just buy data centers and then use them, but in many cases pays a construction company to build them, fills them with GPUs and then <strong>leases them from a company that runs them</strong>, meaning that they don&#x2019;t have to personally staff up and maintain them. This creates an economic boom for construction companies in the short term, as well as lucrative contracts for ongoing support&#x2026;<em>as long as the company in question still wants them. </em>While Microsoft or Amazon might <em>use</em> a data center and, indeed, act as if it owns it, ultimately somebody else is holding the bag and the ultimate responsibility for the data centers.</p><p>One such company is QTS, a data center developer that leases to both Amazon and Meta <a href="https://www.nytimes.com/2025/06/02/business/ai-data-centers-private-equity.html?ref=wheresyoured.at"><u>according to the New York Times</u></a>, which was acquired by Blackstone in 2021 for $10 billion. Since then, Blackstone has used commercial mortgage-backed securities &#x2014; I know! &#x2014; <a href="https://www.costar.com/article/376853552/goldman-sachs-leads-2-billion-loan-as-lenders-pile-into-blackstones-qts-data-centers?ref=wheresyoured.at"><u>to raise over $8.7 billion since then to sink into QTS&#x2019; expansion</u></a>, and <a href="https://www.axios.com/2025/07/15/blackstone-ai-data-centers-energy-pennsylvania?ref=wheresyoured.at"><u>as of mid-July said it&#x2019;d be investing $25 billion in AI data centers and energy</u></a>.</p><p>Blackstone, according to the New York Times, sees &#x201C;strong demand from tech companies,&#x201D; who are apparently &#x201C;willing to sign what they describe as airtight leases for 15 to 20 years to rent out data center space.&#x201D;&#xA0;</p><p>Yet the Times also names another problem &#x2014; the &#x201C;unanswered question&#x201D; of how these private equity firms actually exit these situations. Blackstone, KKR and other asset management firms do not buy companies with the intention of syphoning off revenue, but to pump them up and sell them to another company. Much like AI startups, it isn&#x2019;t obvious who would buy QTS at what I imagine would be a $25 billion or $30 billion valuation, meaning that Blackstone would have to take them public. Similarly, <a href="https://www.datacenterdynamics.com/en/news/kkr-signs-50bn-partnership-with-ecp-for-data-center-and-power-development/?ref=wheresyoured.at"><u>KKR&#x2019;s supposed $50 billion partnership with investment firm Energy Capital partners to build data centers and their associated utilities</u></a> does not appear to have much of an exit plan either.</p><p>And let&#x2019;s not forget Oracle, OpenAI, and Crusoe&#x2019;s abominable mess in Abilene Texas, where <a href="https://www.reuters.com/business/oracle-buy-40-billion-nvidia-chips-openais-us-data-center-ft-reports-2025-05-23/?ref=wheresyoured.at"><u>Oracle is paying for the $40 billion of GPUs</u></a> and <a href="https://crusoe.ai/newsroom/crusoe-blue-owl-capital-and-primary-digital-infrastructure-enter-joint-venture?ref=wheresyoured.at"><u>Crusoe is spending $15 billion raised from Blue Owl Capital and Primary Digital infrastructure</u></a> to build data centers for OpenAI, a company that loses billions of dollars a year. Why? So that OpenAI can, allegedly starting in 2028, <a href="https://techcrunch.com/2025/07/22/openai-agreed-to-pay-oracle-30b-a-year-for-data-center-services/?ref=wheresyoured.at"><u>pay Oracle $30 billion a year for compute</u></a>, and yes, I am being fully serious.&#xA0;</p><p>To be clear, <a href="https://www.wheresyoured.at/howmuchmoney/"><u>OpenAI, by my estimates, has only made around $5.26 billion this year</u></a> (and will have trouble hitting its $12.7 billion revenue projection for 2025), and will likely lose more than $10 billion to do so.</p><p>Oracle will, according to The Information, <a href="https://www.theinformation.com/articles/pressure-rises-oracle-finish-openai-data-center?rc=kz8jh3&amp;ref=wheresyoured.at"><u>owe Crusoe $1 billion in payments across the 15 year span of its lease</u></a>. How does Crusoe afford to pay back its $15 billion in loans? Beats me! <a href="https://www.theinformation.com/articles/upstart-crusoes-audacious-plan-take-cloud-giants?rc=kz8jh3&amp;ref=wheresyoured.at"><u>The Information says</u></a> it&#x2019;s raising $1 billion to &#x201C;take on cloud giants&#x201D; by &#x201C;earning construction management fees and rent, and it can sell its stake in the project upon reaching certain completion milestones,&#x201D; while also building its own AI compute, making the assumption that the demand is there outside of hyperscalers.</p><p>Then there&#x2019;s CoreWeave, my least-favourite company in the world. As I discussed a few months ago, <a href="https://www.wheresyoured.at/core-incompetency/#:~:text=Problem%20Loan%20Number%202%3A%20DDTL%202.0"><u>CoreWeave is burdened by obscene debt</u></a> and a horrifying cash burn, and has seen its stock spike to a high of $183 on June 20, 2025 to around $111 as of writing this sentence, which has led to <a href="https://www.ft.com/content/70638957-52e7-4698-8c36-52364034b086?ref=wheresyoured.at"><u>its all-stock attempt to acquire developer Core Scientific for $9 billion to start to fall apart</u></a> as shareholders balk at the worrisome drop in CoreWeave&#x2019;s stock price. CoreWeave has, since going public, had to borrow <a href="https://investors.coreweave.com/news/news-details/2025/CoreWeave-Closes-2-6-Billion-Secured-Debt-Financing-Facility-Strengthening-Market-Position-as-AI-Cloud-Leader/default.aspx?ref=wheresyoured.at"><u>billions</u></a> of <a href="https://investors.coreweave.com/news/news-details/2025/CoreWeave-Expands-Credit-Facility-to-1-5-Billion-to-Support-Continued-Growth/default.aspx?ref=wheresyoured.at"><u>dollars</u></a> to fund its obscene capital expenditures to handle <a href="https://www.cnbc.com/2025/03/10/openai-to-pay-coreweave-11point9-billion-over-five-years-for-ai-tech.html?ref=wheresyoured.at"><u>the upcoming October 2025 start date for OpenAI&#x2019;s $11.9 billion, 5-year-long deal for compute</u></a>, which is also when CoreWeave must start paying off its largest loan. CoreWeave lost $314 million in its last earnings, and I see no path to profitability or, honestly, its ability to keep doing business if the market sours.</p><p>Coreweave, I add, is pretty much reliant on Microsoft as its primary customer. While this relationship has been fairly smooth (so far, and as far as we know), this dependence also presents an existential threat to Coreweave, and is part of the reason why I&#x2019;m so pessimistic about its survival. Microsoft has its own infrastructure, and has every incentive to cut out middlemen when it&apos;s able to meet supply with the demand it itself owns (or leases, rather than subcontracts out), simply because <em>middlemen add costs and shrink margins</em>. If Microsoft walks, what&#x2019;s left? How does it service its ongoing obligations, and its mountain of debt?&#xA0;</p><p>In all of these cases, data center developers seem to have very few options as to <em>making actual money.</em> We have companies spending billions of dollars to vastly expand their data center footprint, but very little evidence that doing so results in <em>revenue</em> let alone some sort of payoff, and similarly, the actual capital expenditures they&#x2019;re making are&#x2026;much smaller than those of big tech.&#xA0;</p><p>Digital Realty Trust &#x2014; one of the largest developers with over 300 data centers worldwide and <a href="https://www.macrotrends.net/stocks/charts/DLR/digital-realty-trust/revenue?ref=wheresyoured.at"><u>$5.55 billion in revenue in 2024</u></a> &#x2014; <a href="https://investor.digitalrealty.com/news/news-details/2025/Digital-Realty-Reports-Second-Quarter-2025-Results/default.aspx?ref=wheresyoured.at"><u>only spent $3.5 billion in capex last quarter</u></a>, and Equinix (<a href="https://www.equinix.com/newsroom/press-releases/2025/02/equinix-reports-strong-fourth-quarter-and-full-year-2024-results?ref=wheresyoured.at"><u>$8.7 billion revenue in 2024</u></a>), which has 270 of them, <a href="https://www.equinix.com/newsroom/press-releases/2025/07/equinix-reports-second-quarter-2025-results?ref=wheresyoured.at"><u>put capex at $3.5 billion too</u></a>. NTT Global Data Centers, which has over 160 data centers, <a href="https://services.global.ntt/en-us/newsroom/ntt-data-expands-global-data-centers-in-2024-with-bold-investments-and-industry-first-innovations?ref=wheresyoured.at"><u>has dedicated $10 billion in capital expenditures &#x201C;through 2027&#x201D; to build out data centers</u></a>.&#xA0;</p><p>Yet in many of these cases, it&#x2019;s because these companies are &#x2014; to quote a source of mine &#x2014; &#x201C;functionally obsolete for this cycle,&#x201D; because legacy data centers are not plug-and-play ready for GPUs to slot into. Any investment in capex by these companies would have to be for both GPUs <em>and either building or retrofitting (basically ripping the insides out of old) data centers.</em></p><p>This means that the money flowing into AI data centers is predominantly going to neoclouds like CoreWeave and Crusoe, and all seems to flow back to private equity firms that never thought about where the cashout might be. <a href="https://www.blackstone.com/news/press/coreweave-secures-7-5-billion-debt-financing-facility-led-by-blackstone-and-magnetar/?ref=wheresyoured.at"><u>Blackstone led CoreWeave&#x2019;s $7.5 billion loan with Magnetar Capital</u></a>, and <a href="https://crusoe.ai/newsroom/crusoe-and-tallgrass-announce-ai-data-center-in-wyoming/?ref=wheresyoured.at"><u>Crusoe signed a deal a week ago with infrastructure firm Blackstone-owned Tallgrass to build a data center in Wyoming</u></a>, all of which seems very good for Blackstone unless you think &#x201C;how does it actually make money here,&#x201D; as private equity firms do not generally like to hold assets longer than five years.&#xA0;</p><p>Even if it did, its capital expenditures are a drop in the bucket in the grand scheme of things. Assuming Crusoe burns, as <a href="https://www.theinformation.com/articles/upstart-crusoes-audacious-plan-take-cloud-giants?rc=kz8jh3&amp;ref=wheresyoured.at"><u>The Information suggests it will</u></a>, as much as $4 billion in 2025, CoreWeave spends as much as $20 billion, Digital Realty Trust spends $14 billion, Global Data Centers spends $3.33 billion (that&#x2019;s $10bn over 3 years), and Equinix spends $14 billion. <strong>That&#x2019;s $55.33 billion in AI capex spent in 2025 from the largest developers of data centers in the world.</strong></p><p>For some context, as discussed above, $102 billion was spent by Meta, Alphabet, Microsoft and Amazon <strong><em>in the last quarter.&#xA0;</em></strong></p><p>Private equity may ultimately face the same problem as many AI startups: there is no clear exit strategy for these investments. In the absence of real liquidity, firms will likely resort to all manner of financial engineering (read: bullshit) &#x2014;marking up portfolio companies using internally generated valuations, charging fees on those inflated marks, and using those marks to entice new commitments from limited partners.</p><p>Compounding this is their ability to lend increasing amounts of capital to their own portfolio companies via affiliated private credit vehicles&#x2014;effectively recycling capital and pushing valuation risk further down the line. This kind of self-reinforcing leverage loop is particularly opaque in private credit, which now underpins much of the AI infrastructure buildout. The complexity of these arrangements makes it hard to anticipate the full economic fallout if the cycle breaks down, but the systemic risk is building.</p><p>In any case, the supposed &#x201C;AI capex boom&#x201D; that is driving the US economy is not, as reported, driven by the massive interest in building out AI infrastructure for a variety of customers.&#xA0;</p><p>The reality is simple: <strong>the majority of all AI capex is from big tech, which is a massive systemic weakness in our economy.</strong></p><h2 id="big-tech-has-become-a-systemic-weakness-in-the-us-economy-and-markets">Big Tech Has Become A Systemic Weakness In The US Economy (and Markets)</h2><p>While some might say that &#x201C;AI capex&#x201D; has swallowed the US economy, I think it&#x2019;s more appropriate to say that <strong>Big Tech Capex Has Swallowed The US Economy.</strong></p><p>I also want to be clear that the economy &#x2014; which is the overall state of the country&#x2019;s production and consumption of <em>stuff, </em>and the flow of money between participants in said economy &#x2014; and the markets (as in the stock market) are very different things, but the calculations from Kedrosky and others have now allowed us to see where one might hit the other.</p><p>You see, the markets do not actually represent<em> reality</em>. While Microsoft, Amazon, Google, and Meta might <em>want</em> you to think there&#x2019;s a ton of money in AI, their growth is mostly from selling further iterations and contracts for their existing stuff, or in the case of Meta further increasing its ad revenue. The economy is where things are actually bought and sold, representing the economic effects of both the things happening to build out AI and selling access to services and the AI models themselves. I recognize this is simplistic, but I am laying it out for a reason.</p><p><a href="https://www.wheresyoured.at/the-haters-gui/"><u>As I discussed at length in the Hater&#x2019;s Guide to the AI Bubble</u></a>, NVIDIA is the weak point in the stock market, representing roughly 19% of the value of the Magnificent 7, which in turn makes up about 35% of the value of the US stock market. The associated Magnificent Seven stocks have seen a huge boom through their own growth, which has been mistakenly and incorrectly attributed to revenue from AI, which as I laid out previously, is about $35 to $40 billion in the last two years. Nevertheless, the markets can continue to be irrational because all they care about is &#x201C;number going up,&#x201D; as the &#x201C;value&#x201D; of a stock is oftentimes disconnected from the value of the company itself, instead associated with its propensity for growth.</p><p>GDP and other measurements of the <em>economy</em> aren&#x2019;t really something you can fudge quite as easily (<a href="https://www.stlouisfed.org/publications/regional-economist/second-quarter-2017/chinas-economic-data-an-accurate-reflection-or-just-smoke-and-mirrors?ref=wheresyoured.at"><u>at least, in transparent, democratic societies</u></a>), nor can you say a bunch of fancy words to make people feel better in the event that growth stalls or declines.&#xA0;</p><p>This leads me to my principle worry: that &#x201C;AI capex&#x201D; is actually a term for the expenditures of four companies, namely Microsoft, Amazon, Google and Meta, with NVIDIA&#x2019;s GPU sales being part of that capex too.</p><p>While we can include others like Oracle, Musk&#x2019;s xAI, and various Neoclouds like CoreWeave and Crusoe &#x2014; who, according to D.A. Davidson&#x2019;s Gil Luria, will account for about 10% of NVIDIA&#x2019;s GPU sales in 2025 &#x2014; the reality is that whatever economic force is being driven by &#x201C;AI investment&#x201D; is really just four companies building and leasing data centers to burn on generative AI, a product that makes a relatively small amount of money before losing a great deal more.&#xA0;</p><p>42% of NVIDIA&#x2019;s revenue comes from the Magnificent Seven (<a href="https://finance.yahoo.com/news/big-techs-spending-drove-nvidias-rise-154027146.html?ref=wheresyoured.at"><u>per Laura Bratton at Yahoo Finance</u></a>), which naturally means that big tech is the lynchpin of investment in data centers.&#xA0;</p><figure class="kg-card kg-image-card"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXe1Z3Zf18no9qOBqpdP_7qsnJUHnihvD9EeHs3oR5oG_PDamazN0qnaZFUumzQeEFXHRSZ8OQNqCWx0W_g44zz1nVGu8Z1RF70UzunkJIyHrnEtVvvi5exr06P03wwtvAxIhgrrKw?key=t9VmGsYY_q-emQtACD1u0w" class="kg-image" alt loading="lazy" width="400" height="351"></figure><p>I&#x2019;ll put it far more simply: if AI capex represents such a large part of our GDP and economic growth, our economy does, on some level, rest on the back of Microsoft, Google, Meta and Amazon and their continued investment in AI. What should worry everybody is that Microsoft &#x2014; which makes up 18.9% of NVIDIA&#x2019;s revenue &#x2014; <a href="https://x.com/SemiAnalysis_/status/1950999038867730764?ref=wheresyoured.at"><u>has signed basically no leases in the last 12 months, and its committed datacenter construction and land purchases are down year-over-year</u></a>.&#xA0;</p><p>While its capex may not have dipped yet (in part because the chip-heavy nature of generative AI means that capex isn&#x2019;t exclusively dominated by property), <em>it&#x2019;s now obvious that if it does there will be direct effects on both the US economy and stock market, as Microsoft is part of what amounts to a stimulus package propping up America&#x2019;s economic growth.</em>&#xA0;</p><p>And not to repeat the point too much,<em> but big tech has yet to actually turn anything resembling a profit on these data centers, and isn&#x2019;t making much revenue at all out of generative AI.</em></p><p>How, exactly, does this end? What is the plan here? Is big tech going to spend hundreds of billions a year in capital expenditures on generative AI in perpetuity? Will they continue to buy more and more NVIDIA chips as they do so?&#xA0;</p><p>At some point, surely these companies have built enough data centers? Surely, at some point, they&#x2019;ll run out of space to put these GPUs in? Is the plan to, by then, make so much money from AI that it won&#x2019;t matter? What does NVIDIA do at that point? And how does the US economy rebound from the loss of activity that follows?</p><hr><p>As I&#x2019;ve said again and again, the generative AI bubble is, and always has been, fundamentally irrational, and inherently gothic, playing in the ruins, patterns and pathways of previous tech booms despite this one having little or no resemblance to them. Though the tech industry loves to talk about building a glorious future, its present is one steeped in rituals of decay and death, where the virtues of value creation and productivity take a backseat to burning billions and lying to the public <a href="https://arstechnica.com/ai/2025/01/anthropic-chief-says-ai-could-surpass-almost-all-humans-at-almost-everything-shortly-after-2027/?ref=wheresyoured.at"><u>again</u></a> and <a href="https://www.pcgamer.com/software/ai/deepmind-ceo-makes-big-brain-claims-saying-agi-could-be-here-in-the-next-five-to-10-years-and-that-humanity-will-see-a-change-10-times-bigger-than-the-industrial-revolution-and-maybe-10-times-faster/?ref=wheresyoured.at"><u>again</u></a> and <a href="https://www.theverge.com/decoder-podcast-with-nilay-patel/673638/google-ceo-sundar-pichai-interview-ai-search-web-future?ref=wheresyoured.at"><u>again</u></a>. The way in which the media has participated in these lies is disgusting.</p><p>Venture capital, still drunk off the fumes of 2021, keeps running the old playbook: shove as much money into a company as possible in the hopes you can dump it onto an acquirer or the public markets, only to get high on their own supply, pushing valuations to the point that there is no possible liquidity event for the majority of big private AI companies as a result of their overstuffed valuations, burdensome business models and lack of any real intellectual property.</p><p>And, like the rest of the AI bubble, Silicon Valley&#x2019;s only liquidity path out of the bubble is big tech itself. Without Google, <a href="http://character.ai/?ref=wheresyoured.at"><u>Character.ai</u></a> and Windsurf&#x2019;s founders would likely have been left for dead, and the same goes for Inflection, and I&#x2019;d even argue Scale AI, <a href="https://www.cnbc.com/2025/06/12/scale-ai-founder-wang-announces-exit-for-meta-part-of-14-billion-deal.html?ref=wheresyoured.at"><u>whose $14.3 billion &#x201C;investment&#x201D; from Meta</u></a> effectively decapitated the company, removing its CEO Alexandr Wang, leaving the rest of the company to die, <a href="https://www.sfchronicle.com/tech/article/scale-ai-layoffs-meta-investment-20774897.php?ref=wheresyoured.at"><u>laying off 14% of its staff and 500 contractors </u></a>mere weeks after its CEO and investors cashed in.&#xA0;</p><p>In fact, generative AI is turning out to be a fever dream entirely made up by big tech. OpenAI would be dead if it wasn&#x2019;t for the massive infrastructure provided by Microsoft <a href="https://www.theinformation.com/articles/why-openai-could-lose-5-billion-this-year?ref=wheresyoured.at&amp;rc=kz8jh3"><u>at-cost</u></a> in return for rights to its IP, research, and the ability to sell its models on top of the tens of billions of dollars of venture capital thrown into its billion-dollar cash incinerator. Anthropic would be dead if both <a href="https://www.nytimes.com/2025/03/11/technology/google-investment-anthropic.html?ref=wheresyoured.at"><u>Google</u></a> and <a href="https://www.nytimes.com/2025/06/24/technology/amazon-ai-data-centers.html?ref=wheresyoured.at"><u>Amazon</u></a> &#x2014; the latter of which provides much of its infrastructure &#x2014; hadn&#x2019;t invested billions in keeping it alive so that it can burn $3 billion or more in 2025 <a href="https://www.wheresyoured.at/anthropic-and-openai-have-begun-the-subprime-ai-crisis/"><u>while fucking over its enterprise customers</u></a> and <a href="https://x.com/AnthropicAI/status/1949898502688903593?ref=wheresyoured.at"><u>rate limiting the rest</u></a>.&#xA0;</p><p>The generative AI industry is, at its core, unnatural. It does not make significant revenue compared to its unbelievable costs, nor does it have much revenue potential. It requires, unlike just about every software revolution, an unbelievable amount of physical infrastructure to run, and because nobody but big tech can afford to build the infrastructure necessary, creates very little opportunity for competition or efficiency. As the markets are in the throes of the <a href="https://www.wheresyoured.at/the-rot-economy/"><u>growth-at-all-costs Rot Economy,</u></a><em></em>they have failed to keep big tech in line, conflating big tech&#x2019;s ability to grow with growth driven as a result of their capital expenditures. Sensible, reasonable markets would notice the decay of free cash flow or the ridiculousness of big tech&#x2019;s capex bonanza, but instead they clap and squeal every time Satya Nadella jingles his keys.</p><p>What is missing is any real value generation. Again, I tell you, <em>put aside any feelings you may have about generative AI itself</em>, and focus on the actual economic results of this bubble. How much revenue is there? Why is there no profit? Why are there no exits? Why does big tech, which has sunk <em>hundreds of billions of dollars into generative AI,</em> not talk about the revenues they&#x2019;re making? Why, for three years straight, have we been asked to &#x201C;just wait and see,&#x201D; and for how long are we going to have to wait to see it?</p><p>What&#x2019;s incredible is that the inherently compute-intensive nature of generative AI basically requires the construction of these facilities, without actually representing whether they are contributing to the revenues of the companies that operate the models (like Anthropic or OpenAI, or any other business that builds upon them). As the models get more complex and hungry, more data centers get built &#x2014; which hyperscalers book as long-term revenue, even though it&#x2019;s either subsidised by said hyperscalers, or funded by VC money. This, in turn, stimulates even more capex spending. And without having to answer any basic questions about longevity or market fit.&#xA0;</p><p>Yet the worst part of this financial farce is that we&#x2019;ve now got a built-in economic breaking point in the capex from AI. At some point capex <em>has</em> to slow &#x2014; if not because of the lack of revenues or massive costs associated, but because <em>we live in a world with finite space</em>, and when said capex slow happens, so will purchases of NVIDIA GPUs, which will in turn, as proven by Kedrosky and others, slow America&#x2019;s economic growth.</p><p>And that growth <em>is pretty much based on the whims of four companies, which is an incredibly risky and scary proposition.</em> I haven&#x2019;t even dug into the wealth of private credit deals that underpin buildouts for private AI &#x201C;neoclouds&#x201D; like CoreWeave, Crusoe, Nebius, and Lambda, in part because their economic significance is so much smaller than big tech&#x2019;s ugly, meaningless sprawl.&#xA0;</p><p><a href="https://paulkedrosky.com/honey-ai-capex-ate-the-economy/?ref=wheresyoured.at"><u>To quote Kedrosky</u></a>:&#xA0;</p><blockquote>We are in a historically anomalous moment. Regardless of what one thinks about the merits of AI or explosive datacenter expansion, the scale and pace of capital deployment into a rapidly depreciating technology is remarkable. These are not railroads&#x2014;we aren&#x2019;t building century-long infrastructure. AI datacenters are short-lived, asset-intensive facilities riding declining-cost technology curves, requiring frequent hardware replacement to preserve margins.</blockquote><p>You can&#x2019;t bail this out, because there is nothing <em>to</em> bail out. Microsoft, Meta, Amazon and Google have plenty of money and have proven they can spend it. NVIDIA is already doing everything it can to justify people spending more on its GPUs. There&#x2019;s little more it can do here other than soak up the growth before the party ends.&#xA0;</p><p>That capex reduction will bring with it a reduction in expenditures on NVIDIA GPUs, which will take a chunk out of the US stock market. Although the stock market isn&#x2019;t the economy, the two things are inherently linked, and the popping of the AI bubble will have downstream ramifications, just like the dot com bubble did on the wider economy.</p><p>Expect to see an acceleration in layoffs and offshoring, in part driven by a need for tech companies to show &#x2014; for the first time in living memory &#x2014; fiscal restraint. For cities where tech is a major sector of the economy &#x2014; think Seattle and San Francisco &#x2014; there&#x2019;ll be knock-on effects to those companies and individuals that support the tech sector (like restaurants, construction companies building apartments, Uber drivers, and so on). We&#x2019;ll see a drying-up of VC funding. Pension funds will take a hit &#x2014; which will affect how much people have to spend in retirement. It&#x2019;ll be grim.&#xA0;</p><p>Worse than that is the fact that these data centers will be, by definition, non-performing assets, and one that inflicted an opportunity cost that&#x2019;ll be almost impossible to calculate. While a house, once built and sold, technically falls into that category (it doesn&#x2019;t add to any economic productivity), people at least need somewhere to live. Shelter is an essential component of life. You can live without a data center the size of Manhattan.&#xA0;</p><p>What would have happened if companies like Microsoft and Meta instead spent the money on things that actually drove productivity, or created a valuable competitive business that drove economic activity? Hell, even if they just gave everyone a 10% raise, it would have likely been better for the economy than this, if we&#x2019;re factoring in things like consumer spending.&#xA0;</p><p>It&#x2019;s just waste. Profligate, pointless waste.&#xA0;</p><p>In summary, we&#x2019;re already facing the prospect of a recession, and though I am not an economist, I can imagine it being a particularly nasty one given that <a href="https://www.paceretfs.com/resources/resource-library/is-the-market-being-hijacked-by-the-magnificent-seven?utm_source=openai"><u>the Magnificent Seven accounted for 47.87% of the Russell 1000 Index&#x2019;s returns in 2024</u></a>. Even if big tech somehow makes this crap profitable, it&#x2019;s hard to imagine that they&#x2019;ll counterbalance any capex reduction with revenue, because there doesn&#x2019;t seem to be that much revenue in generative AI to begin with.</p><p>This is what happens when you allow the Rot Economy to run wild, building the stock market and tech industry on growth over <em>everything else.</em> This is what happens when the tech media repeatedly fails to hold the powerful to account, catering to their narratives and making excuses for their abominable, billion-dollar losses and mediocre, questionably-useful products.&#xA0;</p><p>Waffle on all you want about the so-called &#x201C;agentic era&#x201D; or &#x201C;annualized revenues&#x201D; that make you hot under the collar &#x2014; I see no reason for celebration about an industry with no exit plans and needless capital expenditures that appear to be one of the few things keeping the American economy growing.&#xA0;</p><p>I have been writing about the tech industry&#x2019;s obsession with generative AI for two years, and never have I felt more grim. Before this was an economic uncertainty &#x2014; a way that our markets might contract, that big tech might take a big haircut, that a bunch of money might be wasted but otherwise the world would keep turning.&#xA0;</p><p>It feels as if everything is aligning for disaster, and I fear there&#x2019;s nothing that can be done to avert it.&#xA0;</p>]]>
			</content:encoded>
		</item>
		<item>
			<title>
				<![CDATA[How Much Money Do OpenAI And Anthropic Actually Make?]]>
			</title>
			<description>
				<![CDATA[<p><em>Hello and welcome to the latest premium edition of Where&apos;s Your Ed At, I appreciate any and all of your subscriptions. I work very hard on these, and they help pay for the costs of running Ghost and, well, my time investigating different things. If you&apos;re</em></p>]]>
			</description>
			<link>https://www.wheresyoured.at/howmuchmoney/</link>
			<guid isPermaLink="false">688a5f1c0f29f50001e9f391</guid>
			<dc:creator>
				<![CDATA[Edward Zitron]]>
			</dc:creator>
			<pubDate>Fri, 01 Aug 2025 16:20:01 GMT</pubDate>
			<content:encoded>
				<![CDATA[<p><em>Hello and welcome to the latest premium edition of Where&apos;s Your Ed At, I appreciate any and all of your subscriptions. I work very hard on these, and they help pay for the costs of running Ghost and, well, my time investigating different things. If you&apos;re on the fence, subscribe! I promise it&apos;s worth it.</em></p><p><em>I also want to give a HUGE thank you to </em><a href="https://linktr.ee/westinlee?ref=wheresyoured.at" rel="noreferrer"><em>Westin Lee</em></a><em>, a writer who has written about business and the use of AI, who was the originator of the whole &quot;what if we used ARR to work out what these people make?&quot; idea. He&apos;s been a tremendous help, and I recommend you check out his work.</em></p><hr><p>If you&apos;re an avid reader of the business and tech media, you&apos;d be forgiven for thinking that OpenAI has made (or will make) in excess of $10 billion this year, and Anthropic in excess of $4 billion.</p><p>Why? Because both companies have intentionally reported or leaked their &quot;annualized recurring revenue&quot; &#x2013; a month&apos;s revenue multiplied by 12. OpenAI leaked yesterday to The Information that it<a href="https://www.theinformation.com/articles/openai-hits-12-billion-annualized-revenue-breaks-700-million-chatgpt-weekly-active-users?rc=kz8jh3&amp;ref=wheresyoured.at"><u>hit $12 billion in &quot;annual recurring revenue&quot;</u></a> &#x2013; suggesting that its July 2025 revenues were around $1 billion.<a href="https://www.theinformation.com/articles/anthropic-revenue-hits-4-billion-annual-pace-competition-cursor-intensifies?rc=kz8jh3&amp;ref=wheresyoured.at"><u>The Information reported on July 1 2025 that Anthropic&apos;s annual run rate was $4 billion</u></a> &#x2013; meaning that its revenue for the month of June 2025 was around $333 million. Then, yesterday, it reported that the run rate was up to $5 billion.&#xA0;</p><blockquote><strong>As a reminder, both of these companies burn billions of dollars &#x2013; more than $5 billion each in 2024.</strong></blockquote><p>These do not, however, <strong>mean that their previous months were this high, nor do they mean that they&apos;ve &quot;made&quot; anything close to these numbers.</strong> Annualized recurring revenue is one of the most regularly-abused statistics in the startup world, and can mean everything from &quot;[actual month]x12&quot; to &quot;[30 day period of revenue]x12&quot; and in most cases it&apos;s a number that doesn&apos;t factor in churn. Some companies even move around the start dates for contracts as a means of gaming this number.&#xA0;</p><p>ARR, also, doesn&#x2019;t factor seasonality of revenue into the calculations. For example, you&#x2019;d expect ChatGPT to have peaks and troughs that correspond with the academic year, with students cancelling their subscriptions during the summer break. If you use ARR, you&#x2019;re essentially taking one month and treating it as representative of the entire calendar year, when it isn&#x2019;t.&#xA0;</p><blockquote><strong>Sidenote</strong>: I want to make one thing especially obvious. When I described ARR as &#x201C;one of the most regularly-abused statistics in the startup world,&#x201D; I meant it. ARR is only really used by startups (and other non-public companies). It&#x2019;s not considered a GAAP-standard accounting practice, and public companies (those traded on the stock market) generally don&#x2019;t use it because they have to report actual figures, and so there&#x2019;s no point. You can&#x2019;t really obfuscate something that you have to, by law, state publicly and explicitly for all to see with crafty trickery.&#xA0;</blockquote><p>These companies are sharing (or leaking) their annualized revenues for a few reasons:</p><ul><li>So that the tech press reports them in a way that makes it sound like they&apos;ll make that much in a year.</li><li>So that the tech press reports a number that sounds bigger and better than the monthly amount. For example, calling a startup a &quot;$100 million ARR&quot; company (<a href="https://techcrunch.com/2025/07/23/eight-months-in-swedish-unicorn-lovable-crosses-the-100m-arr-milestone/?ref=wheresyoured.at"><u>like vibe-coding platform Lovable</u></a>) sounds way better than calling them an &quot;$8.3 million a month company,&quot; in part because the number is smaller, and in part because, I imagine, it might mislead a reader into believing that&apos;s what they&apos;ve made every month. Yes, saying the ARR figure does that already.</li><li>So that investors will believe the company looks bigger and more successful than it is.</li></ul><p>In any case, I want to be clear this is a standard metric in non-public Software-as-a-Service (SaaS) businesses. Nothing is inherently wrong with the <em>metric,</em> save for its <em>use</em> and what&apos;s being interpreted from it.</p><p>Nevertheless, there has been a <em>lot</em> of reporting on both OpenAI and Anthropic&apos;s revenues that has created incredible confusion in the market that benefits both companies, making them seem far more successful than they really are, and giving them credit for revenue they are yet to book.</p><p>Before I dive into this &#x2014; and yes, before the premium break &#x2014; I want to establish some facts.</p><p><strong>OpenAI:</strong></p><ul><li>Raised:<a href="https://www.crunchbase.com/organization/openai?ref=wheresyoured.at#financials"><u>$31.9 billion</u></a>. Other reporting reports $61.9 billion,<a href="https://www.cnbc.com/2025/03/31/openai-closes-40-billion-in-funding-the-largest-private-fundraise-in-history-softbank-chatgpt.html?msockid=281edec7c2a268a818bdcb14c39b69fd&amp;ref=wheresyoured.at"><u>but it includes $40 billion of its March 2025 round</u></a>, of which only $10 billion has been wired, and $20 billion of which is contingent on OpenAI&apos;s conversion to a for-profit. And that&#x2019;s without mentioning the other variables in play &#x2014; like whether Softbank will be able to fulfill their side of the deal. This number is also further muddied by <a href="https://www.nytimes.com/2025/08/01/business/dealbook/openai-ai-mega-funding-deal.html?ref=wheresyoured.at"><u>OpenAI raising <em>another</em> $8.3 billion</u></a> this week - months ahead of when they were meant to - but this is also supposedly part of that $40 billion.</li><li>Valuation: $300 billion.</li><li>Projected 2024 revenues: $4 billion,<a href="https://www.theinformation.com/articles/anthropic-projects-soaring-growth-to-34-5-billion-in-2027-revenue?ref=wheresyoured.at&amp;rc=kz8jh3"><u>per The Information</u></a>,<a href="https://www.nytimes.com/2024/09/27/technology/openai-chatgpt-investors-funding.html?ref=wheresyoured.at"><u>though a September 2024 story from the New York Times suggested that it had predicted $3.7 billion internally</u></a>.<a href="https://www.cnbc.com/2024/09/27/openai-sees-5-billion-loss-this-year-on-3point7-billion-in-revenue.html?ref=wheresyoured.at"><u>CNBC appears to confirm the &quot;$3.7 billion&quot; number is correct</u></a>, but <em>this article was also written on September 27 2024, and the year ends December 31 2025.</em></li><li>Projected 2025 revenues:<a href="https://www.bloomberg.com/news/articles/2025-03-26/openai-expects-revenue-will-triple-to-12-7-billion-this-year?ref=wheresyoured.at"><u>per Bloomberg</u></a>, OpenAI projects to make $12.7 billion this year.</li></ul><p><strong>Anthropic:</strong></p><ul><li>Raised:<a href="https://www.crunchbase.com/organization/anthropic?ref=wheresyoured.at#financials"><u>$20.7 billion</u></a>,<a href="https://www.cnbc.com/2025/07/29/anthropic-in-talks-to-raise-fresh-capital-at-170-billion-valuation.html?ref=wheresyoured.at"><u>with current plans to raise as much as $5 billion more</u></a>.</li><li>Valuation: If the round above closes, $170 billion (I believe it will).</li><li>Projected 2024 revenues: $918 million, per<a href="https://www.theinformation.com/articles/anthropic-projects-soaring-growth-to-34-5-billion-in-2027-revenue?ref=wheresyoured.at&amp;rc=kz8jh3"><u>The Information</u></a>.</li><li>Projected 2025 revenues:<a href="https://www.theinformation.com/articles/anthropic-projects-soaring-growth-to-34-5-billion-in-2027-revenue?ref=wheresyoured.at&amp;rc=kz8jh3"><u>per The Information</u></a>, Anthropic&apos;s base case (likeliest, according to their reporting) revenue projection is $2 billion, with the &quot;optimistic&quot; projection being $4 billion.</li></ul><p>The intention of either reporting or leaking their annualized revenue numbers was to make you think that OpenAI would hit its projected $12.7 billion revenue number, and Anthropic would hit its &quot;optimistic&quot; $4 billion number, because those &quot;annualized revenue&quot; figures sure seem to have the word &quot;annual&quot; in them.</p><blockquote><strong>A sidenote about ARR, and a potential way my analysis is actually too kind: </strong>In this analysis I have <strong>assumed that OpenAI and Anthropic&apos;s revenues have always gone up.</strong><br><br>Annualized revenue is <strong>a one month snapshot of a business.</strong> Though I have no way of proving it &#x2014; which is why I don&apos;t try! &#x2014; but there is always a chance that one or more of the months I discuss here was <strong>lower</strong> than the following. If I had to speculate, I&#x2019;d wager that the summer months &#x2014; those outside the normal academic calendar &#x2014; see lower subscription revenue for these companies. Nevertheless, we do not have that information, and thus will not factor it into the analysis. But even one &quot;off&quot; month would be bad for either Anthropic or OpenAI.<br><br>I will add that we&apos;ve never had real reporting about OpenAI or Anthropic&apos;s <strong>actual total year revenues before, which is why I am doing my best to work it out.</strong></blockquote><p>Yet through an historic analysis of reported annual recurring revenue numbers over the past three years, I&apos;ve found things to be a little less certain. You see, when a company reports their &quot;annual recurring revenue,&quot; what they&apos;re actually telling you is how much they made in a month, and I&apos;ve sat down and found every single god damn bit of reporting about these numbers, calculating (based on the compound growth necessary between the months of reported monthly revenue) how much these companies are <strong><em>actually making in cash.</em></strong></p><p>My analysis, while imperfect (as we lack the data for certain months), aligns closely enough with projections that I am avoiding any egregious statements. OpenAI and Anthropic&apos;s <em>previous</em> projections were fairly accurate, though as I&apos;ll explain in this piece, I believe their new ones are egregious and ridiculous.</p><p>More importantly, in all of these stories, there was <strong>only one time that these companies shared their revenues &#x2014; </strong>when OpenAI shared its $10 billion runrate in May, though the July $12 billion ARR leak is likely intentional too. In fact, I believe both were an intentional attempt to mislead the general public into believing the company was more successful than it is.</p><p>Based on my analysis, <strong><u>OpenAI made around $3.616 billion in revenue in 2024, and so far in 2025 has made, by my calculations, around $5.266 billion in revenue as of the end of July</u></strong>.</p><p>This is also a slower growth rate than it&#x2019;s experienced so far in the year.<a href="https://www.reuters.com/business/media-telecom/openais-annualized-revenue-hits-10-billion-up-55-billion-december-2024-2025-06-09/?ref=wheresyoured.at"><u>Going from $5.5 billion in annualized revenue in December 2024</u></a> to<a href="https://www.cnbc.com/2025/06/09/openai-hits-10-billion-in-annualized-revenue-fueled-by-chatgpt-growth.html?ref=wheresyoured.at"><u>$10 billion annualized in May 2025</u></a> was a compound growth rate of around 12.7%. The &quot;jump&quot; from $10 billion ARR to $12 billion ARR is 9.54%. While I realize this may not seem like a big drop, <strong><em>every single penny counts, and percentage point shifts are worth hundreds of millions (if not billions) of dollars.</em></strong>OpenAI has been projected to make<a href="https://www.theinformation.com/articles/openai-forecast-shows-shift-from-microsoft-to-softbank?ref=wheresyoured.at&amp;rc=kz8jh3"><u>$12.7 billion in revenue</u></a> in 2025. <strong>Making this number will be challenging, and require OpenAI to grow by 14%, every single month, without fail. </strong>For OpenAI to hit this number will require it to make nearly $2 billion a month in revenue by the end of the year to account for the disparity with the earlier months in the year when it made far, far less.</p><h2 id="how-exactly-is-openai-calculating-annualized-revenue"><strong>How Exactly Is OpenAI Calculating Annualized Revenue?</strong></h2><p>I also have serious suspicions about how much OpenAI actually made in May, June and July 2025.&#xA0;</p><p><a href="https://www.theinformation.com/articles/openai-hits-12-billion-annualized-revenue-breaks-700-million-chatgpt-weekly-active-users?rc=kz8jh3&amp;ref=wheresyoured.at"><u>While The Information reported OpenAI hit $12 billion in annualized revenue, they did so in an obtuse way</u></a>:</p><blockquote><em>OpenAI roughly doubled its revenue in the first seven months of the year, reaching $12 billion in annualized revenue, according to a person who spoke to OpenAI executives.&#xA0;&#xA0;</em></blockquote><p>Yet the New York Times, mere days later, <a href="https://www.nytimes.com/2025/08/01/business/dealbook/openai-ai-mega-funding-deal.html?ref=wheresyoured.at"><u>reported $13 billion annualized revenue</u></a>:</p><blockquote><em>OpenAl&apos;s business continues to surge. DealBook hears that the company&apos;s annual recurring revenue has soared to $13 billion, up from $10 billion in June &#x2014; and is projected to surpass $20 billion by the end of the year.</em></blockquote><p>First and foremost, it&#x2019;s incredibly fucking suspicious that two very different numbers were reported here so closely, and even more so that <a href="https://www.cnbc.com/2025/06/09/openai-hits-10-billion-in-annualized-revenue-fueled-by-chatgpt-growth.html?ref=wheresyoured.at"><u>the June 9 2025 announcement of OpenAI hitting $10 billion in annualized revenue</u></a> was not, as I had originally believed, discussing the month of May 2025.</p><p>This likely means that OpenAI is not using standard annualized revenue metrics - which would traditionally mean &#x201C;the last month&#x2019;s revenue multiplied by 12,&#x201D; and instead choosing &#x201C;if all the monthly subscribers and contracts that are currently paying us on this day, June 9 2025, were to be multiplied by 12, we&#x2019;d have $X annualized revenue.&#x201D;</p><p>This is astronomically fucking dodgy. <strong>For the sake of this analysis, I am assuming any announcement of annualized revenue refers to the month previous. </strong>So, for example, when OpenAI announced they hit $10 billion in annualized revenue, I am going to assume this is for the month of May 2025.</p><p>This analysis is going to <em>favour the companies in question. </em>If OpenAI &#x201C;hit $10 billion annualized&#x201D; in or around June 9 2025, it likely means that their May revenues were lower than that. Similarly, OpenAI &#x201C;hitting&#x201D; $12 billion in annualized revenue (announced end of July 2025) - which I have factored into my analysis - is considered the revenue they hit in July 2025.&#xA0;</p><p>In reality, this is likely to credit them more revenue than they deserve. If June&#x2019;s annualized revenue was $10 billion, that means they made $833 million, rather than the $939 million I credit them with for the month.&#xA0;</p><p>One cannot hit $12 billion AND $13 billion annualized in one month unless you are playing extremely silly games with the numbers in question, such as moving around when you start a 30 day period to artificially inflate things. In any case, my analysis for OpenAI&#x2019;s revenue for August is around $13.145 billion - so in line with a &#x201C;$13 billion annualized&#x201D; figure.</p><p>In any case, I am sticking with my analysis as it stands. However, the timing of these annualized revenue leaks now makes me doubt the veracity of their previous leaks, in the sense that there&#x2019;s every chance that they too are either inflated or used in a deceptive manner.</p><p>Based on these numbers, OpenAI&apos;s current growth rate is around 9.54% &#x2014; and at that current pace, it will finish the year at around $11.89 billion in revenue. This is an impressive number, meaning it&#x2019;d be making over $1.5 billion a month in revenue by December 2025 &#x2014; but such an impressive number will be difficult to reach, and mean it has something in the region of $18 billion annualized revenue by the end of the year.</p><p>I also question whether it can make it, and even if it does, how it could possibly afford to serve that revenue long-term.</p><hr><p>In Anthropic&apos;s case, I am extremely confident, based on its well-reported annualized revenues, <strong><u>that Anthropic has, through July 2025, made around $</u>1.5 billion in revenue. This is, of course, assuming that their annualized revenue leaks are for calendar months, and if they&apos;re not, this number could <em>actually be lower.</em></strong></p><p>This is not a question of opinion. Other than April, we have ARR for every single month of the year.&#xA0; Bloomberg is now reporting that Anthropic sees its revenue rate &quot;<a href="https://x.com/EdLudlow/status/1950561790695448810?ref=wheresyoured.at"><u>maybe [going] to $9 billion annualized by year-end</u></a>,&quot; which, to use a technical term, is total bullshit, especially as this number was leaked <em>as Anthropic is fundraising.</em></p><p>In any case, I believe Anthropic can beat its base case estimates. It will almost certainly cross $2 billion in revenue, but I also believe that revenue growth is slowing for these companies, and the amount of cash we credit them as actually making is decidedly more average than &quot;annualized revenue&quot; would have you believe.</p>]]>
			</content:encoded>
		</item>
		<item>
			<title>
				<![CDATA[Is SoftBank Still Backing OpenAI?]]>
			</title>
			<description>
				<![CDATA[<p>Earlier in the week,<a href="https://www.wsj.com/tech/ai/softbank-openai-a3dc57b4?gaa_at=eafs&amp;gaa_n=ASWzDAhSGxVE7YWPjOGO5Bf983xbPlT09fhp3HArXDmk7IpNVRI55vgtx-fYexwjd84%3D&amp;gaa_ts=68800259&amp;gaa_sig=MZzp7XzaujaVrLyNCFafbBRtMZ1ZjpKt8pa23z2pRIL9r7Gcw5vTFIyb7yt0muQTu64HY2mktFMxyJKBL6W72A%3D%3D&amp;ref=wheresyoured.at"><u>the Wall Street Journal reported</u></a> that SoftBank and OpenAI&apos;s &quot;$500 billion&quot; &quot;AI Project&quot; was now setting a &quot;more modest goal of building a small data center by year-end.&quot;</p><p>To quote:</p><blockquote>A $500 billion effort unveiled<a href="https://www.wsj.com/tech/ai/tech-leaders-pledge-up-to-500-billion-in-ai-investment-in-u-s-da506cd4?mod=article_inline&amp;ref=wheresyoured.at"><u>at the White</u></a></blockquote>]]>
			</description>
			<link>https://www.wheresyoured.at/softbank-openai/</link>
			<guid isPermaLink="false">687ffe906d115000016aac56</guid>
			<dc:creator>
				<![CDATA[Edward Zitron]]>
			</dc:creator>
			<pubDate>Thu, 24 Jul 2025 17:19:51 GMT</pubDate>
			<content:encoded>
				<![CDATA[<p>Earlier in the week,<a href="https://www.wsj.com/tech/ai/softbank-openai-a3dc57b4?gaa_at=eafs&amp;gaa_n=ASWzDAhSGxVE7YWPjOGO5Bf983xbPlT09fhp3HArXDmk7IpNVRI55vgtx-fYexwjd84%3D&amp;gaa_ts=68800259&amp;gaa_sig=MZzp7XzaujaVrLyNCFafbBRtMZ1ZjpKt8pa23z2pRIL9r7Gcw5vTFIyb7yt0muQTu64HY2mktFMxyJKBL6W72A%3D%3D&amp;ref=wheresyoured.at"><u>the Wall Street Journal reported</u></a> that SoftBank and OpenAI&apos;s &quot;$500 billion&quot; &quot;AI Project&quot; was now setting a &quot;more modest goal of building a small data center by year-end.&quot;</p><p>To quote:</p><blockquote>A $500 billion effort unveiled<a href="https://www.wsj.com/tech/ai/tech-leaders-pledge-up-to-500-billion-in-ai-investment-in-u-s-da506cd4?mod=article_inline&amp;ref=wheresyoured.at"><u>at the White House</u></a> to supercharge the U.S.&#x2019;s artificial-intelligence ambitions has struggled to get off the ground and has sharply scaled back its near-term plans.<br><br>Six months after Japanese billionaire Masayoshi Son stood shoulder to shoulder with Sam Altman and President<a href="https://www.wsj.com/topics/person/donald-trump?ref=wheresyoured.at"><u>Trump</u></a> to announce the Stargate project, the newly formed company charged with making it happen has yet to complete a single deal for a data center.</blockquote><p>One might be forgiven for being a little confused here, as there is, apparently, a Stargate Data Center being built in Abilene Texas. Yet the Journal added another detail:</p><blockquote>Altman has used the Stargate name, shared with a 1994 Kurt Russell film about aliens who teleport to ancient Egypt, on projects that aren&#x2019;t being financed by the partnership between OpenAI and SoftBank. The trademark to Stargate is held by SoftBank, according to public filings.<br><br>For instance, OpenAI refers to a data center in Abilene, Texas, and another it agreed in March to use in Denton, Texas, as part of Stargate even though they are being done without SoftBank, some of the people familiar with the matter said.</blockquote><p>Confusing, right? One might also be confused by the Bloomberg story called &quot;<a href="https://www.bloomberg.com/news/features/2025-05-20/inside-stargate-ai-data-center-from-openai-and-softbank?ref=wheresyoured.at"><u>Inside The First Stargate AI Data Center</u></a>,&quot; which had the subheadline &quot;OpenAI, Oracle and SoftBank hope that the site in Texas is the first of many across the US.&quot; More-confusingly, the piece talked about Stargate LLC, which OpenAI, Oracle and SoftBank were (allegedly) shareholders of.</p><p>Yet I have confirmed that SoftBank never, ever had any involvement with the site in Abilene Texas. It didn&apos;t fund it, it didn&apos;t build it, it didn&apos;t choose the site and, in fact, does not appear to have anything to do with <em>any</em> data center that OpenAI uses. The data center many, many reporters have referred to as &quot;Stargate&quot; has nothing to do with the &quot;Stargate data center project.&quot;&#xA0; Any reports suggesting otherwise are wrong, and I believe that this is a conscious attempt at misleading the public by OpenAI and SoftBank.</p><p>I confirmed the following with a PR representative from Crusoe, one of the developers of the site in Abilene Texas:</p><blockquote>Funding for construction of [the] Abilene data center is a JV between Crusoe, Blue Owl and Primary Digital Infrastructure. Confirming that Softbank is not and has not been involved in the funding for its construction.&#xA0;</blockquote><p>And, as a reminder,<a href="https://www.theinformation.com/briefings/oracle-ceo-says-openais-stargate-venture-formed-yet?rc=kz8jh3&amp;ref=wheresyoured.at"><u>Stargate as an entity was never formed</u></a> &#x2014; <em>my source being the CEO of Oracle Safra Catz on Oracle&#x2019;s earnings call</em>.</p><p>This is an astonishing &#x2014; and egregious &#x2014; act of misinformation on the part of Sam Altman and OpenAI. By my count,<a href="https://www.techrepublic.com/article/news-stargate-first-ai-data-center-texas/?ref=wheresyoured.at"><u>at</u></a><a href="https://cities-today.com/abilene-named-as-launchpad-for-500-billion-ai-project/?ref=wheresyoured.at"><u>least</u></a><a href="https://techcrunch.com/2025/01/21/openai-teams-up-with-softbank-and-oracle-on-50b-data-center-project/?ref=wheresyoured.at"><u>15</u></a><a href="https://insider.govtech.com/texas/news/openai-chooses-abilene-for-stargate-data-center?ref=wheresyoured.at"><u>different</u></a> stories attribute the Abilene Texas data center to the Stargate project, despite the fact that SoftBank was never and has never been involved. One would forgive anyone who got this wrong, because<a href="https://openai.com/index/announcing-the-stargate-project/?ref=wheresyoured.at"><strong><em><u>OpenAI itself engaged in the deliberate deception in its own announcement of the Stargate Project</u></em></strong></a><strong><em> [emphasis mine]:</em></strong></p><blockquote>The initial equity funders in Stargate are SoftBank, OpenAI, Oracle, and MGX. SoftBank and OpenAI are the lead partners for Stargate, with SoftBank having financial responsibility and OpenAI having operational responsibility. Masayoshi Son will be the chairman.<br><br>Arm, Microsoft, NVIDIA, Oracle, and OpenAI are the key initial technology partners. The buildout is currently underway, <strong><u>starting in Texas</u></strong>, and we are evaluating potential sites across the country for more campuses as we finalize definitive agreements.</blockquote><p>You can weasel-word all you want about how nobody has directly reported that SoftBank was or was not part of Abilene. This is a deliberate, intentional deception, perpetrated by OpenAI and SoftBank, who deliberately misled both the public and the press as a means of keeping up the appearance that SoftBank was deeply involved in (and financially obligated to) the Abilene site.</p><p><strong>Based on reporting that existed at the time but was never drawn together, it appears that Abilene was earmarked <em>by Microsoft</em> for OpenAI&apos;s use as early as July 2024, and never involved SoftBank in any way, shape or form. The &quot;Stargate&quot; Project, as reported, <em><u>was over six months old when it was announced in January 2025, and there have been no additional sites added other than Abilene.</u></em></strong></p><p>In simpler terms, <em>Stargate does not exist other than as a name that Sam Altman gives things to make them feel more special than they are, and SoftBank was never involved. </em>Stargate does not exist as reported.</p><p>The use of the term &quot;Stargate&quot; is an intentional act of deceit, but beneath the surface lies, in my mind, a much bigger story. Furthermore, I believe this deceit means that we should review any and all promises made by OpenAI and SoftBank, and reconsider any and all statements they&apos;ve made, or that have been made about them.</p><p>Let&apos;s review.</p><p>According to reporting:</p><ul><li>In January 2025, it was reported that<a href="https://www.wsj.com/tech/ai/openaiin-talks-for-huge-investment-round-valuing-it-up-to-300-billion-2a2d4327?ref=wheresyoured.at"><u>both OpenAI and SoftBank are contributing $18 billion or $19 billion to the &quot;Stargate data center project.&quot;</u></a></li><li>In February 2025,<a href="https://www.reuters.com/technology/artificial-intelligence/softbank-openai-set-up-ai-japan-joint-venture-2025-02-03/?ref=wheresyoured.at"><u>it was reported</u></a> that OpenAI and Softbank would set up a joint venture called &quot;SB OpenAI Japan,&quot; with SoftBank &quot;also [stating they would] pay $3 billion annually to use OpenAI&apos;s technology across SoftBank group companies.&quot;<ul><li><a href="https://group.softbank/en/news/press/20250203_0?ref=wheresyoured.at"><u>Per SoftBank&apos;s own statement</u></a>, this would also involve developing and marketing something called &quot;Cristal Intelligence.&quot; No, I don&apos;t know what that means either, but allegedly SB OpenAI Japan will market it. SoftBank stated it would deploy &quot;...existing tools like ChatGPT Enterprise to employees across the entire group.&quot;</li></ul></li><li><a href="https://group.softbank/en/news/press/20250401?ref=wheresyoured.at"><u>On March 31 2025</u></a>, SoftBank stated it had entered into a definitive agreement to &quot;make follow-on investments of up to $40 billion,&quot; with the plan to &quot;syndicate out $10 billion,&quot; with SoftBank&apos;s effective investment amount &quot;expected to be up to $30 billion.&quot;<ul><li><a href="https://www.cnbc.com/2025/03/31/openai-closes-40-billion-in-funding-the-largest-private-fundraise-in-history-softbank-chatgpt.html?msockid=281edec7c2a268a818bdcb14c39b69fd&amp;ref=wheresyoured.at"><u>This round was repeatedly referred to as &quot;closed&quot; by the media</u></a>, but only $10 billion &#x2014;<a href="https://www.theinformation.com/articles/openai-discussed-raising-money-saudi-arabia-indian-investors?rc=kz8jh3&amp;ref=wheresyoured.at"><u>of which $7.5 billion was provided by SoftBank according to The Information</u></a> &#x2014; has actually been sent. The remaining $30 billion &#x2014; or $10 billion, in the event OpenAI can&apos;t convert to a for-profit by years-end &#x2014; would be due in December 2025.</li></ul></li></ul><p>Yet based on my research, it appears that SoftBank may not be able to &#x2014; or want to &#x2014; proceed with any of these initiatives other than funding OpenAI&apos;s current round, and evidence suggests that even if it intends to,<em> SoftBank may not be able to afford investing in OpenAI further.</em></p><p>I believe that SoftBank and OpenAI&apos;s relationship is an elaborate ruse, one created to give SoftBank the appearance of innovation, and OpenAI the appearance of a long-term partnership with a major financial institution that, from my research, is incapable of meeting the commitments it has made.</p><p>In simpler terms, OpenAI and SoftBank are bullshitting everyone.</p><p>I can find no tangible proof that SoftBank ever intended to seriously invest money in Stargate, and have evidence from its earnings calls that suggests SoftBank has no idea &#x2014; or real strategy &#x2014; behind its supposed $3-billion-a-year deployment of OpenAI software.</p><p>In fact, other than the $7.5 billion that SoftBank invested earlier in the year, I don&apos;t see a single dollar actually earmarked for anything to do with OpenAI at all.</p><p>SoftBank is allegedly going to send upwards of $20 billion to OpenAI by December 31 2025, and doesn&apos;t appear to have started any of the processes necessary to do so, or shown any signs it will. This is not a good situation for anybody involved.</p>]]>
			</content:encoded>
		</item>
		<item>
			<title>
				<![CDATA[The Hater's Guide To The AI Bubble]]>
			</title>
			<description>
				<![CDATA[<p><strong>Hey! Before we go any further &#x2014; if you want to support my work, please sign up for the premium version of Where&#x2019;s Your Ed At, it&#x2019;s a $7-a-month (or $70-a-year) paid product where every week you get a premium newsletter, all while supporting my free</strong></p>]]>
			</description>
			<link>https://www.wheresyoured.at/the-haters-gui/</link>
			<guid isPermaLink="false">6877f289b78fba00013b8edc</guid>
			<dc:creator>
				<![CDATA[Edward Zitron]]>
			</dc:creator>
			<pubDate>Mon, 21 Jul 2025 16:07:38 GMT</pubDate>
			<content:encoded>
				<![CDATA[<p><strong>Hey! Before we go any further &#x2014; if you want to support my work, please sign up for the premium version of Where&#x2019;s Your Ed At, it&#x2019;s a $7-a-month (or $70-a-year) paid product where every week you get a premium newsletter, all while supporting my free work too.&#xA0;</strong></p><p><strong>Also, subscribe to my podcast </strong><a href="http://linktr.ee/betteroffline?ref=wheresyoured.at"><strong><u>Better Offline</u></strong></a><strong>, which is free. Go and subscribe then download every single episode.&#xA0;Here&apos;s parts </strong><a href="https://www.youtube.com/watch?v=8JxW8TRNV3I&amp;ab_channel=BetterOffline&amp;ref=wheresyoured.at" rel="noreferrer"><strong>1</strong></a><strong>, </strong><a href="https://www.youtube.com/watch?v=7XVYLG2HpVI&amp;ab_channel=BetterOffline&amp;ref=wheresyoured.at" rel="noreferrer"><strong>2</strong></a><strong></strong><a href="https://youtu.be/EYnrtHgN5ok?si=7TuPcj7fnfRCyjaj&amp;ref=wheresyoured.at" rel="noreferrer"><strong>and </strong>3</a> of the audio version of the Hater&apos;s Guide.</p><p><strong>One last thing: This newsletter is nearly 14,500 words. It&#x2019;s long. Perhaps consider making a pot of coffee before you start reading.&#xA0;</strong></p><hr><p>Good journalism is making sure that history is actively captured and appropriately described and assessed, and it&apos;s accurate to describe things as they currently are as alarming.</p><p>And I am <em>alarmed.</em></p><p>Alarm is not a state of weakness, or belligerence, or myopia. My concern does not dull my vision, even though it&apos;s convenient to frame it as somehow alarmist, like I have some hidden agenda or bias toward doom. I profoundly dislike the financial waste, the environmental destruction, and, fundamentally, I dislike the attempt to gaslight people into swearing fealty to a sickly and frail psuedo-industry where everybody but NVIDIA and consultancies lose money.</p><p>I also dislike the fact that I, and others like me, are held to a remarkably different standard to those who paint themselves as &quot;optimists,&quot; which typically means &quot;people that agree with what the market wishes were true.&quot; Critics are continually badgered, prodded, poked, mocked, and jeered at for not automatically aligning with the idea that generative AI will be this massive industry, constantly having to prove themselves, as if somehow there&apos;s something malevolent or craven about criticism, that critics &quot;do this for clicks&quot; or &quot;to be a contrarian.&quot;</p><p>I don&apos;t do anything for clicks. I don&apos;t have any stocks or short positions. My agenda is simple: I like writing, it comes to me naturally, I have a podcast, and it is, on some level, my job to try and understand what the tech industry is doing on a day-to-day basis. It is easy to try and dismiss what I say as going against the grain because &quot;AI is big,&quot; but I&apos;ve been railing against bullshit bubbles since 2021 &#x2014; the<a href="https://www.wheresyoured.at/the-upcoming-remote-work-company/"><u>anti-remote work push</u></a> (<a href="https://www.wheresyoured.at/the-big-media-anti-remote-op-ed-complex/"><u>and the people behind it</u></a>),<a href="https://www.wheresyoured.at/clubhouse-is-the-big-stinker-that/"><u>the Clubhouse and audio social networks bubble</u></a>,<a href="https://www.wheresyoured.at/the-nihilism-and-exploitation-of/"><u>the NFT bubble</u></a>,<a href="https://www.wheresyoured.at/quiet-quitting-and-the-death-of-office/"><u>the made-up quiet quitting panic</u></a>, and I even, though not as clearly as I wished,<a href="https://www.wheresyoured.at/sam-bankrun-fraud/"><u>called that something was up with FTX several months before it imploded</u></a>.&#xA0;</p><p>This isn&apos;t &quot;contrarianism.&quot;&#xA0; It&apos;s the kind of skepticism of power and capital that&apos;s necessary to meet these moments, and if it&apos;s necessary to dismiss my work because it makes you feel icky inside, get a therapist or see a priest.</p><p>Nevertheless, I am <em>alarmed</em>, and while I have said some of these things separately, based on recent developments, I think it&apos;s necessary to say why.&#xA0;</p><p>In short, I believe the AI bubble is deeply unstable, built on vibes and blind faith, and when I say &quot;the AI bubble,&quot; I mean the entirety of the AI trade.</p><p>And it&apos;s alarmingly simple, too.</p><p>But this isn&#x2019;t going to be saccharine, or whiny, or simply <em>worrisome.</em> I think at this point it&#x2019;s become a little ridiculous to not see that we&#x2019;re in a bubble. We&#x2019;re in a god damn bubble, it is so obvious we&#x2019;re in a bubble, it&#x2019;s<em> been</em> so obvious we&#x2019;re in a bubble, a bubble that seems strong but is actually very weak, with a central point of failure.</p><p>I may not be a contrarian, but I am a<em> hater</em>. I hate the waste, the loss, the destruction, the theft, the damage to our planet and the sheer <em>excitement</em> that some executives and writers have that workers may be replaced by AI &#x2014; <strong>and the bald-faced fucking lie that it&#x2019;s happening, and that generative AI is capable of doing so.</strong></p><p>And so I present to you &#x2014; the Hater&#x2019;s Guide to the AI bubble, a comprehensive rundown of arguments I have against the current AI boom&#x2019;s existence. Send it to your friends, your loved ones, or print it out and eat it.&#xA0;&#xA0;</p><p>No, this isn&#x2019;t gonna be a traditional guide, but something you can look at and say &#x201C;oh that&#x2019;s why the AI bubble is so bad.&#x201D; And at this point, I know I&#x2019;m tired of being gaslit by guys in gingham shirts who desperately want to curry favour with other guys in gingham shirts but who also have PHDs. I&#x2019;m tired of reading people talk about how we&#x2019;re &#x201C;in the era of agents&#x201D; that don&#x2019;t <em>fucking work</em> and <em>will never fucking work. </em>I&#x2019;m tired of hearing about &#x201C;powerful AI&#x201D; that is actually crap, and I&#x2019;m tired of being told the future is here while having the world&#x2019;s least-useful most-expensive cloud software shoved down my throat.</p><p>Look, the generative AI boom is a mirage, it hasn&#x2019;t got the revenue or the returns or the product efficacy for it to matter, everything you&#x2019;re seeing is ridiculous and wasteful, and when it all goes tits up I want you to remember that I wrote this and tried to say something.</p><h3 id="the-magnificent-7s-weakpoint-nvidia"><strong>The Magnificent 7&apos;s Weakpoint: NVIDIA</strong></h3><p>As I write this, NVIDIA is currently sitting at $170 a share &#x2014; a dramatic reversal of fate after the pummelling it took from<a href="https://www.wheresyoured.at/deep-impact/"><u>the DeepSeek situation</u></a> in January, which sent it tumbling to a brief late-April trip below $100 before things turned around.&#xA0;</p><p>The Magnificent 7 stocks &#x2014; NVIDIA, Microsoft, Alphabet (Google), Apple, Meta, Tesla and Amazon &#x2014; make up around 35% of the value of the US stock market, and of that, NVIDIA&apos;s market value makes up about 19% of the Magnificent 7. This dominance is also why ordinary people ought to be deeply concerned about the AI bubble. The Magnificent 7 is almost certainly a big part of their retirement plans, even if they&#x2019;re not directly invested.</p><p>Back in May, Yahoo Finance&apos;s<a href="http://finance.yahoo.com/news/big-techs-spending-drove-nvidias-rise-154027146.html?ref=wheresyoured.at"><u>Laura Bratton reported</u></a> that Microsoft (18.9%), Amazon (7.5%), Meta (9.3%), Alphabet (5.6%), and Tesla (0.9%) <strong>alone</strong> make up <strong><em>42.4% of NVIDIA&apos;s revenue. </em></strong>The breakdown makes things worse. Meta spends 25% &#x2014; and Microsoft an alarming 47% &#x2014; of its capital expenditures on NVIDIA chips, and as Bratton notes, Microsoft also spends money renting servers from CoreWeave, which analyst Gil Luria of D.A.Davidson estimates accounted for $8 billion (more than 6%) of NVIDIA&apos;s revenue in 2024. Luria also estimates that neocloud companies like CoreWeave and Crusoe &#x2014; that exist only to prove AI compute services &#x2014; account for as much as 10% of NVIDIA&apos;s revenue.</p><p>NVIDIA&apos;s climbing stock value comes from its continued revenue growth. In the last four quarters, NVIDIA has seen year-over-year growth of 101%, 94%, 78% and 69%, and, <a href="https://nvidianews.nvidia.com/news/nvidia-announces-financial-results-for-first-quarter-fiscal-2026?ref=wheresyoured.at"><u>in the last quarter</u></a>, a little statistic was carefully brushed under the rug: that NVIDIA <em>missed</em>, though narrowly, on data center revenue. This is exactly what it sounds like &#x2014; GPUs that are used in servers, rather than gaming consoles and PCs (.<a href="https://www.morningstar.com/news/marketwatch/2025052776/nvidia-reports-earnings-tomorrow-heres-the-main-issue-on-investors-minds?ref=wheresyoured.at"><u> Analysts estimated it would make $39.4 billion</u></a> from this category, and<a href="https://nvidianews.nvidia.com/news/nvidia-announces-financial-results-for-first-quarter-fiscal-2026?ref=wheresyoured.at"><u>NVIDIA only (lol) brought in $39.1 billion</u></a>. Then again,<a href="https://www.cnbc.com/2025/07/16/nvidia-ceo-wants-to-sell-advanced-chips-to-china-after-h20-ban-lifted.html?ref=wheresyoured.at"><u>it could be attributed to its problems in China, especially as the H20 ban has only just been lifted</u></a>. In any case, it was a miss!</p><p>NVIDIA&apos;s quarter-over-quarter growth has also become aggressively normal &#x2014; from 69%, to 59%, to 12%, to 12% again each quarter, which, again, isn&apos;t <em>bad</em> (it&apos;s pretty great!), but when 88% of your revenue is based on one particular line in your earnings, <em>it&apos;s a pretty big concern, at least for me. </em>Look, I&apos;m not a stock analyst, nor am I pretending to be one, so I am keeping this simple:</p><ul><li>NVIDIA relies not only on selling <strong>lots of GPUs each quarter,</strong> but <strong>it must always, <em>always</em> sell more GPUs the next quarter.</strong></li><li>42% of NVIDIA&apos;s revenue comes from Microsoft, Amazon, Meta, Alphabet and Tesla continuing to buy <strong>more GPUs.</strong></li><li>NVIDIA&apos;s value and continued growth is heavily reliant on <strong>hyperscaler purchases </strong>and <strong>continued interest in generative AI.</strong></li><li>The US stock market&apos;s continued health relies, on some level, on five or six companies (it&apos;s unclear how much Apple buys GPU-wise) spending billions of dollars on GPUs from NVIDIA.<ul><li><a href="https://www.paceretfs.com/resources/resource-library/is-the-market-being-hijacked-by-the-magnificent-seven?utm_source=openai"><u>An analysis from portfolio manager Danke Wang</u></a> from January found that the Magnificent 7 stocks accounted for 47.87% of the Russell 1000 Index&apos;s returns in 2024 (an index fund of the 1000 highest-ranked stocks on FTSE Russell&#x2019;s index).</li></ul></li></ul><p>In simpler terms, <strong>35% of the US stock market is held up by five or six companies buying GPUs. </strong>If NVIDIA&apos;s growth story stumbles, it will reverberate through the rest of the Magnificent 7, making them rely on their own AI trade stories.</p><p>And, as you will shortly find out, <strong><em>there is no AI trade, because generative AI is not making anybody any money.</em></strong></p><h2 id="the-hollow-ai-trade"><strong>The Hollow &quot;AI Trade&quot;</strong></h2><p>I&apos;m so tired of people telling me that companies are &quot;making tons of money on AI.&quot; Nobody is making a profit on generative AI other than NVIDIA. No, really, I&#x2019;m serious.&#xA0;</p><h2 id="the-magnificent-7s-ai-story-is-flawed-with-560-billion-of-capex-between-2024-and-2025-leading-to-35-billion-of-revenue-and-no-profit"><strong>The Magnificent 7&apos;s AI Story Is Flawed, With $560 Billion of Capex between 2024 and 2025 Leading to $35 billion of Revenue, And <u>No Profit</u></strong></h2><p>If they keep their promises, by the end of 2025, Meta, Amazon, Microsoft, Google and Tesla will have spent over $560 billion in capital expenditures on AI in the last two years, all to make around $35 billion.</p><p>This is egregiously fucking stupid.</p><h3 id="microsoft-ai-revenue-in-2025-13-billion-with-10-billion-from-openai-sold-at-a-heavily-discounted-rate-that-essentially-only-covers-costs-for-operating-the-servers"><strong>Microsoft AI Revenue In 2025: $13 billion, with $10 billion from OpenAI, sold &quot;at a heavily discounted rate that essentially only covers costs for operating the servers.&quot;</strong></h3><h3 id="capital-expenditures-in-2025-80-billion"><strong>Capital Expenditures in 2025: $80 billion</strong></h3><p>As of January 2025,<a href="https://www.geekwire.com/2025/microsoft-earnings-2/?ref=wheresyoured.at"><u>Microsoft&apos;s &quot;annualized&quot; &#x2014; meaning [best month]x12 &#x2014; revenue from artificial intelligence was around $13 billion</u></a>, a number that it chose not to update in its last earnings, likely because it&apos;s either flat or not growing, though it could in its upcoming late-July earnings. Yet the problem with this revenue is that $10 billion of that revenue,<a href="https://www.wheresyoured.at/anthropic-is-bleeding-out/"><u>according to The Information</u></a>, comes from OpenAI&apos;s spend on Microsoft&apos;s Azure cloud, and Microsoft offers preferential pricing &#x2014; &quot;<a href="https://www.theinformation.com/articles/why-openai-could-lose-5-billion-this-year?ref=wheresyoured.at&amp;rc=kz8jh3"><u>a heavily discounted rental rate that essentially only covers Microsoft&apos;s costs for operating the servers</u></a>&quot; according to The Information.</p><p>In simpler terms, 76.9% of Microsoft&apos;s AI revenue comes from OpenAI, and is sold at just above or at cost, making Microsoft&apos;s &quot;real&quot; AI revenue about $3 billion,<a href="https://www.cfodive.com/news/microsoft-capex-grow-slower-rate-cfo-ai/746947/?ref=wheresyoured.at"><u>or around 3.75% of this year&apos;s capital expenditures</u></a>, or 16.25% if you count OpenAI&apos;s revenue, which costs Microsoft more money than it earns.</p><p>The Information reports that Microsoft made $4.7 billion in &quot;AI revenue&quot; in 2024, of which OpenAI accounted for $2 billion, meaning that for<a href="https://www.cfodive.com/news/microsoft-capex-grow-slower-rate-cfo-ai/746947/?ref=wheresyoured.at"><u>the $135.7 billion that Microsoft has spent in the last two years on AI infrastructure</u></a>, it has made $17.7 billion, of which OpenAI accounted for $12.7 billion.</p><h3 id="amazon-ai-revenue-in-2025-5-billion"><strong>Amazon AI Revenue In 2025: $5 billion</strong></h3><h3 id="capital-expenditures-in-2025-105-billion"><strong>Capital Expenditures in 2025: $105 billion</strong></h3><p>Things do not improve elsewhere. An analyst estimates that Amazon, which plans to spend $105 billion in capital expenditures this year,<a href="https://finance.yahoo.com/news/amazon-stock-falls-as-raymond-james-downgrades-shares-citing-tariff-headwinds-and-limited-ai-monetization-144747355.html?ref=wheresyoured.at"><u>will make $5 billion on AI in 2025</u></a>, rising, and I quote, &quot;as much as 80%,&quot; suggesting that Amazon may have made a measly $2.77 billion in 2024 on AI<a href="https://www.wsj.com/tech/ai/tech-giants-double-down-on-their-massive-ai-spending-b3040b33?gaa_at=eafs&amp;gaa_n=ASWzDAic1rebartjNOqhq0hJo3nA6jJ1v6VAlHLgXO4gmJT3EDjHuIM7d1KPEmFCdw8%3D&amp;gaa_ts=6878099d&amp;gaa_sig=LrvPhZermCS9YAmQUxqcw9rIEFL5UBuHDGyD_YPAYQ3L-K1t-l6C-36rVguvwWH93ZNAJ0Q09uDCudfnBEsNug%3D%3D&amp;ref=wheresyoured.at"><u>in a year when it spent $83 billion in capital expenditures</u></a>. [editor&apos;s note: this piece originally said &quot;$1 billion&quot; instead of &quot;$2.77 billion&quot; due to a math error, sorry!]</p><p>Last year, Amazon CEO Andy Jassy said that &#x201C;<a href="https://www.techtarget.com/searchenterpriseai/news/366619057/Amazon-to-spend-100B-in-AWS-AI-infrastructure?ref=wheresyoured.at#:~:text=%22AI%20represents%2C%20for%20sure%2C,the%20internet%2C%22%20Jassy%20said."><u>AI represents for sure the biggest opportunity since cloud and probably the biggest technology shift and opportunity in business since the internet.</u></a>&quot; I think he&apos;s full of shit.</p><h3 id="google-ai-revenue-77-billion-at-most"><strong>Google AI Revenue: $7.7 Billion (at most)</strong></h3><h3 id="capital-expenditures-in-2025-75-billion"><strong>Capital Expenditures in 2025:</strong><a href="https://www.cnbc.com/2025/02/04/alphabet-expects-to-invest-about-75-billion-in-capex-in-2025.html?ref=wheresyoured.at"><strong><u>$75 Billion</u></strong></a></h3><p><a href="https://www.wheresyoured.at/anthropic-is-bleeding-out/"><u>Bank of America analyst Justin Post estimated a few weeks ago that Google&apos;s AI revenue would be in the region of $7.7 billion</u></a>, though his math is, if I&apos;m honest, a little generous:</p><blockquote>Google&#x2019;s artificial intelligence model is set to drive $4.2 billion in subscription revenue within its Google Cloud segment in 2025, according to an analysis from Bank of America last week.<br><br>That includes $3.1 billion in revenue from subscribers to Google&#x2019;s AI plans with its Google One service, Bank of America&#x2019;s Justin Post estimates.<br><br>Post also expects that the integration of Google&#x2019;s Gemini AI features within its Workspace service will drive $1.1 billion of the $7.7 billion in revenue he projects for that segment in 2025.</blockquote><p>Google&apos;s &quot;One&quot; subscription includes increased cloud storage across Google Drive, Gmail and Google Photos, and added a $20-a-month &quot;premium&quot; plan in February 2024 that included access to Google&apos;s various AI models. Google has claimed that<a href="https://9to5google.com/2025/05/15/google-one-150-million/?ref=wheresyoured.at"><u>the &quot;premium AI tier accounts for millions&quot; of the 150 million subscribers to the service</u></a>, though how many millions is impossible to estimate &#x2014; but that won&apos;t stop me trying!&#xA0;</p><p>Assuming that $3.1 billion in 2025 revenue would work out to $258 million a month, that would mean there were 12.9 million Google One subscribers also paying for the premium AI tier. This isn&apos;t out of the realm of possibility &#x2014;<a href="https://www.theinformation.com/articles/chatgpt-subscribers-nearly-tripled-to-15-5-million-in-2024?rc=kz8jh3&amp;ref=wheresyoured.at"><u>after all, OpenAI has 15.5 million paying subscribers</u></a> &#x2014; but Post is making a <em>generous</em> assumption here. Nevertheless, we&apos;ll accept the numbers as they are.</p><p>And the numbers fuckin&apos; stink! Google&apos;s $1.1 billion in workspace service revenue <a href="https://jacobin.com/2025/02/google-workspace-increase-prices-cloud?ref=wheresyoured.at"><u>came from a forced price-hike on those who use Google services to run their businesses</u></a>, meaning that this is likely not a number that can significantly increase without punishing them further.</p><p>$7.7 billion of revenue &#x2014; not profit! &#x2014; on $75 billion of capital expenditures. Nasty!</p><h3 id="meta-ai-revenue-2bn-to-3bn"><strong>Meta AI Revenue: $2bn to $3bn</strong></h3><h3 id="capital-expenditures-in-2025-72-billion"><strong>Capital Expenditures In 2025:</strong><a href="https://fortune.com/article/meta-q1-earnings-revenue-profit-beat-ai-capex-raise/?ref=wheresyoured.at"><strong><u>$72 Billion</u></strong></a></h3><p>Someone&apos;s gonna get mad at me for saying this, but I believe that Meta is simply <em>burning cash </em>on generative AI. There is no product that Meta sells that monetizes Large Language Models, but <em>every</em> Meta product now has them shoved into them, such as your Instagram DMs oinking at you to generate artwork based on your conversation.</p><p>Nevertheless, we do have <em>some sort of knowledge of what Meta is saying</em> due to the copyright infringement case<a href="https://www.courtlistener.com/docket/67569326/kadrey-v-meta-platforms-inc/?ref=wheresyoured.at"><u>Kadrey v. Meta</u></a>.<a href="https://chatgptiseatingtheworld.com/2025/04/30/meta-forecasts-ai-will-rake-in-460b-to-1-4-trillion-in-revenues-for-meta-by-2035-should-that-affect-fair-use-analysis/?ref=wheresyoured.at"><u>Unsealed judgment briefs revealed in April</u></a> that Meta is claiming that &quot;GenAI-driven revenue will be more than $2 billion,&quot; with estimates as high as $3 billion.&#xA0; The same document also claims that Meta expects to make <strong><em>$460 billion to $1.4 trillion in total revenue through 2035,</em></strong> the kind of thing that should get you fired in an iron ball into the sun.</p><p>Meta makes 99% of its revenue from advertising, and the unsealed documents state that it &quot;[generates] revenue from [its] Llama models and will continue earning revenue from each iteration,&quot; and &quot;share a percentage of the revenue that [it generates] from users of the Llama models...hosted by those companies,&quot; with the companies in question redacted.<a href="https://techcrunch.com/2025/03/21/meta-has-revenue-sharing-agreements-with-llama-ai-model-hosts-filing-reveals/?ref=wheresyoured.at"><u>Max Zeff of TechCrunch</u></a> adds that Meta lists host partners like AWS, NVIDIA, Databricks, Groq, Dell, Microsoft Azure, Google Cloud, and Snowflake, so it&apos;s <em>possible</em> that Meta makes money from licensing to those companies. Sadly, the exhibits further discussing these numbers are filed under seal.</p><p>Either way, we are now at $332 billion of capital expenditures in 2025 for $28.7 billion of revenue, of which $10 billion is OpenAI&apos;s &quot;at-cost or just above cost&quot; revenue. Not great.</p><h3 id="tesla-does-not-appear-to-make-money-from-generative-ai"><strong>Tesla Does Not Appear To Make Money From Generative AI</strong></h3><h3 id="capital-expenditures-in-2025-11-billion"><strong>Capital Expenditures In 2025:</strong><a href="https://www.reuters.com/business/autos-transportation/tesla-expects-capital-expenditure-exceed-11-bln-2026-2027-2025-01-30/?ref=wheresyoured.at"><strong><u>$11 billion</u></strong></a></h3><p>Despite its prominence in the magnificent 7, Tesla is one of the least-exposed of the magnificent 7 to the AI trade, as Elon Musk has turned it into a meme stock company. That doesn&apos;t mean, of course, that Musk isn&apos;t touching AI. xAI, the company that develops racist Large Language Model &quot;Grok&quot; and owns what remains of Twitter,<a href="https://www.bloomberg.com/news/articles/2025-06-17/musk-s-xai-burning-through-1-billion-a-month-as-costs-pile-up?ref=wheresyoured.at"><u>apparently burns $1 billion a month</u></a>, and<a href="https://www.theinformation.com/projects/generative-ai?ref=wheresyoured.at"><u>The Information reports</u></a> that it makes a whopping $100 million in annualized revenue &#x2014; so, about $8.33 million a month.<a href="https://www.cnn.com/2025/07/14/tech/tesla-musk-shareholder-vote-xai?ref=wheresyoured.at"><u>There is a shareholder vote for Tesla to potentially invest in xAI</u></a>, which will probably happen, allowing Musk to continue to pull leverage from his Tesla stock until the company&apos;s decaying sales and brand eventually swallow him whole.</p><p>But we&apos;re not talking about Elon Musk today.</p><h3 id="apples-ai-story-is-weird"><strong>Apple&apos;s AI Story Is Weird</strong></h3><h3 id="capital-expenditures-in-2025-around-11-billion"><strong>Capital Expenditures In 2025:</strong><a href="https://finbox.com/NASDAQGS:AAPL/explorer/capex/?ref=wheresyoured.at"><strong><u>around $11 billion</u></strong></a></h3><p>Apple Intelligence radicalized millions of people against AI, mostly because it <em>fucking stank. </em>Apple clearly got into AI reluctantly, and now faces stories about how they &quot;<a href="https://www.bloomberg.com/news/articles/2025-05-18/apple-intelligence-struggles-to-keep-up-with-chatgpt-ai-competitors?ref=wheresyoured.at"><u>fell behind in the AI race</u></a>,&quot; which mostly means that Apple aggressively introduced people to the features of generative AI by force, and it turns out that people don&apos;t really want to summarize documents, write emails, or make &quot;custom emoji,&quot; and anyone who thinks they would <strong>is a fucking alien.</strong></p><p>In any case, Apple hasn&apos;t bet the farm on AI, insomuch as it hasn&apos;t spent two hundred billion dollars on infrastructure for a product with a limited market that only loses money.</p><h2 id="the-fragile-five-%E2%80%94-amazon-google-microsoft-meta-and-tesla-%E2%80%94-are-holding-up-the-us-stock-market-by-funding-nvidias-future-growth-story"><strong>The Fragile Five &#x2014; Amazon, Google, Microsoft, Meta and Tesla &#x2014; Are Holding Up The US Stock Market By Funding NVIDIA&apos;s Future Growth Story</strong></h2><p>To be clear, I am not saying that any of the Magnificent 7 are going to die &#x2014; just that five companies&apos; spend on NVIDIA GPUs largely dictate how stable the US stock market will be. If any of these companies (but especially NVIDIA) sneeze, your 401k or your kid&#x2019;s college fund will catch a cold.&#xA0;</p><p>I realize this sounds a little simplistic, but by my calculations, NVIDIA&apos;s value underpins around 8% of the value of the US stock market. At the time of writing, it accounts for roughly 7.5% of the S&amp;P 500 &#x2014; an index of the 500 largest US publicly-traded companies. A disturbing 88% of Nvidia&#x2019;s revenue comes from enterprise-scale GPUs primarily used for generative AI, of which five companies&apos; spend makes up 42% of its revenue. <strong>In the event that any one of these companies makes significant changes to their investments in NVIDIA chips, it will eventually have a direct and meaningful negative impact on the wider market.</strong></p><p>NVIDIA&apos;s earnings are, effectively, the US stock market&apos;s confidence, and everything rides on five companies &#x2014; and if we&apos;re honest, really <em>four</em> companies &#x2014; buying GPUs for generative AI services or to train generative AI models. Worse still, these services, while losing these companies massive amounts of money, <strong><em>don&apos;t produce much revenue, meaning that the AI trade is not driving any real, meaningful revenue growth.</em></strong></p><h3 id="but-ed-they-said-something-about-points-of-growth"><strong><em>But Ed, They Said Something About Points of Growth-</em></strong></h3><p>Silence!</p><p>Any of these companies talking about &quot;growth from AI&quot; or &quot;the jobs that AI will replace&quot; or &quot;how AI has changed their organization&quot; are hand-waving to avoid telling you how much money these services are actually making them. If they were making good money and experiencing real growth as a result of these services, they wouldn&apos;t shut the fuck up about it! They&apos;d be in your ear and up your ass hooting about how much cash they were rolling in!</p><p>And they&apos;re not, because they aren&apos;t rolling in cash, and are in fact blowing nearly a hundred billion dollars each to build massive, power-hungry, costly data centers for no real reason.</p><p>Don&#x2019;t watch the mouth &#x2014; watch the hands. These companies <strong>are going to say they&#x2019;re seeing growth from AI, but unless they actually show you the growth and enumerate it, they are hand-waving.&#xA0;</strong></p><h2 id="ed-amazon-web-services-took-years-to-become-profitable-people-said-amazon-would-fail"><strong>Ed! Amazon Web Services Took Years To Become Profitable! People Said Amazon Would Fail!</strong></h2><p>So, one of the most annoying and consistent responses to my work is to say that either Amazon or Amazon Web Services &#x201C;ran at a loss,&#x201D; and that Amazon Web Services &#x2014; the invention of modern cloud computing infrastructure &#x2014; &#x201C;lost money and then didn&#x2019;t.&#x201D;&#xA0;</p><p>The thing is, this statement is one of those things that people say because it<em> sounds rational.</em> Amazon<em> did</em> lose money, and Amazon Web Services <em>was</em> expensive, that&#x2019;s obvious, right?&#xA0;</p><p>The thing is, I&#x2019;ve never really had anyone explain this point to me, so I am finally going to sit down and deal with this criticism, because every single person who mentions it thinks they just pulled Excalibur from the stone and can now decapitate me. They claim that because people in the past doubted Amazon &#x2014; because, or in addition to the burn rate of Amazon Web Services as the company built out its infrastructure &#x2014; that I too am wrong, because they were wrong about that.</p><p>This isn&apos;t Camelot, you rube! You are not King Arthur!</p><p>I will address both the argument itself and the &quot;they&quot; part of it too &#x2014; because if the argument is that the people that got AWS wrong should not be trusted, then we should no longer trust them, the people actively propagandizing our supposed generative AI future.</p><p><strong><em>Right?</em></strong></p><p>So, I&apos;m honestly not <em>sure</em> where this argument came from, because there is, to my knowledge, no story about Amazon Web Services where somebody suggested its burnrate would kill Amazon.</p><p>But let&#x2019;s go back in time to the May 31 1999 piece that some might be thinking of, called &quot;<a href="https://archive.is/5DLzp?ref=wheresyoured.at"><u>Amazon.bomb</u></a>,&quot; and how writer Jacqueline Doherty was mocked soundly for &quot;being wrong&quot; about Amazon, which has now become quite profitable.</p><p>I also want to be clear <strong>that Amazon Web Services didn&apos;t launch until 2006, and</strong><a href="https://www.annualreports.com/HostedData/AnnualReportArchive/a/NASDAQ_AMZN_2003.pdf?ref=wheresyoured.at"><strong><u>Amazon itself would become reliably profitable in 2003</u></strong></a><strong>. </strong>Technically Amazon had opened up<a href="https://press.aboutamazon.com/2002/7/amazon-com-launches-web-services-developers-can-now-incorporate-amazon-com-content-and-features-into-their-own-web-sites-extends-welcome-mat-for-developers?ref=wheresyoured.at"><u>Amazon.com&apos;s web services for developers to incorporate its content into their applications</u></a> in 2002, but what we consider AWS today &#x2014; cloud storage and compute &#x2014; launched in 2006.</p><p>But okay, what did she actually say?</p><blockquote>Unfortunately for Bezos, Amazon is now entering a stage in which investors will be less willing to rely on his charisma and more demanding of answers to tough questions like, when will this company actually turn a profit? And how will Amazon triumph over a slew of new competitors who have deep pockets and new technologies?<br><br>We tried to ask Bezos, but he declined to make himself or any other executives of the company available. He can ignore Barron&apos;s, but he can&apos;t ignore the questions.<br><br>Amazon last year posted a loss of $125 million [$242.6m in today&apos;s money) on revenues of $610 million [$1.183 billion in today&apos;s money]. And in this year&apos;s first quarter it got even worse, as the company posted a loss of $61.7 million [$119.75 million in today&apos;s money] on revenues of $293.6 million [$569.82 million in today&apos;s money].</blockquote><p>Her argument, for the most part, is that Amazon was burning cash, had a ton of competition from other people doing similar things, and that analysts backed her up:</p><blockquote>&quot;The first mover does not always win. The importance of being first is a mantra in the Internet world, but it&apos;s wrong. The ones that are the most efficient will be successful,&quot; says one retail analyst. &quot;In retailing, anyone can build a great-looking store. The hard part is building a great-looking store that makes money.&quot;</blockquote><p>Fair arguments for the time, though perhaps a little narrow-minded. The assumption wasn&apos;t that <em>what Amazon was building</em> was a bad idea, <em>but that Amazon wouldn&apos;t be the ones to build it,</em> with one saying:</p><blockquote>&quot;Once Wal-Mart decides to go after Amazon, there&apos;s no contest,&quot; declares Kurt Barnard, president of Barnard&apos;s Retail Trend Report. &quot;Wal-Mart has resources Amazon can&apos;t even dream about.&quot;</blockquote><p>In simpler terms: <strong>Amazon&apos;s business model wasn&apos;t in question. People were buying shit online. In fact, this was just before the dot com bubble burst, and when optimism about the web was at a high point.</strong> Yet the comparison stops there &#x2014; people obviously liked buying shit online, it was the business models of many of these companies &#x2014; like WebVan &#x2014; that sucked.</p><h2 id="but-lets-talk-about-amazon-web-services"><strong>But Let&apos;s Talk About Amazon Web Services</strong></h2><p>Amazon Web Services was an outgrowth of Amazon&apos;s own infrastructure, which had to expand rapidly to deal with the influx of web traffic for Amazon.com, which had become one of the world&apos;s most popular websites and was becoming increasingly more-complex as it sold things other than books. Other companies had their own infrastructure, but if a smaller company wanted to scale, they&#x2019;d basically need to build their own thing.</p><p>It&apos;s actually pretty cool what Amazon did! Remember, this was the early 2000s, before Facebook, Twitter, and a lot of the modern internet we know that runs on services like Amazon Web Services, Microsoft Azure and Google Cloud.<a href="https://archive.ph/20210824035659/https://aws.amazon.com/blogs/aws/happy-15th-birthday-amazon-ec2/?ref=wheresyoured.at"><u>It invented the modern concept of compute</u></a>!</p><p>But we&apos;re here to talk about Amazon Web Services being <em>dangerous for Amazon</em> and people <em>hating on it.</em></p><p>A November 2006 story from Bloomberg talked about<a href="https://www.bloomberg.com/news/articles/2006-11-12/jeff-bezos-risky-bet?ref=wheresyoured.at"><u>Jeff Bezos&apos; Risky Bet</u></a> to &quot;run your business with the technology behind his web site,&quot; saying that &quot;Wall Street [wanted] him to mind the store.&quot; Bezos, referred to as a &quot;one-time internet poster boy&quot; that became &quot;a post-dot-com pi&#xF1;ata.&quot; Nevertheless, this article has what my haters crave:</p><blockquote>But if techies are wowed by Bezos&apos; grand plan, it&apos;s not likely to win many converts on Wall Street. To many observers, it conjures up the ghost of Amazon past. During the dot-com boom, Bezos spent hundreds of millions of dollars to build distribution centers and computer systems in the promise that they eventually would pay off with outsize returns. That helped set the stage for the world&apos;s biggest Web retail operation, with expected sales of $10.5 billion this year.<br><br>...<br><br>All that has investors restless and many analysts throwing up their hands wondering if Bezos is merely flailing around for an alternative to his retail operation. Eleven of 27 analysts who follow the company have underperform or sell ratings on the stock--a stunning vote of no confidence. That number of sell recommendations is matched among large companies only by Qwest Communications International Inc. (Q ), according to investment consultant StarMine Corp. It&apos;s more than even the eight sell opinions on struggling Ford Motor Co. (F )</blockquote><p>Pretty bad, right? My goose is cooked? All those analysts seem pretty mad!</p><p>Except it&apos;s not, my goose is raw! Yours, however, has been in the oven for over a year!&#xA0;</p><p>Emphasis mine:</p><blockquote>By all accounts, Amazon&apos;s new businesses bring in a minuscule amount of revenue. <strong>Although its direct cost of providing them appears relatively low because the hardware and software are in place</strong>, Stifel Nicolaus &amp; Co. (SF ) analyst Scott W. Devitt notes: &quot;There&apos;s not going to be any economic return from any of these projects for the foreseeable future.&quot; Bezos himself admits as much. But with several years of heavy spending already, he&apos;s making this a priority for the long haul. &quot;We think it&apos;s going to be a very meaningful business for us one day,&quot; he says. &quot;What we&apos;ve historically seen is that the seeds we plant can take anywhere from three, five, seven years.&quot;</blockquote><p>That&apos;s right &#x2014; the ongoing costs aren&apos;t the problem.</p><p>Hey wait a second, that&apos;s a name! I can look up a name! Scott W. Devitt now works at Wedbush as its managing director of equity research, and has said AI companies would enter a new stage in 2025...god,<a href="https://finance.yahoo.com/video/palantir-snowflake-salesforce-gain-next-162817595.html?ref=wheresyoured.at"><u>just read this</u></a>:</p><blockquote>The second stage is &quot;the application phase of the cycle, which should benefit software companies as well as the cloud providers. And then, phase three of this will ultimately be the consumer-facing companies figuring out how to use the technology in ways that actually can drive increased interactions with consumers.&quot;</blockquote><p>The analyst says the market will enter phase two in 2025, with software companies and cloud provider stocks expected to see gains. He adds that cybersecurity companies could also benefit as the technology evolves.</p><p>Dewitt specifically calls out Palantir, Snowflake, and Salesforce as those who would &quot;gain.&quot; In none of these cases am I able to see the actual revenue from AI,<a href="https://www.theinformation.com/articles/ai-giving-salesforce-boost?rc=kz8jh3&amp;ref=wheresyoured.at"><u>but Salesforce itself said that it will see no revenue growth from AI this year</u></a>. Palantir also, <a href="https://adu.autonomy.work/posts/2025_05_21_ai_risk/?ref=wheresyoured.at"><u>as discovered by the Autonomy Institute&#x2019;s recent study</u></a>, <a href="https://www.sec.gov/Archives/edgar/data/1321655/000132165525000022/pltr-20241231.htm?ref=wheresyoured.at"><u>recently added to the following to its public disclosures</u></a>:</p><blockquote><em>There are significant risks involved in deploying AI and there can be no assurance that using AI in our platforms and products will enhance or be beneficial to our business, including our profitability.</em></blockquote><p>What I&apos;m saying is that<em> analysts can be wrong! And they can be wrong at scale!</em> There is no analyst consensus that agrees with me. In fact, most analysts appear to be bullish on AI, despite the significantly-worse costs and total lack of growth!</p><p>Yet even in this Hater&apos;s Parade, the unnamed journalist makes a case<em> for </em>Amazon Web Services:</p><blockquote>Sooner than that, those initiatives may provide a boost for Amazon&apos;s retail side. For one, they potentially make a profit center out of idle computing capacity needed for that retail operation. Like most computer networks, Amazon&apos;s uses as little as 10% of its capacity at any one time just to leave room for occasional spikes. It&apos;s the same story in the company&apos;s distribution centers. Keeping them humming at higher capacity means they operate more efficiently, besides giving customers a much broader selection of products. And the more stuff Amazon ships, both its own inventory or others&apos;, the better deals it can cut with shippers.</blockquote><h3 id="but-amazon-web-services-cost-money-ed-now-you-shall-meet-your-end"><strong>But Amazon Web Services Cost Money Ed, Now You Shall Meet Your End!</strong></h3><p>Nice try, chuckles!</p><p>In 2015, <a href="https://www.channelfutures.com/cloud/amazon-com-breaks-out-aws-cloud-revenues-for-first-time-in-q1-report?ref=wheresyoured.at"><u>the year that Amazon Web Services became profitable</u></a>,<a href="https://www.forbes.com/sites/chuckjones/2015/04/22/amazon-detailing-aws-performance-may-not-be-good-for-the-stock/?ref=wheresyoured.at"><u>Morgan Stanley analyst Katy Huberty believed</u></a> that it was running at a &quot;material loss,&quot; suggesting that $5.5 billion of Amazon&apos;s &quot;technology and content expenses&quot; was actually AWS expenses, with a &quot;negative contribution of $1.3 billion.&quot;</p><p>Here is Katy Huberty, the analyst in question, declaring six months ago that &quot;<a href="https://www.linkedin.com/posts/katy-huberty-6930694_we-expect-2025-to-be-a-year-of-agentic-ai-activity-7283538383807627264-3rN0/?ref=wheresyoured.at"><u>2025 [will] be the year of Agentic AI, robust enterprise adoption, and broadening AI winners</u></a>.&quot;</p><p>So, yes, analysts really got AWS wrong. But putting that aside, there might actually be a comparison here! Amazon Web Services <em>absolutely</em> created a capital expenditures drain on Amazon. <a href="https://www.forbes.com/sites/chuckjones/2015/04/22/amazon-detailing-aws-performance-may-not-be-good-for-the-stock/?ref=wheresyoured.at"><u>From Forbes&#x2019;s Chuck Jones</u></a>:</p><blockquote>In 2014 Amazon had $4.9 billion in capital expenditures, up 42% from 2013&#x2019;s $3.4 billion. The company has a wide range of items that it buys to support and grow its business ranging from warehouses, robots and computer systems for its core retail business and AWS. While I don&#x2019;t expect Amazon to detail how much goes to AWS I suspect it is a decent percentage, which means AWS needs to generate appropriate returns on the capital deployed.</blockquote><p>In today&apos;s money, this means that Amazon spent $6.76 billion in capital expenditures on AWS in 2014. Assuming it was this much every year &#x2014; it wasn&apos;t, but I want to make an example of every person claiming that this is a gotcha &#x2014; it took $67.6 billion and ten years (though one could argue it was nine) of pure capital expenditures to turn Amazon Web Services into<a href="https://www.geekwire.com/2025/amazons-quarterly-profits-soar-to-a-record-20-billion-but-cloud-growth-comes-up-short/?ref=wheresyoured.at#:~:text=Although%20AWS%20sales%20($28.8,$21.2%20billion%20for%20the%20quarter."><u>a business that now makes billions of dollars a quarter in profit</u></a>.</p><p>That&apos;s $15.4 billion <strong>less than Amazon&apos;s capital expenditures for 2024, and less than one-fifteenth its projected capex spend for 2025. </strong>And to be clear, the actual capital expenditure numbers are likely much lower, but I want to make it clear that <em>even when factoring in inflation,</em> Amazon Web Services was A) a bargain and B) a fraction of the cost <em>of what Amazon has spent in 2024 or 2025.</em></p><blockquote><strong>A fun aside: </strong>On March 30 2015,<a href="https://archive.is/ObpQl?ref=wheresyoured.at"><u>Kevin Roose wrote a piece for New York Magazine</u></a> about the cloud compute wars, in which he claimed that, and I quote, &quot;there&apos;s no reason to suspect that Amazon would ever need to raise prices on AWS, or turn the fabled &quot;profit switch&quot; that pundits have been speculating about for years.&quot;<a href="https://web.archive.org/web/20201108100958/https://www.bbc.co.uk/news/business-32442268"><u>Less than a month later Amazon revealed Amazon Web Services was profitable</u></a>. <em>They don&apos;t call him &quot;the most right man in tech journalism&quot; for nothing!</em></blockquote><h2 id="generative-ai-and-large-language-models-do-not-resemble-amazon-web-services-or-the-greater-cloud-compute-boom-as-generative-ai-is-not-infrastructure"><strong>Generative AI and Large Language Models Do Not Resemble Amazon Web Services or The Greater Cloud Compute Boom, As Generative AI Is <em>Not Infrastructure</em></strong></h2><p>Some people compare Large Language Models and their associated services to Amazon Web Services, or services like Microsoft Azure or Google Cloud, and they are wrong to do so.</p><p>Amazon Web Services, when it launched, comprised of things like (and forgive how much I&apos;m diluting this) Amazon&apos;s Elastic Compute Cloud (EC2), where you rent space on Amazon&apos;s servers to run applications in the cloud, or Amazon Simple Storage (S3), which is enterprise-level storage for applications. In simpler terms, if you were providing a cloud-based service, you used Amazon to both store the stuff that the service needed <em>and</em> the actual cloud-based processing (compute, so like your computer loads and runs applications but delivered to thousands or millions of people).&#xA0;</p><p>This is a huge industry.<a href="https://www.aboutamazon.com/news/company-news/amazon-ceo-andy-jassy-2024-letter-to-shareholders?ref=wheresyoured.at"><u>Amazon Web Services alone brought in revenues of over $100 billion in 2024</u></a>, and while Microsoft and Google don&apos;t break out their cloud revenues, they&apos;re similarly large parts of their revenue, and<a href="https://www.nextplatform.com/2025/01/29/azure-cant-make-up-for-on-premise-profit-decline-at-microsoft/?ref=wheresyoured.at"><u>Microsoft has used Azure in the past to patch over shoddy growth</u></a>.</p><p>These services are also <em>selling infrastructure.</em> You aren&apos;t just paying for the compute, but the ability to access storage and deliver services with low latency &#x2014; so users have a snappy experience &#x2014; wherever they are in the world. The subtle magic of the internet is that it works at all, and a large part of that is the cloud compute infrastructure and oligopoly of the main providers having such vast data centers. This is much cheaper than doing it yourself, until a certain point.<a href="https://www.dropbox.com/business/trust/security/architecture?ref=wheresyoured.at#:~:text=Dropbox%20corporate%20and%20production%20systems%20are%20housed,our%20infrastructure%20housed%20at%20third%2Dparty%20data%20centers."><u>Dropbox moved away from Amazon Web Services as it scaled</u></a>. It also allows someone else to take care of maintenance of the hardware <em>and </em>make sure it actually gets to your customers. You also don&apos;t have to worry about spikes in usage, because these things are usage-based, and you can always add more compute to meet demand.</p><p>There is, of course, nuance &#x2014; security-specific features, content-specific delivery services, database services &#x2014; behind these clouds. You are buying into the infrastructure of the infrastructure provider, and the reason these products are so profitable is, in part, because you are handing off the problems and responsibility to somebody else. And based on that idea, there are multiple product categories you can build on top of it, because <strong>ultimately cloud services are about Amazon, Microsoft and Google running your infrastructure for you.</strong></p><p>Large Language Models and their associated services are completely different, despite these companies attempting to prove otherwise, and it starts with a very simple problem: why did any of these companies build these giant data centers and fill them full of GPUs?</p><p>Amazon Web Services was created out of necessity &#x2014; Amazon&apos;s infrastructure needs were so great that it effectively had to build both the software and hardware necessary to deliver a store that sold theoretically everything to theoretically anywhere, handling both the traffic from customers, delivering the software that runs Amazon.com quickly and reliably, and, well, making sure things ran in a stable way. It didn&apos;t need to come up with a reason for people to run web applications &#x2014; they were already doing so themselves, but in ways that cost a lot, were inflexible, and required specialist skills. AWS took something that people already did, and what there was a proven demand for, and made it better. Eventually, Google and Microsoft would join the fray.&#xA0;</p><p>And that appears to be the only similarity with generative AI &#x2014; that due to the ridiculous costs of both the data centers and GPUs necessary to provide these services, it&apos;s largely impossible for others to even enter the market.</p><p>Yet after that, generative AI feels more like a <em>feature </em>of cloud infrastructure rather than infrastructure itself. AWS and similar megaclouds are versatile, flexible and multifaceted. Generative AI does what generative AI does, and that&apos;s about it.</p><p>You can <em>run</em> lots of different things on AWS. What are the different things you can run using Large Language Models? What are the different use cases, and, indeed, user requirements that make this the supposed &quot;next big thing&quot;?</p><p>Perhaps the argument is that generative AI is the next AWS or similar cloud service because you can build the next great companies on the infrastructure of others &#x2014; the models of, say, OpenAI and Anthropic, and the servers of Microsoft.&#xA0;</p><p>So, okay, let&apos;s humour this point too. You can build the next great AI startup, and you have to build it on one of the megclouds because they&apos;re the only ones that can afford to build the infrastructure.</p><p>One small problem.</p><h2 id="companies-built-on-top-of-large-language-models-dont-make-much-money-in-fact-theyre-likely-all-deeply-unprofitable"><strong>Companies Built On Top Of Large Language Models Don&apos;t Make Much Money (In Fact, They&apos;re Likely All Deeply Unprofitable)</strong></h2><p>Let&apos;s start by establishing a few facts:</p><ul><li>Outside of one exception &#x2014; <a href="https://www.theregister.com/2022/08/01/david_holz_midjourney/?ref=wheresyoured.at"><u>Midjourney, which&#xA0; claimed it was profitable in 2022</u></a>, which may not still be the case, I&#x2019;ve reached out to ask&#x2014; every single Large Language Model company is unprofitable, often wildly so.&#xA0;</li><li>Outside of OpenAI, Anthropic and Anysphere (which makes AI coding app Cursor), there are no Large Language Model companies &#x2014; either building models or services on top of others&apos; models &#x2014; that make more than $500 million in annualized revenue (meaning month x 12), and outside of Midjourney ($200m ARR) and Ironclad ($150m ARR),<a href="https://www.theinformation.com/projects/generative-ai?rc=kz8jh3&amp;ref=wheresyoured.at"><u>according to The Information&apos;s Generative AI database</u></a>, and Perplexity (which just announced it&#x2019;s at $150m ARR), there are <strong>only twelve generative AI-powered companies making $100 million annualized (or $8.3 million a month) in revenue. </strong>Though the database doesn&apos;t have Replit (which recently announced it hit $100 million in annualized revenue), I&apos;ve included it in my calculations for the sake of fairness.<ul><li>Of these companies, two have been acquired &#x2014;<a href="https://www.servicenow.com/company/media/press-room/servicenow-to-acquire-moveworks.html?ref=wheresyoured.at"><u>Moveworks</u></a> (acquired by ServiceNow in March 2025) and Windsurf (<a href="https://cognition.ai/blog/windsurf?ref=wheresyoured.at"><u>acquired by Cognition in July 2025</u></a>).</li><li>For the sake of simplicity, I&apos;ve left out companies like Surge, Scale, Turing and Together, all of whom run consultancies selling services for training models.</li></ul></li><li>Otherwise, there are seven companies that make $50 million or more ARR ($4.16 million a month).</li></ul><p>None of this is to say that one hundred million dollars isn&apos;t a lot of money to you and me, but in the world of Software-as-Service or enterprise software, <em>this is chump change. </em>Hubspot had revenues of $2.63 billion in its 2024 financial year.</p><p>We&apos;re three years in, and generative AI&apos;s highest-grossing companies &#x2014; outside OpenAI<a href="https://www.cnbc.com/2025/06/09/openai-hits-10-billion-in-annualized-revenue-fueled-by-chatgpt-growth.html?ref=wheresyoured.at"><u>($10 billion annualized as of early June</u></a>) and Anthropic (<a href="https://www.theinformation.com/articles/anthropic-revenue-hits-4-billion-annual-pace-competition-cursor-intensifies?rc=kz8jh3&amp;ref=wheresyoured.at"><u>$4 billion annualized as of July</u></a>), and both lose billions a year after revenue &#x2014; have three major problems:</p><ul><li>Businesses powered by generative AI do not seem to be popular.</li><li>Those businesses that are remotely popular are deeply unprofitable...</li><li>...and even the less-popular generative AI-powered businesses are deeply unprofitable.</li></ul><p>But let&apos;s start with Anysphere and Cursor, its AI-powered coding app, and its $500 million of annualized revenue. Pretty great, right?<a href="https://www.theinformation.com/briefings/cursor-hits-200-million-annual-recurring-revenue?rc=kz8jh3&amp;ref=wheresyoured.at"><u>It hit $200 million in annualized revenue in March</u></a>,<a href="https://techcrunch.com/2025/06/05/cursors-anysphere-nabs-9-9b-valuation-soars-past-500m-arr/?ref=wheresyoured.at"><u>then hit $500 million annualized revenue in June after raising $900 million</u></a>. That&apos;s amazing!</p><p>Sadly, it&apos;s a mirage. Cursor&apos;s growth was a result of an unsustainable business model that it&#x2019;s now had to replace with opaque terms of service, dramatically restricted access to models, and rate limits that effectively stop its users using the product at the price point they were used to.</p><p>It&#x2019;s also horribly unprofitable, and a sign of things to come for generative AI.</p><h2 id="cursors-500-million-annualized-revenue-was-earned-with-a-product-it-no-longer-offers-and-anthropicopenai-just-raised-their-prices-increasing-cursor%E2%80%99s-costs-dramatically"><strong>Cursor&apos;s $500 Million &quot;Annualized Revenue&quot; Was Earned With A Product It No Longer Offers, And Anthropic/OpenAI Just Raised Their Prices, Increasing Cursor&#x2019;s Costs Dramatically</strong></h2><p>A couple of weeks ago,<a href="https://www.wheresyoured.at/anthropic-and-openai-have-begun-the-subprime-ai-crisis/"><u>I wrote up the dramatic changes that Cursor made to its service in the middle of June on my premium newsletter</u></a>, and discovered that they timed precisely with Anthropic (and OpenAI to a lesser extent) adding &quot;service tiers&quot; and &quot;priority processing,&quot; which is tech language for &quot;pay us extra if you have a lot of customers or face rate limits or service delays.&quot; These price shifts have also led to <a href="https://blog.replit.com/effort-based-pricing?ref=wheresyoured.at"><u>companies like Replit having to make significant changes to its pricing model that disfavor users</u></a>.&#xA0;</p><p>I will now plagiarise myself:</p><ul><li>In or around May 5, 2025 &#x2014;<a href="https://www.ft.com/content/a7b34d53-a844-4e69-a55c-b9dee9a97dd2?ref=wheresyoured.at"><u> Cursor closes a $500 million funding round</u></a>.</li><li>May 22 2025 &#x2014;<a href="https://www.anthropic.com/news/claude-4?ref=wheresyoured.at"><u> Anthropic launches Claude 4</u></a> Opus and Sonnet, and on May 30, 2025 adds<a href="https://web.archive.org/web/20250530132140/https://docs.anthropic.com/en/api/service-tiers"><u> Service Tiers</u></a>, including priority pricing specifically focused on cache-heavy products like Cursor.</li><li>May 30, 2025 &#x2014; Reuters reports that Anthropic&apos;s &quot;<a href="https://www.reuters.com/business/anthropic-hits-3-billion-annualized-revenue-business-demand-ai-2025-05-30/?ref=wheresyoured.at"><u>annualized revenue hit $3 billion</u></a>,&quot; with a &quot;key driver&quot; being &quot;code generation.&quot; This translates to around $250 million in monthly revenue.</li><li><a href="http://www.cnbc.com/2025/06/09/openai-hits-10-billion-in-annualized-revenue-fueled-by-chatgpt-growth.html?ref=wheresyoured.at"><u>June 9 2025</u></a> &#x2014; CNBC reports OpenAI has hit $10 billion in annualized revenue. They say &quot;annual recurring revenue,&quot; but they mean annualized.<ul><li>The very same day,<a href="https://www.wheresyoured.at/make-fun-of-them/"><u> OpenAI cuts the price of its o3 model by 80%</u></a>, which competes directly with Claude 4 Opus.<ul><li>This is a direct and aggressive attempt to force Anthropic to raise prices, or try and muscle in on its terrain.</li></ul></li></ul></li><li>On or around June 16 2025 &#x2014;<a href="https://web.archive.org/web/20250619080155/https://www.cursor.com/en/blog/new-tier"><u> Cursor changes its pricing</u></a>, adding a new $200-a-month &quot;Ultra&quot; tier that, in its own words, is &quot;made possible by multi-year partnerships with OpenAI, Anthropic, Google and xAI,&quot; which translates to &quot;multi-year commitments to spend, which can be amortized as monthly amounts.&quot;</li><li>A day later, Cursor dramatically changed its offering to a &quot;usage-based&quot; one where users got &quot;at least&quot; the value of their subscription &#x2014; $20-a-month provided more than $20 of API calls &#x2014; in compute, along with arbitrary rate limits and &quot;unlimited&quot; access to Cursor&apos;s own slow model that its users hate.</li><li><a href="https://blog.replit.com/effort-based-pricing?ref=wheresyoured.at"><u>June 18</u></a> &#x2014; Replit announces its &quot;<a href="https://blog.replit.com/effort-based-pricing?ref=wheresyoured.at"><u>effort-based pricing</u></a>&quot; increases.</li><li>July 1 2025 &#x2014;<a href="https://www.theinformation.com/articles/anthropic-revenue-hits-4-billion-annual-pace-competition-cursor-intensifies?rc=kz8jh3&amp;ref=wheresyoured.at"><u> The Information reports</u></a> Anthropic has hit &quot;$4 billion annual pace,&quot;&#xA0; meaning that it is making $333 million a month, or an increase of $83 million a month, <strong>or an increase of just under 25% in the space of a month.</strong></li></ul><p>In simpler terms, Cursor raised $900 million and very likely had to hand large amounts of that money over to OpenAI and Anthropic to keep doing business with them, <em>and then immediately changed its terms of service to make them worse.</em> As I said at the time:</p><blockquote>While some may believe that both OpenAI and Anthropic hitting &quot;annualized revenue&quot; milestones is good news, you have to consider <strong>how</strong> these milestones were hit. Based on my reporting, I believe that both companies are effectively doing steroids, forcing massive infrastructural costs onto big customers as a means of covering the increasing costs of their own models.<br><br>There is simply no other way to read this situation. By making these changes, Anthropic is intentionally making it harder for its largest customer to do business, creating extra revenue by making Cursor&apos;s product worse by proxy. What&apos;s sickening about this particular situation is that it doesn&apos;t really matter if Cursor&apos;s customers are happy or sad &#x2014; they,<a href="https://openai.com/api-priority-processing/?ref=wheresyoured.at"><u> like OpenAI&apos;s enterprise Priority Access API</u></a>,<a href="https://docs.anthropic.com/en/api/service-tiers?ref=wheresyoured.at"><u> require a long-term commitment which involves a minimum throughput of tokens for second as part of their Tiered Access program</u></a>.<br><br>If Cursor&apos;s customers drop off, both OpenAI and Anthropic still get their cut, and if Cursor&apos;s customers somehow outspend even those commitments, they&apos;ll either still get rate limited or Anysphere will incur more costs.</blockquote><p>Cursor is the largest and most-successful generative AI company, and these aggressive and desperate changes to its product suggest A) that its product is deeply unprofitable and B) that its current growth was a result of offering a product that was not the one it would sell in the long term. <strong>Cursor misled its customers, and its current revenue is, as a result, <em>highly unlikely to stay at this level.</em></strong></p><p>Worse still,<a href="https://x.com/nmasc_/status/1945537779061977456?ref=wheresyoured.at"><u>the two Anthropic engineers who left to join Cursor two weeks ago just returned to Anthropic</u></a>. This heavily suggests that whatever they saw at Cursor wasn&#x2019;t compelling enough to make them stay.</p><p>As I also said:</p><blockquote>While Cursor may have raised $900 million, it was really OpenAI, Anthropic, xAI and Google that got that money.<br><br>At this point, there are no profitable enterprise AI startups, and it is highly unlikely that the new pricing models by both Cursor and Replit are going to help.<br><br>These are now the new terms of doing business with these companies &#x2014; a shakedown, where you pay up for priority access or &quot;tiers&quot; or face indeterminate delays or rate limits. Any startup scaling into an &quot;enterprise&quot; integration of generative AI which means, in this case, anything that requires a certain level of service uptime) has to commit to both a minimum amount of months and a throughput of tokens, which means that the price of starting an AI startup that gets any kind of real market traction just dramatically increased.<br><br>While one could say &quot;oh perhaps you don&apos;t need priority access,&quot; the &quot;need&quot; here is something that will be entirely judged by Anthropic and OpenAI in an utterly opaque manner. They can &#x2014; and will! &#x2014; throttle companies that are too demanding on their system, as proven by the fact that they&apos;ve done this to Cursor multiple times.</blockquote><h3 id="why-does-cursor-matter-simple-generative-ai-has-no-business-model-if-it-cant-do-software-as-a-service"><strong>Why Does Cursor Matter? Simple: Generative AI Has No Business Model If It Can&apos;t Do Software As A Service</strong></h3><p>I realize it&apos;s likely a little boring hearing about software as a service, <strong>but this is the only place where generative AI can really make money. Companies buying hundreds or thousands of seats are how industries that rely upon compute grow, and without that growth, they&apos;re going nowhere.</strong></p><p>To give you some context, Netflix makes about $39 billion a year in subscription revenue, and Spotify about $18 billion. These are the single-most-popular consumer software subscriptions in the world &#x2014; and<a href="https://www.theinformation.com/articles/chatgpt-subscribers-nearly-tripled-to-15-5-million-in-2024?rc=kz8jh3&amp;ref=wheresyoured.at"><u>OpenAI&apos;s 15.5 million subscribers</u></a> suggest that it can&apos;t rely on them for the kind of growth that would actually make the company worth $300 billion (or more).</p><p>Cursor is, as it stands, the <em>one</em> example of a company thriving using generative AI, and it appears its rapid growth was a result of selling a product at a massive loss. As it stands today, Cursor&apos;s product is significantly worse, and its Reddit is full of people furious at the company for the changes.</p><p>In simpler terms, Cursor was the company that people mentioned to prove that startups could make money by building products on top of OpenAI and Anthropic&apos;s models, yet the truth is that the only way to do so and grow is to burn tons of money. While the tempting argument is to say that Cursor&#x2019;s &quot;customers are addicted,&quot; this is clearly not the case, nor is it a real business model.</p><p>This story also showed that Anthropic and OpenAI are the biggest threats to their customers, and will actively rent-seek and punish their success stories, looking to loot as much as they can from them.</p><p><strong>To put it bluntly: <u>Cursor&apos;s growth story was a lie. It reached $500 million in annualized revenue selling a product it can no longer afford to sell, suggesting material weakness in its own business and any and all coding startups.</u></strong></p><p>It is also remarkable &#x2014; and a shocking failure of journalism &#x2014; that this isn&#x2019;t in every single article about Anysphere.</p><h3 id="no-really-where-are-the-consumer-ai-startups"><strong>No, Really, Where Are The Consumer AI Startups?</strong></h3><p>I&apos;m serious! Perplexity?<a href="https://www.ft.com/content/4e05a5c5-84ad-4f8a-991a-d7f3842de76d?ref=wheresyoured.at"><u> Perplexity only has $150 million in annualized revenue</u></a>!<a href="https://www.theinformation.com/articles/google-challenger-perplexity-growth-comes-high-cost?rc=kz8jh3&amp;ref=wheresyoured.at"><u>It spent 167% of its revenue in 2024</u></a> ($57m, its revenue was $34m) on compute services from Anthropic, OpenAI, and Amazon! It <strong>lost $68 million!</strong></p><p>And worse still, it has no path to profitability, and <strong><em>it&#x2019;s not even anything new! It&#x2019;s a search engine! </em></strong>Professional gasbag Alex Heath just did a<a href="https://www.theverge.com/command-line-newsletter/656599/perplexitys-ceo-on-fighting-google-and-the-coming-ai-browser-war?ref=wheresyoured.at#comments"><u>flummoxing interview</u></a> with Perplexity CEO Aravind Srivinas, who, when asked how it&#x2019;d become profitable, appeared to experience a stroke:</p><blockquote>Maybe let me give you another example. You want to put an ad on Meta, Instagram, and you want to look at ads done by similar brands, pull that, study that, or look at the AdWords pricing of a hundred different keywords and figure out how to price your thing competitively. These are tasks that could definitely save you hours and hours and maybe even give you an arbitrage over what you could do yourself, because AI is able to do a lot more. And at scale, if it helps you to make a few million bucks, does it not make sense to spend $2,000 for that prompt? It does, right? So I think we&#x2019;re going to be able to monetize in many more interesting ways than chatbots for the browser.</blockquote><p>Aravind, <em>do you smell toast?</em></p><p>And don&#x2019;t talk to me about &#x201C;AI browsers,&#x201D; I&#x2019;m sorry, it&#x2019;s not a business model. How are people going to make revenue on this, hm? What do these products actually do? Oh <a href="https://www.theverge.com/news/709025/perplexity-comet-ai-browser-chrome-competitor?ref=wheresyoured.at"><u>they can poorly automate accepting LinkedIn invites</u></a>? It&#x2019;s like God himself has personally blessed my computer. Big deal!&#xA0;</p><p>In any case, it doesn&apos;t seem like you can really build a consumer AI startup that makes anything approaching a real company. Other than ChatGPT, I guess?</p><h2 id="the-generative-ai-software-as-a-service-market-is-small-with-little-room-for-growth-and-no-profits-to-be-seen"><strong>The Generative AI Software As A Service Market Is Small, With Little Room For Growth And No Profits To Be Seen</strong></h2><p>Arguably the biggest sign that things are troubling in the generative AI space is that we use &quot;annualized revenue&quot; at all, which, as I&apos;ve mentioned repeatedly, means multiplying a month by 12 and saying &quot;that&apos;s our annualized!&quot;</p><p>The problem with this number is that, well, people cancel things. While your June might be great, if 10% of your subscribers churn in a bad month (due to a change in your terms of service), that&apos;s a chunk of your <em>annualized</em> revenue gone.</p><p>But the worst sign is that <strong><em>nobody is saying the monthly figures, mostly because the monthly figures kinda suck! </em></strong>$100 million of annualized revenue is $8.33 million a month. To give you some scale,<a href="https://www.nextplatform.com/2018/02/05/navigating-revenue-streams-profit-pools-aws/?ref=wheresyoured.at"><u>Amazon Web Services hit $189 million ($15.75 million a month) in revenue in 2008</u></a>, two years after founding, and while it took until 2015 to hit profitability, it actually hit break-even in 2009, though it invested cash in growth for a few years after.</p><p>Right now, <em>not a single generative AI software company is profitable, <strong>and none of them are showing the signs of the kind of hypergrowth that previous &quot;big&quot; software companies had. </strong></em>While Cursor is technically &quot;<a href="https://medium.com/strategy-decoded/cursor-went-from-1-100m-arr-in-12-months-the-fastest-saas-to-achieve-this-19d811c4f0bb?ref=wheresyoured.at"><u>the fastest growing SaaS of all time</u></a>,&quot; it did so using what amounts to fake pricing. You can dress this up as &quot;growth stage&quot; or &quot;enshittification (it isn&apos;t by the way, generally price changes make things profitable, which this did not),&quot; but Cursor lied. It lied to the public about what its product would do long-term. It isn&apos;t even obvious whether its current pricing is sustainable.</p><p>Outside of Cursor, what other software startups are there?</p><p><strong><em>Glean?</em></strong></p><p>Everyone loves to talk about enterprise search company Glean &#x2014; a company that uses AI to search and generate answers from your company&apos;s files and documents.</p><p>In December 2024, Glean raised $260 million,<a href="https://www.wheresyoured.at/anthropic-is-bleeding-out/"><u>proudly stating that it had over $550 million of cash in hand</u></a> with &quot;best-in-class ARR growth.&quot; A few months later in February 2025,<a href="https://www.glean.com/press/glean-achieves-100m-arr-in-three-years-delivering-true-ai-roi-to-the-enterprise?ref=wheresyoured.at"><u>Glean announced</u></a> it&#x2019;d &quot;achieved $100 million in annual recurring revenue in fourth quarter FY25, cementing its position as one of the fastest-growing SaaS startups and reflecting a surging demand for AI-powered workplace intelligence.&quot; In this case, ARR could literally mean anything, as it appears to be based on quarters &#x2014; meaning it could be an average of the last three months of the year, I guess?</p><p>Anywho, in June 2025,<a href="https://www.glean.com/blog/glean-series-f-announcement?ref=wheresyoured.at"><u>Glean announced it had raised<em> another funding round</em>, this time raising $150 million</u></a>, and, troublingly, added that since its last round, it had &quot;...surpassed $100M in ARR.&quot;</p><p><strong><em>Five months into the fucking year and your monthly revenue is the same? That isn&apos;t good! <u>That isn&apos;t good at all!</u></em></strong></p><p>Also, what happened to that $550 million in cash? Why did Glean need more?<em> Hey wait a second, Glean announced its raise on June 18 2025, two days after</em><a href="https://cursor.com/blog/new-tier?ref=wheresyoured.at"><em><u>Cursor&apos;s pricing increase</u></em></a><em> and</em><a href="https://blog.replit.com/effort-based-pricing?ref=wheresyoured.at"><em><u>the same day that Replit announced a similar hike</u></em></a><em>!</em></p><p>It&apos;s almost as if its pricing dramatically increased due to the introduction of<a href="https://docs.anthropic.com/en/api/service-tiers?ref=wheresyoured.at"><u>Anthropic&apos;s Service Tiers</u></a> and<a href="https://openai.com/api-priority-processing/?ref=wheresyoured.at"><u>OpenAI&apos;s Priority Processing</u></a>.</p><p>I&apos;m guessing, but isn&apos;t it kind of weird that all of these companies raised money about the same time?</p><p>Hey, that reminds me.</p><h2 id="there-are-no-unique-generative-ai-companies-%E2%80%94-and-building-a-moat-based-on-technology-is-near-impossible"><strong>There Are No Unique Generative AI Companies &#x2014; And Building A Moat Based On Technology Is Near-Impossible</strong></h2><p>If you look at what generative AI companies do (note that the following is not a quality barometer), it&apos;s probably doing one of the following things:</p><ul><li>A chatbot, either one you ask questions or &quot;talk to&quot;<ul><li>This includes customer service bots</li></ul></li><li>Searching, summarizing or comparing documents, with increasing amounts of complexity of documents or quantity of documents to be compared<ul><li>This includes being able to &quot;ask questions&quot; of documents</li></ul></li><li>Web Search</li><li>&quot;Deep Research&quot; &#x2014; meaning long-form web search that generates a document</li><li>Generating text, images, voice, or in some rare cases video</li><li>Using generative AI to to write, edit or &quot;maintain&quot; code</li><li>Transcription</li><li>Translation</li><li>Photo and video editing</li></ul><p>Every single generative AI company that isn&apos;t OpenAI or Anthropic does one or a few of these things, and I mean<em> every</em> one of them, and it&apos;s because every single generative AI company uses Large Language Models, which have inherent limits on what they can do. LLMs can generate, they can search, they can edit (kind of!), they can transcribe (sometimes accurately!) and they can translate (often less accurately).</p><p>As a result, it&apos;s very, very difficult for a company to build something <strong>unique. </strong>Though Cursor is successful, it is ultimately a series of system prompts, a custom model that its users hate, a user interface and connections to models by OpenAI and Anthropic, both of whom have competing products <em>and</em> make money from Cursor and its competitors. Within weeks of Cursor&apos;s changes to its services,<a href="https://www.reddit.com/r/cursor/comments/1m0eusx/amazons_cursor_competitor_kiro_is_surprisingly/?ref=wheresyoured.at"><u>Amazon</u></a> and<a href="https://www.infoq.com/news/2025/03/trae-bytedance-claude-37-free/?ref=wheresyoured.at"><u>ByteDance</u></a> released competitors that, for the most part, do the same thing. <em>Sure</em> there&apos;s a few differences in how they&apos;re designed, but <strong><em>design is not a moat, especially in a high-cost, negative-profit business, where your only way of growing is to offer a product you can&apos;t afford to sustain.</em></strong></p><p>The only other moat you can build..is the services you provide, which, when your services are dependent on a Large Language Model, are dependent on the model developer, <strong><em>who, in the case of OpenAI and Anthropic, could simply clone your startup, because <u>the only valuable intellectual property is theirs.</u></em></strong></p><p>You may say &quot;well, nobody else has any ideas either,&quot; to which I&apos;ll say that I fully agree.<a href="https://www.wheresyoured.at/rotcombubble/"><u>My Rot-Com Bubble thesis</u></a> suggests we&apos;re out of hypergrowth ideas, and yeah, I think we&apos;re out of ideas related to Large Language Models too.</p><p>At this point, I think it&apos;s fair to ask &#x2014; are there <strong>any</strong> good companies you can build on top of Large Language Models? I don&apos;t mean <em>add features related to</em>, I mean <strong>an AI company that actually sells a product that people buy at scale that isn&apos;t called ChatGPT.</strong></p><h2 id="established-large-language-models-are-a-crutch"><strong>Established Large Language Models Are A Crutch</strong></h2><p>In previous tech booms, companies would make their <em>own</em> &#x201C;models&#x201D; &#x2014; their own infrastructure, or the things that make them distinct from other companies &#x2014; but the generative AI boom effectively changes that by making everybody build stuff on top of <em>somebody else&#x2019;s models</em>, because training your own models is both extremely expensive and requires vast amounts of infrastructure.</p><p>As a result, much of this &#x201C;boom&#x201D; is about a few companies &#x2014; really two, if we&#x2019;re honest &#x2014; getting other companies to try and build functional software for them.&#xA0;</p><h2 id="openai-and-anthropic-are-their-customers-weak-point"><strong>OpenAI And Anthropic Are Their Customers&apos; Weak Point</strong></h2><p>I wanted to add one note <strong>&#x2014; </strong>that, ultimately, OpenAI and Anthropic are bad for their customers. Their models are popular (by which I mean their customers&apos; customers will expect access to them) meaning that OpenAI and Anthropic can (as they did with Cursor) arbitrarily change pricing, service availability or functionality based on how they feel that day. Don&apos;t believe me?<a href="https://techcrunch.com/2025/06/05/anthropic-co-founder-on-cutting-access-to-windsurf-it-would-be-odd-for-us-to-sell-claude-to-openai/?ref=wheresyoured.at"><u>Anthropic cut off access to AI coding platform Windsurf because it <em>looked like</em> it might get acquired by OpenAI</u></a>.</p><p>Even by big tech standards this fucking sucks. And these companies will do it again!</p><h2 id="the-limited-use-cases-are-because-large-language-models-are-all-really-similar"><strong>The Limited Use Cases Are Because Large Language Models Are All Really Similar</strong></h2><p>Because all Large Language Models<a href="https://www.wsj.com/tech/ai/ai-training-data-synthetic-openai-anthropic-9230f8d8?gaa_at=eafs&amp;gaa_n=ASWzDAigPSiKga_s99AazhrLqlvtYZJNMBC9N34pkLxVKj22KKPUsjdEIVGUFIzWHT0%3D&amp;gaa_ts=68797f68&amp;gaa_sig=A29fPAcpvFfKoF9wk2d6WDWCKCCRhqkZLfAh7ZsjKVckbtd6oxkVhsXo1Ov4mkJJJPC4FCgDxOlXPKaZM2jcDw%3D%3D&amp;ref=wheresyoured.at"><u>require more data than anyone has ever needed</u></a>, they all basically have to use the same data, either taken from the internet or bought from one of a few companies (Scale, Surge, Turing, Together, etc.). While they can get customized data or do customized training/reinforcement learning, these models are all transformer-based, and they all function similarly, and the only way to make them different is by training them, which doesn&apos;t make them <em>much different</em>, just <em>better at things they already do.</em></p><h2 id="generative-ai-is-simply-too-expensive-to-build-a-sustainable-business-on-top-of-it"><strong>Generative AI Is Simply Too Expensive To Build A Sustainable Business On Top Of It</strong></h2><p>I already mentioned OpenAI and Anthropic&apos;s costs, as well as Perplexity&apos;s $50 million+ bill to Anthropic, Amazon and OpenAI<a href="https://www.wheresyoured.at/anthropic-is-bleeding-out/"><u>off of a measly $34 million in revenue</u></a>. These companies cost too much to run, and their functionality doesn&apos;t make enough money to make them make sense.</p><p>The problem isn&apos;t just the pricing, but how unpredictable it is.<a href="https://www.ciodive.com/news/generative-ai-drives-unmanageable-cloud-cost-finops/729126/?ref=wheresyoured.at"><u>As Matt Ashare wrote for CIO Dive last year</u></a>, generative AI makes a lot of companies&#x2019; lives difficult through the massive spikes in costs that come from power users, with few ways to mitigate their costs. One of the ways that a company manages their cloud bills is by having some degree of predictability &#x2014; which is difficult to do with the constant slew of new models and demands for new products to go with them, especially when said models can (and do) cost more with subsequent iterations.</p><p>As a result, it&apos;s hard for AI companies to <em>actually budget</em>.</p><h2 id="companies-are-using-the-term-agent-to-deceive-customers-and-investors"><strong>Companies Are Using The Term &quot;Agent&quot; To Deceive Customers and Investors</strong></h2><p>&quot;But Ed!&quot; you cry, &quot;What about AGENTS?&quot;</p><p><a href="https://www.youtube.com/watch?v=pE_x3UC1f3o&amp;ref=wheresyoured.at"><u>Let me tell you about agents</u></a>.</p><p>The term &quot;agent&quot; is one of the most egregious acts of fraud I&apos;ve seen in my entire career writing about this crap, and that includes the metaverse.</p><p>When you hear the word &quot;agent,&quot; you are meant to think of an autonomous AI that can go and do stuff <strong>without oversight</strong>, replacing somebody&apos;s job in the process, and companies have been pushing the boundaries of good taste and financial crimes in pursuit of them.</p><p>Most egregious of them is Salesforce&apos;s &quot;<a href="https://www.salesforce.com/agentforce/?ref=wheresyoured.at"><u>Agentforce</u></a>,&quot; which lets you &quot;deploy AI agents at scale&quot; and &quot;brings digital labor to every employee, department and business process.&quot; <strong>This is a blatant fucking lie. <u>Agentforce is a god damn chatbot platform, it&apos;s for launching chatbots, they can sometimes plug into APIs that allow them to access other information, <em>but they are neither autonomous nor &quot;agents&quot; by any reasonable definition.</em></u></strong></p><p>Not only does Salesforce not actually sell &quot;agents,&quot; its own research shows that agents only achieve around a 58% success rate on <strong>single-step tasks</strong>, meaning,<a href="https://www.theregister.com/2025/06/16/salesforce_llm_agents_benchmark/?ref=wheresyoured.at"><u>to quote The Register</u></a>, &quot;tasks that can be completed in a single step without needing follow-up actions or more information.&quot; On multi-step tasks &#x2014; so, you know, <em>most tasks</em> &#x2014; they succeed a depressing 35% of the time.</p><p>Last week, OpenAI announced its own &quot;ChatGPT agent&quot; that can allegedly go &quot;do tasks&quot; on a &quot;virtual computer.&quot;<a href="https://www.youtube.com/live/1jn_RpbPbEc?si=lifAoaH7VhMmo440&amp;ref=wheresyoured.at"><u>In its <strong>own demo</strong></u></a>, the agent took 21 or so minutes to spit out a plan for a wedding with destinations, a vague calendar and some suit options, and then showed a pre-prepared demo of the &quot;agent&quot; preparing an itinerary of how to visit every major league ballpark. In this example&apos;s case, &quot;agent&quot; took 23 minutes, and produced arguably the most confusing-looking map I&apos;ve seen in my life.</p><figure class="kg-card kg-image-card"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXcNoX8jZhZh9cufNmJzyhRgGm5h0WpDpwmtGTswmh0WPezUncScGHb5NZOfABQd0_Yo1_iWx3C4NxUoqNxKyRXNp6Dfc32MhyPpkBi8FhYj_K_emEP2v5p7b50Ac9gIhumf7sUQgA?key=TggKg1UXe62ansbtuP1HEw" class="kg-image" alt loading="lazy" width="333" height="163"></figure><p>It also missed out every single major league ballpark on the East Coast &#x2014; including Yankee Stadium and Fenway Park &#x2014; and added a random stadium in the middle of the Gulf of Mexico. What team is that, eh Sam? The Deepwater Horizon Devils? Is there a baseball team in North Dakota?&#xA0;</p><p>I should also be clear <strong>this was the pre-prepared example.</strong> As with every Large Language Model-based product &#x2014; and yes, that&apos;s what this is, even if OpenAI won&apos;t talk about what model &#x2014; results are extremely variable.</p><p>Agents are difficult, because tasks are difficult, even if they can be completed by a human being that a CEO thinks is stupid. What OpenAI appears to be doing is using a virtual machine to run scripts that its models trigger. Regardless of how well it works (it works very very poorly and inconsistently), it&apos;s also likely very expensive.</p><p>In any case, <strong>every single company you see using the word agent is trying to mislead you. </strong>Glean&apos;s &quot;<a href="https://www.glean.com/product/ai-agents?ref=wheresyoured.at"><u>AI agents</u></a>&quot; are chatbots with if-this-then-that functions that trigger events using APIs (the connectors between different software services), <strong>not taking actual actions, because that is not what LLMs can do.</strong></p><p><a href="https://www.servicenow.com/products/ai-agents.html?ref=wheresyoured.at"><u>ServiceNow&apos;s AI agents that allegedly &quot;act autonomously and proactively on your behalf&quot; are</u></a>, despite claiming they &quot;go beyond &#x2018;better chatbots,&#x2019;&quot; still ultimately chatbots that use APIs to trigger different events using if-this-then-that functions. Sometimes these chatbots can also answer questions that people might have, or trigger an event somewhere. Oh, right, that&apos;s the same thing.</p><p>The closest we have to an &quot;agent&quot; of any kind is a coding agent, which can make a list of things that you might do on a software project and then go and generate the code and push stuff to Github when you ask them to, and they can do so &quot;autonomously,&quot; in the sense that you can let them just run whatever task seems right. When I say &quot;ask them to&quot; or &quot;go and&quot; I mean that these agents are not remotely intelligent,<a href="https://www.reddit.com/r/ExperiencedDevs/comments/1krttqo/my_new_hobby_watching_ai_slowly_drive_microsoft/?ref=wheresyoured.at"><u>and when let run rampant fuck up everything and create a bunch of extra work</u></a>. Also,<a href="https://www.theregister.com/2025/07/11/ai_code_tools_slow_down/?ref=wheresyoured.at"><u> a study found that AI coding tools made engineers 19% slower</u></a>.</p><p>Nevertheless, <strong>none of these products are autonomous agents, and anybody using the term agent likely means &quot;chatbot.&quot;</strong></p><p><strong><em>And it&apos;s working because the media keeps repeating everything these companies say.</em></strong></p><h2 id="but-really-though-everybody-is-losing-money-on-generative-ai-and-nobodys-making-a-profit"><strong>But Really Though, Everybody Is Losing Money On Generative AI, And Nobody&apos;s Making A Profit</strong></h2><p>I realize we&apos;ve taken kind of a scenic route here, but I needed to lay the groundwork here, because I am well and truly alarmed.</p><p>According to a UBS report from the 26th of June, the public companies running AI services are making absolutely pathetic amounts of money from AI:</p><figure class="kg-card kg-image-card"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXdgzRoajkuHLV9x7EqtbN7nvvhX7FT4RBkbmFoxAPNnIavCnuHuletztwzNRaS-GTe8SRPdDeCu0mwnTgEulpixmn_BggsSfrd5OhPWGOJ65gg4TbitMp3YGaH0eTBWbyBQb2TVyA?key=TggKg1UXe62ansbtuP1HEw" class="kg-image" alt loading="lazy" width="589" height="243"></figure><p>ServiceNow&apos;s use of &quot;$250 million ACV&quot; &#x2014; so annual contract value &#x2014; may be one of the more honest explanations of revenue I&apos;ve seen, putting them in the upper echelons of AI revenue unless, of course, you think for two seconds, whether these are AI-specific contracts. Or, perhaps, are they contracts <em>including AI?</em> Eh, who cares. It&apos;s also year-long agreements that could churn, and<a href="https://www.gartner.com/en/newsroom/press-releases/2025-06-25-gartner-predicts-over-40-percent-of-agentic-ai-projects-will-be-canceled-by-end-of-2027?ref=wheresyoured.at"><u>according to Gartner, over 40% of &quot;agentic AI&quot; projects will be canceled by end of 2027</u></a>.</p><p>And really, ya gotta laugh at Adobe and Salesforce, both of whom have talked so god damn much about generative AI and yet have only made around $100 million in annualized revenue from it. Pathetic! These aren&apos;t futuristic numbers! They&apos;re barely product categories! And none of this seems to include costs.</p><p><em>Oh well.</em></p><h2 id="openai-and-anthropic-are-the-generative-ai-industry-are-deeply-unstable-and-unsustainable-and-are-critical-to-the-ai-trade-continuing"><strong>OpenAI and Anthropic <em>Are</em> The Generative AI Industry, Are Deeply Unstable and Unsustainable, and Are Critical To The AI Trade Continuing</strong></h2><p>I haven&apos;t really spent time on my favourite subject &#x2014;<a href="https://www.wheresyoured.at/openai-is-a-systemic-risk-to-the-tech-industry-2/"><u>OpenAI being a systemic risk to the tech industry</u></a>.</p><p>To recap:</p><ul><li>OpenAI and Anthropic both lose billions of dollars a year <strong>after revenue</strong>, and their stories <strong><u>do not mirror any other startup in history, not Uber, not Amazon Web Services, <em>nothing.</em></u></strong><a href="https://www.wheresyoured.at/to-serve-altman/"><u>I address the Uber point in this article</u></a>.</li><li>SoftBank is putting itself in dire straits <em>simply to fund OpenAI once. </em>This deal threatens its credit rating, with SoftBank having to take on what will be multiple loans <strong>to fund the remaining $30 billion of OpenAI&apos;s $40 billion round,</strong><a href="https://www.theinformation.com/articles/openai-discussed-raising-money-saudi-arabia-indian-investors?rc=kz8jh3&amp;ref=wheresyoured.at"><strong><u>which has yet to close and OpenAI is, in fact, still raising</u></strong></a><strong>.</strong><ul><li>This is before you consider the other $19 billion that SoftBank has agreed to contribute to the Stargate data center project, money that it does not currently have available.</li></ul></li><li>OpenAI has promised $19 billion to the Stargate data center project, money it <strong>does not have</strong> and <strong>cannot get without SoftBank&apos;s funds.</strong><ul><li><strong><u>Again, neither SoftBank nor OpenAI has the money for Stargate right now.</u></strong></li></ul></li><li>OpenAI must convert to a for-profit by the end of 2025, or it loses $20 billion of the remaining $30 billion of funding. If it does not convert by October 2026, its current funding converts to debt.<a href="https://www.wheresyoured.at/why-did-microsoft-invest-in-openai/"><u>It is demanding remarkable, unreasonable concessions from Microsoft</u></a>, which is refusing to budge and<a href="https://www.ft.com/content/072e90fe-1c8c-415c-8024-5996b1ebb3cb?ref=wheresyoured.at"><u>is willing to walk away from the negotiations necessary to convert</u></a>.</li><li>OpenAI does not have a path to profitability, and its future, like Anthropic&apos;s, is dependent on a continual flow of capital from venture capitalists and big tech, who must also continue to expand infrastructure.</li></ul><p>Anthropic is in a similar, but slightly better position &#x2014;<a href="https://www.theinformation.com/articles/anthropic-revenue-hits-4-billion-annual-pace-competition-cursor-intensifies?rc=kz8jh3&amp;ref=wheresyoured.at"><u>it is set to lose $3 billion this year on $4 billion of revenue</u></a>. It also has no path to profitability,<a href="https://www.wheresyoured.at/anthropic-and-openai-have-begun-the-subprime-ai-crisis/"><u>recently jacked up prices on Cursor, its largest customer</u></a>,<a href="https://techcrunch.com/2025/07/17/anthropic-tightens-usage-limits-for-claude-code-without-telling-users/?utm_campaign=social&amp;utm_source=bluesky&amp;utm_medium=organic"><u>and had to put restraints on Claude Code</u></a><a href="https://www.wheresyoured.at/anthropic-is-bleeding-out/"><u>after allowing users to burn 100% to 10,000% of their revenue</u></a>. These are the actions of a desperate company.</p><p>Nevertheless, OpenAI and Anthropic&apos;s revenues amount to, by my estimates, more than half of the entire revenue of the generative AI industry, <strong>including the hyperscalers.</strong></p><p><strong>To be abundantly clear: <u>the two companies that amount to around half of <em>all generative artificial intelligence revenue are ONLY LOSING MONEY.</em></u></strong></p><p>I&apos;ve said a lot of this before, which is why I&apos;m not harping on about it, <strong>but the most important company in the entire AI industry needs to convert by the end of the year or it&apos;s effectively dead, and even if it does, it burns billions and billions of dollars a year and will die without continual funding. It has no path to profitability, and anyone telling you otherwise is a liar or a fantasist.</strong></p><p>Worse still, outside of OpenAI...what is there, really?</p><h2 id="there-is-no-real-ai-adoption-nor-is-there-any-significant-revenue"><strong>There Is No Real AI Adoption, Nor Is There Any Significant Revenue</strong></h2><p><a href="https://www.wheresyoured.at/wheres-the-money/"><u>As I wrote earlier in the year</u></a>, there is really no significant adoption of generative AI services or products. ChatGPT has 500 million weekly users, and otherwise, it seems that other services struggle to get 15 million of them. And while the 500 million weekly users sounds &#x2014; and, in fairness, is &#x2014; impressive, there&#x2019;s a world of difference between someone using a product as part of their job, and someone dicking around with an image generator, or a college student trying to cheat on their homework.</p><p><strong>Sidebar: </strong>Google cheated by<a href="https://www.pcworld.com/article/2638233/so-long-google-assistant-its-geminis-world-now.html?ref=wheresyoured.at"><u>combining Google Gemini with Google Assistant</u></a> to claim that it has 350 million users. Don&apos;t care, sorry.</p><p>This is worrying on so many levels, chief of which is that everybody has been talking about AI for three god damn years, everybody has said &quot;AI&quot; in every earnings and media appearance and exhausting blog post, and we still can&apos;t scrape together the bits needed to make a functional industry.</p><p>I know some of you will probably read this and point to ChatGPT&apos;s users, and I<a href="https://www.wheresyoured.at/make-fun-of-them/"><u>quote myself here</u></a>:</p><p>It has, allegedly, 500 million weekly active users &#x2014; and, by the last count, only 15.5 million paying subscribers, an absolutely putrid conversion rate even before you realize that the actual conversion rate would be monthly active subscribers. That&#x2019;s how any real software company actually defines its metrics, by the fucking way.</p><p>Why is this impressive? Because it grew fast? It literally had more PR and more marketing and more attention and more opportunities to sell to more people than any company has ever had in the history of anything. Every single industry has been told to think about AI for three years, and they&#x2019;ve been told to do so because of a company called OpenAI. There isn&#x2019;t a single god damn product since Google or Facebook that has had this level of media pressure, and both of those companies launched without the massive amount of media (and social media) that we have today.&#xA0;</p><p>ChatGPT is a very successful growth product and an absolutely horrifying business. OpenAI is a banana republic that cannot function on its own, it does not resemble Uber, Amazon Web Services, or any other business in the past other than WeWork, the other company that SoftBank spent way too much money on.</p><p>And outside of ChatGPT, there really isn&apos;t anything else.</p><h2 id="yes-generative-ai-does-something-but-ai-is-predominantly-marketed-based-on-lies"><strong>Yes, Generative AI &quot;Does Something,&quot; But AI Is Predominantly Marketed Based On Lies</strong></h2><p>Before I wrap up &#x2014; I&apos;m tired, and I imagine you are too &#x2014; I want to address something.</p><p>Yes, generative AI has functionality. There are coding products and search products that people like and pay for. As I have discussed above, <strong>none of these companies are profitable, and until one of them is profitable, generative AI-based companies are not real businesses.</strong></p><p>In any case, the problem isn&apos;t so much that LLMs &quot;don&apos;t do anything,&quot; but that people talk about them doing things they can&apos;t do.</p><ul><li>The use of the word &quot;agent&quot; is a deliberate attempt to suggest that LLMs are autonomous.</li><li>Any and all stories about AI replacing jobs are intentionally manipulative attempts to boost stock valuations and suggest that models are capable of replacing human workers at scale.<a href="https://www.cnn.com/2025/05/30/business/anthropic-amodei-ai-jobs-nightcap?ref=wheresyoured.at"><u>Allison Morrow of CNN has an excellent piece about this</u></a>.<a href="https://www.wheresyoured.at/sic/"><u>As I discussed in this piece</u></a>, this is one of the more egregious failures of the tech media I&apos;ve ever seen, willingly publishing Dario Amodei outright making stuff up.</li><li>The discussion of the term &quot;AGI&quot; is an attempt to suggest that Large Language Models can create conscious intelligence,<a href="https://www.youtube.com/watch?v=4__gg83s_Do&amp;ref=wheresyoured.at"><u>a fictional concept that Meta&apos;s chief AI scientist says won&apos;t come from scaling up LLMs</u></a>.<ul><li>Members of the media: every time you talk about the &quot;really smart engineers they&apos;re paying,&quot; know that you are doing marketing for these companies, when what&apos;s really happening is people are giving tens of millions of dollars to guys who will work on teams that are pursuing a totally-unproven concept.</li></ul></li><li>The use of the word &quot;singularity&quot; is similarly manipulative.</li><li>The use of<a href="https://www.axios.com/2025/06/20/ai-models-deceive-steal-blackmail-anthropic?ref=wheresyoured.at"><u>stories about models &quot;lying, cheating and stealing to reach goals&quot; or &quot;stop themselves being turned off&quot;</u></a> are intentionally deceptive, as these models can (and clearly are) being prompted to take these actions.<ul><li>To be abundantly clear, the manipulative suggestion here is that these models are autonomous or conscious in some way, which they are not.</li></ul></li></ul><p>I believe that the generative AI market is a $50 billion revenue industry masquerading as a $1 trillion one, and the media is helping.</p><h2 id="the-ai-trade-is-entirely-about-gpus-and-is-incredibly-brittle-as-a-result"><strong>The AI Trade Is Entirely About GPUs, And Is Incredibly Brittle As A Result</strong></h2><p>As I&apos;ve explained at length, the AI trade is not one based on revenue, user growth, the efficacy of tools or significance of any technological breakthrough. Stocks are not moving based on whether they are making money on AI, because if they were, they&apos;d be moving downward. However, due to the vibes-based nature of the AI trade, companies are benefiting<a href="https://www.morningstar.com/stocks/alphabet-earnings-ai-monetization-continues-improve-ad-spending-remains-strong?ref=wheresyoured.at"><u>from the press inexplicably crediting growth to AI with no proof that that&apos;s the case</u></a>.</p><p><a href="https://www.wheresyoured.at/oai-business/"><u>OpenAI is a terrible business</u></a>, and the only businesses worse than OpenAI are the companies built on top of it. Large Language Models are too expensive to run, and have limited abilities beyond the ones I&apos;ve named previously, and because everybody is running models that all, on some level, do the same thing, it&apos;s very hard for people to build really innovative products on top of them.</p><p>And, ultimately, <em>this entire trade hinges on GPUs.</em></p><p><a href="https://www.wheresyoured.at/core-incompetency/#:~:text=Problem%20Loan%20Number%202%3A%20DDTL%202.0"><u>CoreWeave</u></a> was initially funded by NVIDIA, its IPO funded partially by NVIDIA, NVIDIA is one of its customers, and CoreWeave raises debt on the GPUs it buys from NVIDIA to build more data centers, while also using the money to buy GPUs from NVIDIA. This isn&#x2019;t me being polemic or hysterical &#x2014; this is quite literally what is happening, and how CoreWeave operates. If you aren&#x2019;t alarmed by that, I&#x2019;m not sure what to tell you.</p><p>Elsewhere, <a href="https://www.ft.com/content/a9cd130f-f6bf-4750-98cc-19d87394e657?ref=wheresyoured.at"><u>Oracle is buying $40 billion in GPUs</u></a> for<a href="https://www.theinformation.com/briefings/oracle-ceo-says-openais-stargate-venture-formed-yet?rc=kz8jh3&amp;ref=wheresyoured.at"><u>the still-unformed Stargate data center project</u></a>, and<a href="https://www.theguardian.com/technology/2025/jul/16/zuckerberg-meta-data-center-ai-manhattan?ref=wheresyoured.at"><u>Meta is building a Manhattan-sized data center to fill with NVIDIA GPUs</u></a>.</p><p>OpenAI is Microsoft&apos;s largest Azure client &#x2014; an insanely risky proposition on multiple levels, not simply in the fact that it&#x2019;s serving the revenue at-cost but that<a href="https://www.wheresyoured.at/why-did-microsoft-invest-in-openai/"><u>Microsoft executives believed OpenAI would fail in the long term when they invested</u></a> in 2023 &#x2014; and Microsoft is NVIDIA&apos;s largest client for GPUs, meaning that any changes to Microsoft&apos;s future interest in OpenAI, such as<a href="https://www.wheresyoured.at/power-cut/"><u>reducing its data center expansion</u></a>, would eventually hit NVIDIA&apos;s revenue.</p><p>Why do you think <a href="https://www.wheresyoured.at/deep-impact/"><u>DeepSeek</u></a> shocked the market? It wasn&apos;t because of any clunky story around training techniques. It was because it said to the market that NVIDIA might not sell more GPUs every single quarter in perpetuity.</p><p>Microsoft, Meta, Google, Apple, Amazon and Tesla aren&apos;t <em>making much money</em> from AI &#x2014; in fact, they&apos;re losing billions of dollars on whatever revenues they do make from it. Their stock growth is not coming from actual revenue, but the vibes around &quot;being an AI company,&quot; which means absolutely jack shit when you don&apos;t have the users, finances, or products to back them up.</p><p>So, really, everything comes down to NVIDIA&apos;s ability to sell GPUs, and this industry, if we&apos;re really honest, at this point only exists to do so. Generative AI products do not provide significant revenue growth, its products are not useful in the way that unlocks significant business value, and the products that have some adoption run at such a grotesque loss.</p><h2 id="im-alarmed"><strong>I&apos;m Alarmed!</strong></h2><p>I realize I&apos;ve thrown a lot at you, and, for the second time this year, written the longest thing I&apos;ve ever written.</p><p>But I needed to write this, because I&apos;m really worried.</p><p>We&apos;re in a bubble. If you do not think we&apos;re in a bubble, you are not looking outside.<a href="https://gizmodo.com/wall-streets-ai-bubble-is-worse-than-the-1999-dot-com-bubble-warns-a-top-economist-2000630487?ref=wheresyoured.at"><u>Apollo Global Chief Economist Torsten Slok said it last week</u></a>. Well, okay, what he said was much worse:</p><blockquote>&#x201C;The difference between the IT bubble in the 1990s and the AI bubble today is that the top 10 companies in the S&amp;P 500 today are more overvalued than they were in the 1990s,&#x201D; Slok wrote in a recent research note that was widely shared across social media and financial circles.</blockquote><p>We are in a bubble. Generative AI does not do the things that it&apos;s being sold as doing, and the things it can actually do aren&apos;t the kind of things that create business returns, automate labor, or really do much more than one extension of a cloud software platform. The money isn&apos;t there, the users aren&apos;t there, every company seems to lose money and some companies lose so much money that it&apos;s impossible to tell how they&apos;ll survive.</p><p>Worse still, this bubble is entirely symbolic. The bailouts of the Great Financial Crisis were focused on banks and funds that had failed because they ran out of money, and the TARP initiative existed to plug the holes with low-interest loans.</p><p>There are few holes to plug here, because even if OpenAI and Anthropic somehow became eternal money-burners, <em>the AI trade exists based on the continued and continually-increasing sale and use of GPUs.</em> There are limited amounts of capital, but also limited amounts of data centers to actually put GPUs, and on top of that, at some point growth will slow at one of the Magnificent 7, <em>at which point costs will have to come down from things that lose them tons of money, such as generative AI.</em></p><p><a href="https://bsky.app/profile/edzitron.com/post/3lmkahymkec2t?ref=wheresyoured.at" rel="noreferrer"><u>Before you ask</u>-</a></p><h3 id="but-isn%E2%80%99t-the-cost-of-inference-going-down"><strong>But, Isn&#x2019;t The Cost Of Inference Going Down?</strong></h3><p>You do not have proof for this statement! The cost of tokens going down is not the same thing as the cost of inference goes down! Everyone saying this is saying it because a guy once said it to them! You don&apos;t have proof! I have more proof for what I am saying!</p><p>While <em>it theoretically might be,</em> all evidence points to larger models costing more money, especially reasoning-heavy ones like Claude Opus 4. Inference is not the only thing happening, and if this is your one response, you are a big bozo and doofus and should go back to making squeaky noises when you see tech executives or hear my name.</p><h3 id="but-ed-what-about-asics"><strong>But Ed, What About ASICs?</strong></h3><p>Okay, so one argument is that these companies will use ASICs &#x2014; customized chips for specific operations &#x2014; to reduce the amount they&apos;re spending.</p><p>A few thoughts:</p><ul><li>When? Say<a href="https://www.reuters.com/technology/artificial-intelligence/openai-builds-first-chip-with-broadcom-tsmc-scales-back-foundry-ambition-2024-10-29/?ref=wheresyoured.at"><u>OpenAI and Broadcom actually build their ASIC in 2026</u></a> (they won&apos;t) &#x2014; how many of them will they build? Do they have contracts with companies that can actually produce high-performance silicon, of which there are only three (Samsung, TSMC, and arguably SMIC, which is currently sanctioned), and these companies typically have their capacity booked well in advance. Even starting a production run of a semiconductor product can take weeks. Do they have the server architecture prepared? Have they tested it? Does it work? Is the performance actually good?<a href="https://www.theinformation.com/articles/microsofts-ai-chip-effort-falls-behind?rc=kz8jh3&amp;ref=wheresyoured.at"><u>Microsoft has failed to create a workable, reliable ASIC</u></a>. What makes OpenAI special?</li><li>It takes a lot of money to build these chips and they are yet to prove they&apos;re better than NVIDIA GPUs for AI compute, and even if they do, are they going to retrofit every data center? Can they build enough?</li><li>If this actually happens, <em>it still fucks up the AI trade. NVIDIA STILL NEEDS TO SELL GPUs!</em></li></ul><hr><p>I am worried because despite all of these obvious, brutal and near-unfixable problems, everybody is walking around acting like things are going great with AI. The New York Times<a href="https://www.nytimes.com/2025/06/16/magazine/using-ai-hard-fork.html?ref=wheresyoured.at"><u>claims everybody is using AI for everything</u></a> &#x2014; a blatant lie, one that exists to prop up an industry that has categorically failed to deliver the innovations or returns that it promised, yet still receives glowing press from a tech and business media that refuses to look outside and see that the sky is red and frogs are landing everywhere.</p><p>Other than the frog thing, I&apos;m not even being dramatic. Everywhere you look in the AI trade, things get worse &#x2014; no revenue, billions being burned, no moat, no infrastructure play, no comparables in history other than the dot com bubble and WeWork, and a series of flagrant lies spouted by the powerful and members of the press that are afraid of moving against market consensus.</p><p>Worse still, despite NVIDIA&apos;s strength, <em>NVIDIA is the market&apos;s weakness</em>, through no fault of its own, really. Jensen Huang sells GPUs, people want to buy GPUs, and now the rest of the market is leaning aggressively on one company, feeding it billions of dollars in the hopes that the things they&apos;re buying start making them a profit.</p><p>And that really is the most ridiculous thing. At the center of the AI trade sits GPUs that, on installation, immediately start losing the company in question money. Large Language Models burn cash for negative returns to build products that all kind of work the same way.</p><p>If you&apos;re going to say I&apos;m wrong, sit and think carefully about why. Is it because you don&apos;t want me to be right? Is it because you think &quot;these companies will work it out&quot;? This isn&apos;t anything like Uber, AWS, or any other situation. It is its own monstrosity, a creature of hubris and ignorance caused by<a href="https://www.wheresyoured.at/rotcombubble/"><u>a tech industry that&apos;s run out of ideas</u></a>, built on top of <em>one company</em>.</p><p>You can plead with me all you want about how there are actual people using AI. You&apos;ve probably read the &quot;<a href="https://fly.io/blog/youre-all-nuts/?ref=wheresyoured.at"><u>My AI Skeptic Friends Are All Nuts</u></a>&quot; blog, and if you&apos;re gonna send it to me,<a href="https://ludic.mataroa.blog/blog/contra-ptaceks-terrible-article-on-ai/?ref=wheresyoured.at"><u>read the response from Nik Suresh first</u></a>. If you&apos;re going to say that I &quot;don&apos;t speak to people who actually use these products,&quot; you are categorically wrong and in denial.</p><p>I am only writing with this aggressive tone because, for the best part of two years, I have been made to repeatedly explain myself in a way that no AI &quot;optimist&quot; is made, and I admit I resent it. I have written hundreds of thousands of words with hundreds of citations, and <em>still, to this day</em>, there are people who claim I am somehow flawed in my analysis, that I&apos;m missing something, that I am somehow failing to make my case.</p><p>The only people failing to make their case are the AI optimists still claiming that these companies are making &quot;powerful AI.&quot; And once this bubble pops, I will be asking for an apology.</p><h2 id="i-dont-like-whats-happening"><strong>I Don&apos;t Like What&apos;s Happening</strong></h2><p>I love ending pieces with personal thoughts about stuff because I am an emotional and overly honest person, and I enjoy writing a lot.</p><p>I do not, however, enjoy telling you at length how brittle everything is. An ideal tech industry would be one built on innovation, revenue, real growth based on actual business returns that helped humans be better, not <em>outright lie</em> about replacing them. All that generative AI has done is show how much lust there is in both the markets <em>and the media </em>for replacing human labor &#x2014; and yes, it is in the media too. I truly believe there are multiple reporters who feel genuine excitement when they write scary stories about how Dario Amodei says white collar workers will be fired in the next few years in favour of &quot;agents&quot; that will never exist.</p><p>Everything I&#x2019;m discussing is the result of <a href="https://www.wheresyoured.at/the-rot-economy/"><u>the Rot Economy thesis</u></a> I wrote back in 2023 &#x2014; the growth-at-all-costs mindset that has driven every tech company to focus on increasing quarterly revenue numbers, even if the products suck, or are deeply unprofitable, or, in the case of generative AI, <strong><em>both.</em></strong></p><p>Nowhere has there been a more pungent version of the Rot Economy than in Large Language Models, or more specifically<em> GPUs</em>. By making everything about growth, you inevitably reach a point where the only thing you know how to do is spend money, and both LLMs and GPUs allowed big tech to <em>do the thing that worked before</em> &#x2014; building a bunch of data centers and buying a bunch of chips &#x2014; without making sure they&#x2019;d done the crucial work of &#x201C;making sure this would create products people like.&#x201D; As a result, we&#x2019;re now sitting on top of one of the most brittle situations in economic history &#x2014; our markets held up by whether four or five companies will continue to buy chips that start losing them money the second they&#x2019;re installed.</p><p>I am disgusted by how many people are unwilling or unable to engage with the truth, favouring instead a scornful, contemptuous tone toward anybody who doesn&apos;t believe that generative AI is the future. If you are a writer that writes about AI smarmily insulting people who &quot;don&apos;t understand AI,&quot; you are a shitty fucking writer, because either AI isn&apos;t that good or you&apos;re not good at explaining why it&apos;s good. Perhaps it&apos;s both.</p><p>If you want to know my true agenda, it&apos;s that I see something in generative AI and its boosters something I truly dislike. Large Language Models authoritatively state things that are incorrect because they have no concept of right or wrong. I believe that the writers, managers and executives that find it exciting do so because it gives them the ability to pretend to be intelligent without actually learning anything, to do everything they can to avoid actual work or responsibility for themselves or others.</p><p>There is an overwhelming condescension that comes from fans of generative AI &#x2014; the sense that they know something you don&apos;t, something they double down on. We are being forced to use it by bosses, or services we like that now insist it&apos;s part of our documents or our search engines, not because it does something, but because those pushing it need us to use it to prove that they know what&apos;s going on.</p><p><a href="https://substack.com/home/post/p-168513007?ref=wheresyoured.at"><u>To quote my editor Matt Hughes</u></a>: &quot;...generative AI...is an expression of contempt towards people, one that considers them to be a commodity at best, and a rapidly-depreciating asset at worst.&quot;</p><p>I haven&apos;t quite cracked why, but generative AI also brings out the worst in some people. By giving the illusion of labor, it excites those who are desperate to replace or commoditize it. By giving the illusion of education, it excites those who are too idle to actually learn things<a href="https://futurism.com/former-ceo-uber-ai?ref=wheresyoured.at"><u>by convincing them that in a few minutes they can learn quantum physics</u></a>. By giving the illusion of activity, it allows the gluttony of<a href="https://www.wheresyoured.at/the-era-of-the-business-idiot/"><u>Business Idiots</u></a> that control everything to pretend that they do something. By giving the illusion of<a href="https://davekarpf.substack.com/p/silicon-valley-runs-on-futurity?ref=wheresyoured.at"><u>futurity</u></a>, it gives reporters that have long-since disconnected from actual software and hardware the ability to pretend that they know what&apos;s happening in the tech industry.</p><p>And, fundamentally, its biggest illusion is economic activity, because despite being questionably-useful and burning billions of dollars, its need to do so creates a justification for spending billions of dollars on GPUs and data center sprawl, which allows big tech to sink money into something and give the illusion of growth.</p><p>I love writing, but I don&apos;t love writing this. I think I&apos;m right, and it&#x2019;s not something I&#x2019;m necessarily happy about.&#xA0; If I&apos;m wrong, I&apos;ll explain how I&apos;m wrong in great detail, and not shy away from taking accountability, but I really do not think I am, and that&apos;s why I&apos;m so alarmed.</p><p>What I am describing is a bubble, and one with an obvious weakness: one company&apos;s ability to sell hardware to four or five other companies, all to run services that lose billions of dollars.</p><p>At some point the momentum behind NVIDIA slows. Maybe it won&apos;t even be sales slowing &#x2014; maybe it&apos;ll just be the suggestion that one of its largest customers won&apos;t be buying as many GPUs. Perception matters just as much as actual numbers, and sometimes more, and a shift in sentiment could start a chain of events that knocks down the entire house of cards.&#xA0;</p><p>I don&apos;t know when, I don&apos;t know how, but I really, really don&apos;t know how I&apos;m wrong.</p><p>I hate that so many people will see their retirements wrecked, and that so many people intentionally or accidentally helped steer the market in this reckless, needless and wasteful direction, all because big tech didn&#x2019;t have a new way to show quarterly growth. I hate that <a href="https://futurism.com/microsoft-boss-ai-advice?ref=wheresyoured.at"><u>so many people have lost their jobs</u></a> because companies are spending the equivalent of the entire GDP of some European countries on data centers and GPUs that won&#x2019;t actually deliver any value.&#xA0;</p><p>But my purpose here is to explain to you, no matter your background or interests or creed or whatever way you found my work, why it happened. As you watch this collapse, I want you to tell your friends about why &#x2014; the people responsible and the decisions they made &#x2014; and make sure it&#x2019;s clear that there <em>are</em> people responsible. </p><p>Sam Altman, Dario Amodei, Satya Nadella, Sundar Pichai, Tim Cook, Elon Musk, Mark Zuckerberg and Andy Jassy have overseen a needless, wasteful and destructive economic force that will harm our markets (and by a larger extension our economy) and the tech industry writ large, and when this is over, they must be held accountable.</p><p>And remember that you, as a regular person, can understand all of this. These people want you to believe this is black magic, that you are wrong to worry about the billions wasted or question the usefulness of these tools. You are smarter than they reckon and stronger than they know, and a better future is one where you recognize this, and realize that power and money doesn&#x2019;t make a man righteous, right, or smart.</p><p>I started writing this newsletter with 300 subscribers, and I now have 67,000 and a growing premium subscriber base. I am grateful for the time you&#x2019;ve given me, and really hope that I continue to help you see the tech industry for what it currently is &#x2014; captured almost entirely by people that have no interest in building the future.<br></p>]]>
			</content:encoded>
		</item>
		<item>
			<title>
				<![CDATA[The Remarkable Incompetence At The Heart Of Tech]]>
			</title>
			<description>
				<![CDATA[<p>Hello premium subscribers! Today I have the first guest post I&apos;ve ever commissioned (read: paid) on Where&apos;s Your Ed At - <a href="https://www.linkedin.com/in/nik-suresh/?ref=wheresyoured.at" rel="noreferrer">Nik Suresh</a>, <a href="https://ludic.mataroa.blog/about-me/?ref=wheresyoured.at" rel="noreferrer">one of the greatest living business and tech writers</a>, best-known for his piece <a href="https://ludic.mataroa.blog/blog/i-will-fucking-piledrive-you-if-you-mention-ai-again/?ref=wheresyoured.at" rel="noreferrer">I Will Fucking Piledrive You If You Mention AI Again</a></p>]]>
			</description>
			<link>https://www.wheresyoured.at/the-remarkable-incompetence-at-the-heart-of-tech/</link>
			<guid isPermaLink="false">687a5797b78fba00013b9cc4</guid>
			<dc:creator>
				<![CDATA[Edward Zitron]]>
			</dc:creator>
			<pubDate>Fri, 18 Jul 2025 14:51:41 GMT</pubDate>
			<content:encoded>
				<![CDATA[<p>Hello premium subscribers! Today I have the first guest post I&apos;ve ever commissioned (read: paid) on Where&apos;s Your Ed At - <a href="https://www.linkedin.com/in/nik-suresh/?ref=wheresyoured.at" rel="noreferrer">Nik Suresh</a>, <a href="https://ludic.mataroa.blog/about-me/?ref=wheresyoured.at" rel="noreferrer">one of the greatest living business and tech writers</a>, best-known for his piece <a href="https://ludic.mataroa.blog/blog/i-will-fucking-piledrive-you-if-you-mention-ai-again/?ref=wheresyoured.at" rel="noreferrer">I Will Fucking Piledrive You If You Mention AI Again</a>, probably my favourite piece of the AI era.</p><p>I want to be clear that I take any guest writing on here very seriously, and do not intend to do this regularly. The quality bar is very high, which is why I started with Nik. I cannot express enough how much I love his work. <a href="https://ludic.mataroa.blog/blog/brainwash-an-executive-today/?ref=wheresyoured.at" rel="noreferrer">Brainwash An Executive Today</a> is amazing, <a href="https://ludic.mataroa.blog/blog/contra-ptaceks-terrible-article-on-ai/?ref=wheresyoured.at" rel="noreferrer">as is his teardown</a> of Contra Ptacek&apos;s <a href="https://fly.io/blog/youre-all-nuts/?ref=wheresyoured.at" rel="noreferrer">All My AI Skeptic Friends Are Nuts</a>. Nik is a software engineer, the executive director of an IT consultancy, and in general someone who actually understands software and the industries built around selling it.  </p><p>You can check out his work <a href="https://ludic.mataroa.blog/hits/?ref=wheresyoured.at"><u>here</u></a> and check out his team <a href="https://www.hermit-tech.com/?ref=wheresyoured.at"><u>here</u></a>.</p><hr><p>Ed asked me to write about why leaders around the world are constantly buying software they don&#x2019;t need. He probably had a few high-profile companies in mind, like Snowflake. Put aside whether Snowflake is a good product &#x2013; most people don&#x2019;t know what a database <em>is</em>, so why on earth does a <em>specialized</em> and very expensive database have a market cap of $71B?&#xA0;</p><p>That&#x2019;s a fair question &#x2013; and being both a software engineer and the managing director at a tech consultancy, I can talk about what&#x2019;s happening on the ground. And yes, people <em>are </em>buying software that they don&#x2019;t need.</p><p>I <em>wish</em> that was the extent of our problems.</p><p>Pointless software purchases are a comparatively minor symptom of the seething rot and stunning incompetence at the core of most companies&#x2019; technical operations. Things are bad to a degree that sounds <em>unbelievable</em> to people that don&#x2019;t have the background to witness or understand it firsthand.</p><p>Here is my thesis:</p><p>Most enterprise SaaS purchases are simply a distraction &#x2013; total wishful thinking &#x2013; for leaders that hope waving a credit card is going to absolve them of the need to understand and manage the true crisis in software engineering. Buying software has many desirable characteristics &#x2013; everyone else is doing it, it can stall having to deliver results for years, and allows leaders to adopt a thin veneer of innovation. In reality, they&#x2019;re&#xA0; settling for totally conservative failure. The <em>real</em> crisis, the one they&#x2019;re ignoring, is only resolved by deep systems thinking, emotional awareness, and an <em>actual understanding</em> of the domain they operate in.</p><p>And that crisis, succinctly stated, is thus: our institutions are filled to burst with incompetents cosplaying as software engineers, forked-tongue vermin-consultants hawking lies to the desperate, and leaders who consider think reading Malcolm Gladwell makes you a profound intellectual (if you don&#x2019;t understand why this is a problem, please report to my office for immediate disciplinary action).&#xA0;</p><p>I&#x2019;m going to try and explain things as they&#x2019;re actually like at normal companies. Welcome to my Hell, and hold your screams until the end.</p><h2 id="i-the-industry-is-sick-in-a-way-that-can%E2%80%99t-be-solved-by-saas-spend"># I. The Industry is Sick in a Way That Can&#x2019;t Be Solved by SaaS Spend</h2><p>The typical team at a large organization &#x2013; in a truly random office, of the sort that buys products like Salesforce but will otherwise never be in the news &#x2013; might literally deliver nothing of value for years at a time. I know, I know, how can people be doing nothing for <em>years?</em> A day? Sure, everyone has an off-day. Weeks? Maybe. But <em>years</em>? Someone&#x2019;s going to notice eventually, right?</p><p>Most industries have long-since been seized by a variety of tedious managerialism that&#x2019;s utterly divorced from actually accomplishing any work, but the abstract nature of programming allows for <em>software</em> teams to do nothing to a degree that stretches credulity. Code can be reported as 90% done in meetings for years; there&#x2019;s no physical artifact that non-programmers can use to verify it. There&#x2019;s no wall with half the bricks laid, just lines of incomprehensible text which someone assures you constitutes Value.&#xA0;</p><p>This is a real, well-known phenomenon amongst software engineers, but no one <em>believes us</em> when we bring it up, because surely there&#x2019;s no way profit-obsessed capitalists are spending millions of dollars on teams with no visible output.</p><p>I know it sounds wild. I feel like I&#x2019;ve been taking crazy pills for years. But enjoy some anecdotes:</p><p>My first tech job was &#x201C;data scientist,&#x201D; a software engineering subspecialty focused on advanced statistical methods (or &#x201C;AI&#x201D; if you are inclined towards grifting). When a data scientist successfully applies statistical methods to solve a business problem, it&#x2019;s called producing a &#x201C;model.&#x201D; My team produced no models in <em>two years</em>, but nonetheless received an innovation award from leadership, and they <em>kept paying me six figures</em>. I know small squads of data scientists with salaries totaling millions that haven&#x2019;t deployed working models for twice that long.</p><p>During my next job, at an entirely unrelated organization, I was tasked with finishing a website that had been &#x201C;almost done&#x201D; for a few years, whose main purpose was for a team to do some data entry. This is something that takes about a competent team two weeks &#x2013; my current team regularly does <em>more complicated </em>things in that time. I finished in good time and handed it to the IT department to host, a task that should take a day if done very efficiently, or perhaps three months if you were dealing with extreme bureaucracy and a history of bad technical decisions. It&#x2019;s been five years and the organization has to deploy the finished product. I later discovered that the company had spent four years trying<em> before I joined</em>. It&#x2019;s just a website! When the internet was coming up, people famously hired <em>teenagers</em> to do this!</p><p>I&#x2019;m not even going to get into my third and fourth jobs, except to say they involved some truly spectacular displays of technical brilliance, such as discovering a team <a href="https://ludic.mataroa.blog/blog/i-accidentally-saved-half-a-million-dollars/?ref=wheresyoured.at"><u>burning hundreds of thousands of dollars on Snowflake</u></a> because they didn&#x2019;t take thirty seconds to double-check any settings. I suspect that Snowflake&#x2019;s annual revenue would drop by more than 20% if every team in the world spent five minutes (<em>actually</em> five minutes, it was that easy) to make the change I did &#x2013; editing a single number in the settings that has no negative side-effects for the typical business &#x2013; but they&#x2019;re also staffed by people that don&#x2019;t read or study, so there&#x2019;s no way to reach them.</p><p>I warn every single friend who enters the software industry that unless they land a role with the top 1% of software engineering organizations, they are about to witness true madness. Without fail, they report back in six months with something along the lines of &#x201C;I thought you were exaggerating.&#x201D; In a private conversation about a year ago, an employee that left a well-known unicorn start-up confided:</p><blockquote>&#x201C;After leaving that company, I couldn&#x2019;t believe that the rest of the world works this way.&#x201D;</blockquote><p>There are places where this doesn&#x2019;t happen, but this madness is overwhelmingly the experience at companies that purchase huge enterprise products like Salesforce &#x2013; the relationship between astonishing inefficiency and buying these products is so strong that it&#x2019;s a core part of how my current team handles sales. We don&#x2019;t waste time trying to sell to companies that use this stuff &#x2013; it&#x2019;s usually too late to save them &#x2013; and I spend a lot of time tracking down companies in the process of being pitched this stuff by competing vendors.</p><p>In 2023, software engineer Emmanuel Maggiore <a href="https://emaggiori.com/employed-in-tech-for-years-but-almost-never-worked/?ref=wheresyoured.at"><u>wrote</u></a>:</p><blockquote>&#x201C;When Twitter fired half of its employees in 2022, and most tech giants followed suit, I wasn&#x2019;t surprised. In fact, I think little will change for those companies. After being employed in the tech sector for years, I have come to the conclusion that most people in tech don&#x2019;t work. I don&#x2019;t mean we don&#x2019;t work hard; I mean we almost don&#x2019;t work at all. Nada. Zilch. And when we do get to do some work, it often brings low added value to the company and its customers. All of this while being paid an amount of money some people wouldn&#x2019;t even dream of.&#x201D;</blockquote><p>This will be totally unrecognizable to about half the software people in the world &#x2013; those working at companies like Netflix which are famous for their software engineering cultures, or some of those working at startups where there isn&#x2019;t enough slack to obfuscate. For everyone else, what I&#x2019;ve described is Tuesday.</p><p><strong><em>Also as a note to my lovely fans who email me about the RSS feed &quot;including the whole premium newsletter&quot; - I give generous previews! The rest of the (premium) article follows.</em></strong></p>]]>
			</content:encoded>
		</item>
		<item>
			<title>
				<![CDATA[Anthropic Is Bleeding Out]]>
			</title>
			<description>
				<![CDATA[<p><strong>Hello premium customers! </strong>Feel free to get in touch at ez@betteroffline.com if you&apos;re ever feeling chatty. And if you&apos;re not one yet, please subscribe and support my independent brain madness.</p><p>Also, thank you to Kasey Kagawa for helping with the maths on this.</p><p><a href="https://youtu.be/bAO5sM89HUw?si=NRir5AXaYtcraOqG&amp;ref=wheresyoured.at"><strong><em><u>Soundtrack:</u></em></strong></a></p>]]>
			</description>
			<link>https://www.wheresyoured.at/anthropic-is-bleeding-out/</link>
			<guid isPermaLink="false">686f3cb3d9ae8d00012c565f</guid>
			<dc:creator>
				<![CDATA[Edward Zitron]]>
			</dc:creator>
			<pubDate>Fri, 11 Jul 2025 16:32:04 GMT</pubDate>
			<content:encoded>
				<![CDATA[<p><strong>Hello premium customers! </strong>Feel free to get in touch at ez@betteroffline.com if you&apos;re ever feeling chatty. And if you&apos;re not one yet, please subscribe and support my independent brain madness.</p><p>Also, thank you to Kasey Kagawa for helping with the maths on this.</p><p><a href="https://youtu.be/bAO5sM89HUw?si=NRir5AXaYtcraOqG&amp;ref=wheresyoured.at"><strong><em><u>Soundtrack: Killer Be Killed - Melting Of My Marrow</u></em></strong></a></p><hr><p><a href="https://www.wheresyoured.at/anthropic-and-openai-have-begun-the-subprime-ai-crisis/"><u>Earlier in the week</u></a>, I put out a piece about how Anthropic had begun cranking up prices on its enterprise customers, most notably Cursor, a $500 million Annualised Recurring Revenue (meaning month multiplied by 12) startup that is also Anthropic&#x2019;s largest customer for API access to models like Claude Sonnet 4 and Opus 4.</p><p>As a result, Cursor had to make massive changes to the business model that had let it grow so large in the first place, replacing (on June 17 2025, a few weeks after Anthropic&#x2019;s May 22 launch of its&#xA0; Claude Opus 4 and Sonnet 4 models) a relatively limitless $20-a-month offering with a much-more-limited $20-a-month package and a less-limited-but-still-worse-than-the-old-$20-tier $200-a-month subscription, pissing off customers and leading to<a href="http://reddit.com/r/cursor/?ref=wheresyoured.at"><u> most of the Cursor Subreddit</u></a> turning into people complaining or discussing they&#x2019;d cancel their subscription.</p><p>Though I recommend you go and read the previous analysis, the long and short of it is that Anthropic increased the costs on its largest customer &#x2014; a coding startup &#x2014; about 8 days (on May 30 2025) after launching two models (Sonnet 4 and Claude Opus 4) specifically dedicated to coding.</p><p>I concluded with the following:</p><blockquote>What I have described in this newsletter is one of the most dramatic and aggressive price increases in the history of software, with effectively no historical comparison. No infrastructure provider in the history of Silicon Valley has so distinctly and aggressively upped its prices on customers, let alone their largest and most prominent ones, and doing so is an act of desperation that suggests fundamental weaknesses in their business models.<br><br>Worse still, these changes will begin to kneecap an already-shaky enterprise revenue story for two companies desperate to maintain one. OpenAI&apos;s priority pricing is basic rent-seeking, jacking up prices to guarantee access. Anthropic&apos;s pricing changes are intentional, mob-like attempts to increase revenue by hitting its most-active customers exactly where it hurts, launching a model for coding startups to integrate that&#x2019;s <strong>specifically priced to increase costs on enterprise coding startups.</strong></blockquote><p>But the whole time I kept coming back to a question: why, exactly, would Anthropic do this? Was this rent seeking? A desperate attempt to boost revenue? An attempt to bring its largest customer&#x2019;s compute demands under control<a href="https://www.vincentschmalbach.com/cursor-is-anthropics-largest-customer-and-maxing-out-their-gpus/?ref=wheresyoured.at"><u> as its regularly pushed Anthropic&#x2019;s capacity to the limit</u></a>?</p><p>Or, perhaps, it was a little simpler: was Anthropic having its own issues with capacity, and maybe even cash flow.</p><p>Another announcement happened on May 22 2025 &#x2014;<a href="https://docs.anthropic.com/en/release-notes/claude-code?ref=wheresyoured.at"><u> Anthropic launched Claude Code</u></a>, a version of Anthropic&#x2019;s Claude that runs directly in your terminal (or integrates into your IDE) that uses Anthropic&#x2019;s Claude models to write and manage code. This is, I realize, a bit of an oversimplification, but the actual efficacy or ability of Claude Code is largely irrelevant other than in the sheer amount of cloud compute it requires.</p><p>As a reminder,<a href="https://www.anthropic.com/news/claude-4?ref=wheresyoured.at"><u> Anthropic also launched its Claude Sonnet 4 and Opus 4 models on May 22 2025</u></a>, shortly followed by its Service Tiers, and then both Cursor and vibe-coding startup Replit&#x2019;s price changes, which I covered last week. These are not the moves of a company brimming with confidence about its infrastructure or financial position, which made me want to work out <em>why things might have got more expensive.</em></p><p>And then I found out, and it was really, really fucking bad.</p><p>Claude Code, as a product, is quite popular, along with its Sonnet 4 and Opus 4 models. It&#x2019;s accessible via Anthropic&#x2019;s $20-a-month &#x201C;Pro&#x201D; subscription (but only using the Claude Sonnet 4 model), or the $100 (5x the usage of Pro) and $200 (20x the usage of Pro) &#x201D;Max&#x201D; subscriptions. While people hit rate limits, they seem to be getting a lot out of using it, to the point that you have people on Reddit boasting<a href="https://www.reddit.com/r/cursor/comments/1lmhm5x/idk_how_you_guys_are_using_claude_code_but_im/?utm_source=share&amp;utm_medium=web3x&amp;utm_name=web3xcss&amp;utm_term=1&amp;utm_content=share_button"><u> about running eight parallel instances of Claude Code</u></a>.</p><p>Something to know about software engineers is that they&#x2019;re <em>animals</em>, and I mean that with respect. If something can be automated, a software engineer is at the very least going to<em> take a look at automating it</em>, and Claude Code, when poked in the right way, can automate a lot of things, though to what quality level or success rate I have no real idea, and while there are <em>limits </em>and <em>restrictions</em>, software engineers <em>absolutely fucking love testing limits and getting around restrictions, </em>and many I know see them as challenges to overcome.</p><p>As a result, software engineers are running Claude Code <em>at full tilt, to the limits, </em>to the point that some set alarms to wake up during the night when their limits reset after five hours to maximize their usage, along with<a href="https://www.reddit.com/r/ClaudeAI/comments/1lh71x0/ccusage_v1500_live_monitoring_dashboard_is_here/?ref=wheresyoured.at"><u> specialised dashboards to help them do so</u></a>. One other note is that Claude Code&#x2019;s functionality creates detailed logs about the amount of input or output tokens it&#x2019;s using throughout the day to complete its tasks, including whether said tokens were written to or read from the cache.</p><p>Software engineers also love <em>numbers</em>, and they also love<em> deals</em>, and thus somebody created<a href="https://github.com/ryoppippi/ccusage?ref=wheresyoured.at"><u> CCusage,</u></a> a tool that, using those logs, allows Claude Code users to see exactly how much compute you&#x2019;re burning with your subscription, even though Anthropic is only charging you $20, $100 or $200-a-month. CCUsage compares these logs (which contain both how tokens were used and what models were run) to the up-to-date information from Anthropic&#x2019;s API prices, and tells you exactly how much you&#x2019;ve spent in compute (<a href="https://lib.rs/crates/ccusage-rs?ref=wheresyoured.at"><u>here&#x2019;s a more detailed run-down</u></a>).</p><p>In simpler terms, CCusage is a relatively-accurate barometer of how much you are costing Anthropic at any given time, with the understanding that its costs <em>may</em> (we truly have no idea) be lower than the API prices they charge, though I add that based on<a href="https://www.theinformation.com/articles/anthropic-projects-soaring-growth-to-34-5-billion-in-2027-revenue?rc=kz8jh3&amp;ref=wheresyoured.at"><u> how Anthropic is expected to lose $3 billion this year (that&#x2019;s after revenue!)</u></a> there&#x2019;s a chance that it&#x2019;s actually <em>losing money on every API call.</em></p><p>Nevertheless, there&#x2019;s one much, much, much bigger problem:<strong> Anthropic is very likely losing money on every single Claude Code customer, and based on my analysis, appears to be losing hundreds or even thousands of dollars per customer.</strong></p><p>There is a gaping wound in the side of Anthropic, and it threatens financial doom for the company.</p><hr><p>Some caveats before we continue:</p><ul><li>CCusage is not direct information from Anthropic, and thus there may be things we don&#x2019;t know about how it charges customers, or any means of efficiency it may have.</li><li>Despite the amount of evidence I&#x2019;ve found, we do not have a representative sample of exact pricing. This evidence comes from people who use Claude Code, are measuring their usage, and elected to post their CCusage dashboards online &#x2014; which likely represents a small sample of the total user base.&#xA0;</li><li>Nevertheless, the amount of cases I&#x2019;ve found online of egregious, unrelentingly unprofitable burn are deeply concerning, and it&#x2019;s hard to imagine that these examples are outliers.&#xA0;</li><li>We do not know if the current, unrestricted version of Claude Code will last.</li></ul><p>The reason I&#x2019;m leading with these caveats is because the numbers I&#x2019;ve found about the sheer amount of money Claude Code&#x2019;s users are burning are absolutely shocking.&#xA0;</p><p>In the event that they are representative of the greater picture of Anthropic&#x2019;s customer base, this company is wilfully burning 200% to 3000% of each Pro or Max customer that interacts with Claude Code, and in each price point&#x2019;s case I have found repeated evidence that customers are allowed to burn their entire monthly payment in compute within, at best, eight days, with some cases involving customers on a $200-a-month subscription burning as much as $10,000 worth of compute.</p><blockquote>Sidenote: While researching this piece, I decided to send my editor, <a href="https://bsky.app/profile/matthewhughes.bsky.social?ref=wheresyoured.at"><u>Matt Hughes</u></a>, &#xA3;20 and told him to create an Anthropic Pro account and install Claude Code with the aim of seeing how much of Anthropic&#x2019;s money he could burn over the course of an hour or so.&#xA0;<br><br>Matt, a <a href="https://whatwelost.substack.com/p/what-we-lost?ref=wheresyoured.at"><u>developer-turned-journalist</u></a>, told Claude Code to build the scaffolding for a browser-based game using the <a href="http://phaser.js/?ref=wheresyoured.at"><u>phaser.js</u></a> library &#x2014; a simple, incredibly accessible tool for creating HTML 5 games. Just creating that scaffolding ended up burning around $2.50, and that&#x2019;s with just over the course of an hour.&#xA0;<br><br>It&#x2019;s easy to see how someone using Claude Code as part of their job, or as part of creating their side-project, could end up burning way more money than they paid as part of their package.&#xA0;</blockquote><p>Furthermore, it&#x2019;s important to know that Anthropic&#x2019;s models are synonymous with using generative AI to write or manage code.<a href="https://openrouter.ai/rankings?ref=wheresyoured.at"><u> Anthropic&#x2019;s models make up more than half of all tokens related to programming that flow through OpenRouter</u></a>, a popular unified API for integrating models into services, and<a href="https://www.axios.com/2025/05/22/anthropic-claude-version-4-ai-model?ref=wheresyoured.at"><u> currently lead on major LLM coding benchmarks</u></a>. Much of Cursor&#x2019;s downfall has come from integrating both of these models, in particular the expensive (and I imagine compute intensive) Opus 4 model, which Anthropic only allows users of its $100-a-month or $200-a-month &#x201C;Max&#x201D; subscriptions to access.</p><p>In my research, I have found more than thirty different reported instances of users that have spent in excess of the amount they pay Anthropic <strong>by a factor of no less than 100%. </strong>For sake of your sanity, I will split them up by their paid subscription, and how much more than it they spent.</p>]]>
			</content:encoded>
		</item>
		<item>
			<title>
				<![CDATA[Anthropic and OpenAI Have Begun The Subprime AI Crisis]]>
			</title>
			<description>
				<![CDATA[<p><strong>Hello premium customers! </strong>Feel free to get in touch at ez@betteroffline.com if you&apos;re ever feeling chatty. And if you&apos;re not one yet, I&apos;m sorry that I paywalled this, but it took me so much effort and drove me a little insane.</p><hr><p>Back</p>]]>
			</description>
			<link>https://www.wheresyoured.at/anthropic-and-openai-have-begun-the-subprime-ai-crisis/</link>
			<guid isPermaLink="false">6866b0417b9f0e0001f1ffdc</guid>
			<dc:creator>
				<![CDATA[Edward Zitron]]>
			</dc:creator>
			<pubDate>Mon, 07 Jul 2025 16:34:48 GMT</pubDate>
			<content:encoded>
				<![CDATA[<p><strong>Hello premium customers! </strong>Feel free to get in touch at ez@betteroffline.com if you&apos;re ever feeling chatty. And if you&apos;re not one yet, I&apos;m sorry that I paywalled this, but it took me so much effort and drove me a little insane.</p><hr><p>Back in September 2024 I wrote about a phenomena I call<a href="https://www.wheresyoured.at/subprimeai/"><u>The Subprime AI Crisis</u></a> &#x2014; that companies like Anthropic and OpenAI are providing their services at a massive loss, and that at some point they would have to start finding ways to recoup their costs, raising the prices of providing their services, which in turn would cause those connecting to their APIs to have to start doing the same to their customers.</p><p>As an aside, I also made the following prediction:</p><blockquote>I believe that, at the very least, Microsoft will begin reducing costs <em>in other areas of its business</em> as a means of helping sustain the AI boom. In an email shared with me by a source from earlier this year, Microsoft&apos;s senior leadership team requested (in a plan that was eventually scrapped) reducing power requirements from multiple areas within the company as a means of freeing up power for GPUs, including moving other services&apos; compute to other countries as a means of freeing up capacity for AI.</blockquote><p><a href="https://www.seattletimes.com/business/microsoft/microsoft-to-lay-off-as-many-as-9000-employees-in-latest-round/?ref=wheresyoured.at"><u>Microsoft laid off 9000 people last week</u></a>, one of its largest in history,<a href="https://apnews.com/article/microsoft-layoffs-xbox-f44079957b12370f72e24edebe9fcc6b?ref=wheresyoured.at"><u>hitting its Xbox division hardest</u></a>,<a href="https://www.wheresyoured.at/make-fun-of-them/"><u>about a month and a half after laying off 6000 people</u></a>.</p><p>But really, my biggest prediction was this:</p><blockquote>I hypothesize a kind of subprime AI crisis is brewing, where almost the entire tech industry has bought in on a technology sold at a vastly-discounted rate, heavily-centralized and subsidized by big tech. At some point, the incredible, toxic burn-rate of generative AI is going to catch up with them, which in turn will lead to price increases, or companies releasing new products and features with wildly onerous rates &#x2014;<a href="https://investor.salesforce.com/press-releases/press-release-details/2024/Salesforce-Unveils-AgentforceWhat-AI-Was-Meant-to-Be/default.aspx?ref=wheresyoured.at"><u>like the egregious <em>$2-a-conversation</em> rate for Salesforce&#x2019;s &#x201C;Agentforce&#x201D; product</u></a> &#x2014; that will make even stalwart enterprise customers with budget to burn unable to justify the expense.<br><br>What happens when the entire tech industry relies on the success of a kind of software that only loses money, and doesn&#x2019;t create much value to begin with? And what happens when the heat gets too much, and these AI products become impossible to reconcile with, and these companies have nothing else to sell?</blockquote><p>We may be about to find out.</p><h2 id="the-enshittification-of-cursor"><strong>The Enshittification Of Cursor</strong></h2><p>Last week, it came out that Anthropic, whose Claude models compete with those made by OpenAI,<a href="https://www.theinformation.com/articles/anthropic-revenue-hits-4-billion-annual-pace-competition-cursor-intensifies?rc=kz8jh3&amp;ref=wheresyoured.at"><u>had hit $4 billion in annualized revenue, meaning [whatever month it is] multiplied by twelve</u></a>, and expects to <em>lose</em> $3 billion in 2025 because of how utterly unprofitable its models are, though The Information adds that this is an improvement over a loss of $5.6 billion in 2024, which Anthropic claims was due to &quot;<a href="https://www.theinformation.com/articles/anthropic-projects-soaring-growth-to-34-5-billion-in-2027-revenue?rc=kz8jh3&amp;ref=wheresyoured.at"><u>a one-off payment to access the data centers that power its technology</u></a>.&quot;</p><blockquote>Hey, wait a second. Isn&apos;t Anthropic running its services on<a href="https://www.anthropic.com/news/anthropic-amazon-trainium?ref=wheresyoured.at"><u>Amazon Web Services</u></a> and<a href="https://www.anthropic.com/news/anthropic-partners-with-google-cloud?ref=wheresyoured.at"><u>Google Cloud</u></a>? Didn&apos;t both Google and Amazon fund them? Is Anthropic just handing their money back to them? Weird! Kinda reminds me of<a href="https://www.wheresyoured.at/why-did-microsoft-invest-in-openai/"><u>how Microsoft is booking the revenue it gets from OpenAI handing it cloud credits</u></a>. Weird!</blockquote><p>Anyway, The Information added in its piece that Anthropic also lost the lead developer of their Claude Code product (Boris Cherny) to Anysphere, maker of the buzzy coding startup Cursor, along with Cat Wu, one of the product managers on Claude Code, with both allegedly going on to develop &quot;agent-like features,&quot; a thing that, to quote The Information, involves &quot;automating complex coding tasks involving multiple steps.&quot;</p><p>I wouldn&apos;t usually just write down exactly what a startup has told The Information, but these details are important, as are the following:</p><blockquote>Cursor&#x2019;s growth is also accelerating thanks to advances in Anthropic&#x2019;s models and what developers say is an easy-to-use interface. The company said last month that it has surpassed $500 million in annual recurring revenue, or $42 million in revenue per month. That&#x2019;s more than double its pace of $200 million in annual recurring revenue as of March. Anysphere&#x2019;s valuation is $9.9 billion, up from $2.6 billion in December.</blockquote><p>Anysphere has become precious to Silicon Valley &#x2014; proof that there are startups other than OpenAI and Anthropic that can build actual products that people will pay for that use AI in some way, and,<a href="https://www.theinformation.com/projects/generative-ai?rc=kz8jh3&amp;ref=wheresyoured.at"><u>according to The Information&apos;s Generative AI database</u></a>, has the most recurring revenue of any private AI-powered software-as-a-service startup (outside of the aforementioned big two).</p><p>Cursor and Anysphere are symbolic. Cursor is a tool that developers actually like, that actually makes money, that grew organically based on people talking about how much they liked it, and it proliferated one of generative AI&apos;s only real use cases &#x2014; being able to generate or edit code quickly.&#xA0;</p><p>To get a little more specific, Cursor is something called an IDE &#x2014; integrated development environment, which allows a developer to write code, run tests, manage projects, and so on, &#x2014; but with AI integrations that can predict what your next change to the code might be (which Cursor calls &quot;tab completions&quot;), and the ability to generate code and take actions across an entire project rather than in separate requests. If you want a deeper dive (as I&apos;m not a software developer),<a href="https://randomcoding.com/blog/2024-09-15-is-cursor-ais-code-editor-any-good/?ref=wheresyoured.at"><u>I recommend reading this piece from Random Coding</u></a>.</p><blockquote><strong>A note about coding startups and AI-generated code:</strong> Code is <strong>character-heavy</strong>, as I&apos;ll get into later, but it means that in general coding startups use way more generative AI services than, say, a company generating text or images. Code is extremely verbose, and bad code often moreso, and changes to it are nuanced, requiring the generative AI model in question to ingest and output a great deal of stuff.</blockquote><p>This is, of course, compounded by their propensity for hallucinations. Basically, some degree of relying on AI-generated code means knowing that you&apos;re going to generate a certain amount of crap that you&apos;ll have to fix. While you save time in the aggregate, you are still burning extra tokens on the mistakes a model might make.</p><p>You will eventually realise why that&apos;s bad.</p><p>Nevertheless, the long and short of it is that Cursor is a well-liked product for using AI to build software, with the ability to ask it to take distinct actions using natural language, specifically using Cursor&apos;s (sigh) &quot;agent,&quot; which can be told to do something and then work on it in the background as you go and do something else. Nothing about what I&apos;m saying is an endorsement of the product, but it&apos;s hard to deny that software developers generally liked Cursor, and that it&apos;s become extremely popular as a result.</p><p>Or, perhaps, I should&apos;ve said &quot;liked.&quot;</p>]]>
			</content:encoded>
		</item>
		<item>
			<title>
				<![CDATA[Make Fun Of Them]]>
			</title>
			<description>
				<![CDATA[<p>Have you ever heard Sam Altman speak?</p><p>I&#x2019;m serious, have you ever heard this man say words from his mouth?&#xA0;</p><p>Here is but one of the trenchant insights from Sam Altman in<a href="https://www.youtube.com/watch?v=mZUG0pr5hBo&amp;ref=wheresyoured.at"><u> his agonizing 37-minute-long podcast conversation with his brother Jack Altman from last week</u></a>:</p><blockquote><em><strong>&#x201C;</strong>I</em></blockquote>]]>
			</description>
			<link>https://www.wheresyoured.at/make-fun-of-them/</link>
			<guid isPermaLink="false">68629e5c4fda1e0001308045</guid>
			<dc:creator>
				<![CDATA[Edward Zitron]]>
			</dc:creator>
			<pubDate>Mon, 30 Jun 2025 14:42:04 GMT</pubDate>
			<content:encoded>
				<![CDATA[<p>Have you ever heard Sam Altman speak?</p><p>I&#x2019;m serious, have you ever heard this man say words from his mouth?&#xA0;</p><p>Here is but one of the trenchant insights from Sam Altman in<a href="https://www.youtube.com/watch?v=mZUG0pr5hBo&amp;ref=wheresyoured.at"><u> his agonizing 37-minute-long podcast conversation with his brother Jack Altman from last week</u></a>:</p><blockquote><em><strong>&#x201C;</strong>I think there will be incredible other products. There will be crazy new social experiences. There will be, like, Google Docs style AI workflows that are just way more productive. You&#x2019;ll start to see, you&#x2019;ll have these virtual employees, but the thing that I think will be most impactful on that five to ten year timeframe is AI will actually discover new science.&#x201D;&#xA0;</em></blockquote><p>When asked why he believes AI will &#x201C;discover new science,&#x201D; Altman says that &#x201C;I think we&#x2019;ve cracked reasoning in the models,&#x201D; adding that &#x201C;we&#x2019;ve a long way to go,&#x201D; and that he &#x201C;think[s] we know what to do,&#x201D; adding that OpenAI&#x2019;s o3 model &#x201C;is already pretty smart,&#x201D; and that he&#x2019;s heard people say &#x201C;wow, this is like a good PHD.&#x201D;</p><p>That&#x2019;s the entire answer! It&#x2019;s complete nonsense! Sam Altman, the CEO of OpenAI, a company allegedly worth $300 billion to venture capitalists and SoftBank, kind of sounds like a huge idiot!</p><p>&#x201C;But Ed!&#x201D; you cry. &#x201C;You can&#x2019;t just call Sam Altman an idiot! He isn&#x2019;t stupid! He runs a big company, and he&#x2019;s super successful!&#x201D;</p><p>My counter to that is, first, yes I can, I&#x2019;m doing it right now. Second, if Altman didn&#x2019;t want to be called stupid, he wouldn&#x2019;t say stupid shit with a straight face to a massive global audience.</p><p>My favourite part of the interview is near the beginning:</p><blockquote><strong>Jack Altman: </strong><em>So reasoning will lead to science going faster or just new stuff or both?</em><br><br><strong>Sam Altman:</strong><em> I mean, you already hear scientists who say they&#x2019;re faster with AI, like we don&#x2019;t have AI maybe autonomously doing science, but if a human scientist is three times as productive using o3, that&#x2019;s still a pretty big deal.</em><br><br><strong>Jack Altman:</strong><em>Yeah</em><br><br><strong>Sam Altman: </strong><em>And then as that keeps going and the AI can autonomously do some science, figure out novel physics-</em><br><br><strong>Jack Altman: </strong><em>Is it all that happening as a copilot right now?</em> [Editor&#x2019;s note: this is exactly what Jack Altman says]<br><br><strong>Sam Altman: </strong><em>Yeah there&#x2019;s definitely not&#x2026; You definitely can&#x2019;t go say like, &#x201C;Hey ChatGPT, figure out new physics&#x201D; and expect that to work. So I think it is currently copilot-like, but I&#x2019;ve heard like, anecdotal reports from biologists where it&#x2019;s like, &#x201C;wow, it really did figure out an idea. I had to develop it, but it made a fundamental leap.&#x201D;&#xA0;</em></blockquote><p>This is a nonsensical conversation, and both of them sound very, very stupid.&#xA0;</p><p>&#x201C;So, is this going to make new science or make science faster?&#x201D; &#x201C;Yeah, I hear scientists are using AI to go faster [CITATION NEEDED], but if a human scientist goes three times faster [CITATION NEEDED] using my model that would be good. Also I heard from a guy that he heard a guy who did biology who said &#x2018;this helped.&#x2019;&#x201D;</p><p>Phenomenal! Give this guy $40 billion or more dollars every year until he creates a superintelligence, <em>that&#x2019;ll fucking work.</em></p><p>Here are some other incredible quotes from the genius mind of Sam Altman:</p><ul><li><em>&#x201C;You hear these stories of people who use AI to do market research and figure out new products and then email some manufacturer and get some dumb thing made and sell it on Amazon and run ads&#x2026;there are people that have actually figured out at small scale in the most boring ways possible how to put a dollar into AI and get the AI to run a toy business, but it&#x2019;s actually working. So that&#x2019;ll climb the gradient.&#x201D;&#xA0;</em><ul><li>You may wonder if &#x201C;the gradient&#x201D; is mentioned at some point elsewhere. It is not.</li></ul></li><li><em>&#xA0;&#x201C;So every year before the last maybe up until last year I would&#x2019;ve said, &#x2018;hey I think this is going to go really far,&#x2019; but it still seems like there&#x2019;s a lot we&#x2019;ve got to figure out.&#x201D;&#xA0;</em></li><li><em>&#x201C;If something goes wrong, I would say somehow it&#x2019;s that we build legitimate super intelligence and it doesn&#x2019;t make the world much better, it doesn&#x2019;t change things as much as it sounds like it should.&#x201D;</em></li><li><em>&#x201C;So yeah, I think the relativistic point is really important, but to us, our jobs feel incredibly important and stressful and satisfying. And if we&apos;re all just making better entertainment for each other in the future, maybe that&apos;s kind of what at least one of us is doing right now.&#x201D;&#xA0;</em></li></ul><p>This is gobbledygook, nonsense, bullshit peddled by a guy who has only the most tangential understanding of the technology his company is building.&#xA0;</p><p>Every single interview with Sam Altman is like this, every single one, ever since he became a prominent tech investor and founder. Without fail. And the sad part is that Altman isn&#x2019;t alone in this.</p><p>Sundar Pichai, <a href="https://www.theverge.com/decoder-podcast-with-nilay-patel/673638/google-ceo-sundar-pichai-interview-ai-search-web-future?ref=wheresyoured.at"><u>when asked one of Nilay Patel&#x2019;s patented 100-word-plus-questions</u></a> about Jony Ive and Sam Altman&#x2019;s new (and likely heavily delayed) hardware startup:</p><blockquote><em>I think AI is going to be bigger than the internet. There are going to be companies, products, and categories created that we aren&#x2019;t aware of today. I think the future looks exciting. I think there&#x2019;s a lot of opportunity to innovate around hardware form factors at this moment with this platform shift. I&#x2019;m looking forward to seeing what they do. We are going to be doing a lot as well. I think it&#x2019;s an exciting time to be a consumer, it&#x2019;s an exciting time to be a developer. I&#x2019;m looking forward to it.</em></blockquote><p>The fuck are you on about, Sundar? Your answer to a question about whether you anticipate more competition is to say &#x201C;yeah I think people are gonna make shit we haven&#x2019;t come up with and uhh, hardware, can&#x2019;t wait!&#x201D;</p><p>While I think Pichai is likely a little smarter than Altman, in the same way that Satya Nadella is a little smarter than Pichai, and in the same way that a golden retriever is smarter than a chihuahua. That said, none of these men are superintelligences, nor, when pressed, do they ever seem to have any actual answers.</p><p>Let&#x2019;s see what Satya Nadella of Microsoft answered when asked about how exactly it&#x2019;s going to get to (and <a href="https://www.youtube.com/watch?v=4GLSzuYXh6w&amp;ref=wheresyoured.at"><u>I paraphrase Dwarkesh Patel&#x2019;s mealy-mouthed question</u></a>) $130 billion in AI revenue &#x201C;through AGI&#x201D;:</p><blockquote><em>The way I come at it, Dwarkesh, it&apos;s a great question because at some level, if you&apos;re going to have this explosion, abundance, whatever, commodity of intelligence available, the first thing we have to observe is GDP growth.<br><br>Before I get to what Microsoft&apos;s revenue will look like, there&apos;s only one governor in all of this. This is where we get a little bit ahead of ourselves with all this AGI hype. Remember the developed world, which is what? 2% growth and if you adjust for inflation it&#x2019;s zero?<br><br>So in 2025, as we sit here, I&apos;m not an economist, at least I look at it and say we have a real growth challenge. So, the first thing that we all have to do is, when we say this is like the Industrial Revolution, let&apos;s have that Industrial Revolution type of growth.<br><br>That means to me, 10%, 7%, developed world, inflation-adjusted, growing at 5%. That&apos;s the real marker. It can&apos;t just be supply-side.<br><br>In fact that&#x2019;s the thing, a lot of people are writing about it, and I&apos;m glad they are, which is the big winners here are not going to be tech companies. The winners are going to be the broader industry that uses this commodity that, by the way, is abundant. Suddenly productivity goes up and the economy is growing at a faster rate. When that happens, we&apos;ll be fine as an industry.<br><br>But that&apos;s to me the moment. Us self-claiming some AGI milestone, that&apos;s just nonsensical benchmark hacking to me. The real benchmark is: the world growing at 10%.</em></blockquote><p>This quote has been used as a means of suggesting that Nadella is saying that &#x201C;<a href="https://ca.finance.yahoo.com/news/microsoft-ceo-admits-ai-generating-123059075.html?ref=wheresyoured.at"><u>generative AI is generating basically no value</u></a>,&#x201D; which, while somewhat true, obfuscates its true meaning: Satya Nadella isn&#x2019;t saying a fucking thing.&#xA0;</p><p>The question was &#x201C;how do you get Microsoft to $130 billion in revenue,&#x201D; and Satya Nadella&#x2019;s answer was to say &#x201C;uhhh, abundance, uhhh, explosion, uhhhhh, GDP! Growth! Industrial revolution! Inflation-adjusted! Percentages! The winners will be the people who do stuff, and then productivity will go up!&#x201D;</p><p>This is fucking nonsense, and it&#x2019;s time to stop idolizing these speciously-informed goobers. While kinder souls or Zitron-haters may read this and say &#x201C;ahh, actually, what Nadella was saying was&#x2026;&#x201D; stop. I want to stop you there and suggest that perhaps a smart person should be able to speak clearly enough that their intent is obvious.&#xA0;</p><p>It&#x2019;s tempting to believe that there is some sort of intellectual barrier between you and the powerful &#x2014; that the confusing and obtuse way that they speak is the sound of genius, rather than somebody who has learned a lot of smart-sounding words without ever learning what they mean.</p><p>&#x201C;But Ed, they&#x2019;re <em>trained</em> to do this!&#x201D;</p><p>As someone who has media trained hundreds of people, there is only so much you can do to steer someone&#x2019;s language. You cannot say to Sundar Pichai &#x201C;hey man, can you sound <em>more</em> confusing?&#x201D; You can, however, tell them what not to talk about and hope for the best. Sure, you can make them practice, sure, you can give them feedback, but people past a certain stage of power or popularity <em>are going to talk however they want, and if they&#x2019;re a big stupid idiot pretending to be smart, they&#x2019;re going to sound exactly like this.</em></p><p>Why? Because <strong>nobody in the media ever asks them to explain themselves.</strong> When you&#x2019;ve spent your entire career being asked friendly-or-friendly-adjacent questions and never having someone say &#x201C;wait, what does that mean?&#x201D; you will continue to mutate in a pseudo-communicator that spits out information-adjacent bullshit.&#xA0;</p><p>I am, to be clear, <em>being very specific about that question.</em> Powerful CEOs and founders never, ever get asked to explain what they&#x2019;re saying, even when what they&#x2019;re saying barely resembles an actual answer.&#xA0;</p><p>Pichai, Altman and Nadella have always given this kind of empty-brained intellectual slop in response to questions because the media coddles them. These people are product managers and/or management consultants &#x2014; and in Altman&#x2019;s case, a savvy negotiator and manipulator known for &#x201C;an absenteeism that rankled his peers and some of the startups he was supposed to nurture&#x201D; as an investor at yCombinator, <a href="https://www.washingtonpost.com/technology/2023/11/22/sam-altman-fired-y-combinator-paul-graham/?ref=wheresyoured.at"><u>according to the Washington Post</u></a>.</p><blockquote>I&#x2019;ll try and explain this with a little aside.<br><br>Let&#x2019;s think about a hypothetical question about your friend whose dog died:<br><br>You: Oh no, what happened?<br><br>Them: Well, my dog had a tragic yet ultimately final distinction between their ideal and non-ideal state, due to the involvement of a kind of automatic mechanical device, and when that happened, we realized we&#x2019;d have to move on from the current paradigm of dog ownership and into a new era, which we both feel a great deal of emotion about and see the opportunities within.<br><br>You would probably be a little confused and ask them to explain what they meant.<br><br>You: Wait, what do you mean automatic mechanical what? Huh?<br><br>Them: Yeah, exactly, and that was part of the challenge. You see, like, the various interactions we have in our day are challenging, and we see a lot of opportunities in assailing those challenges, but part of the road to getting around them is facing them head on, which is ultimately what happened there. And while we were involved, we didn&#x2019;t want to be, and so we had to make some dramatic changes.&#xA0;<br><br>You still, at this point, do not really know what happened. Did a car hit the dog? <em><strong>Did they run over their dog</strong>?</em><br><br>In this scenario, would you nod and say &#x201C;wow man, that sucks, I&#x2019;m sorry,&#x201D; or would you ask them to explain what they&#x2019;re saying? Would you, perhaps, ask what it is they mean?</blockquote><p>By &#x201C;coddle,&#x201D; I mean these people are deliberately engaging in a combination of detective work and amnesia, where the reader or the listener is forced to simultaneously try and divine the meaning of their answer, while also not thinking too hard about the question the interviewer asked.&#xA0;</p><p>Look at most modern business interviews. They involve a journalist asking a question, somebody giving an answer, and the journalist saying &#x201C;okay!&#x201D; and moving onto the next question, occasionally saying &#x201C;but what about <em>this</em>?&#x201D; when the appropriate response to many of the answers is to ask them to <strong>simplify them so that their meaning is clearer.</strong></p><p>A common response to all of this is to say that &#x201C;interviewers can&#x2019;t be antagonistic,&#x201D; and I don&#x2019;t think a lot of people understand what that means. It isn&#x2019;t &#x201C;antagonistic&#x201D; to ask somebody to clearly articulate what they&#x2019;re saying, nor is it &#x201C;antagonistic&#x201D; to say that you don&#x2019;t understand, or that they didn&#x2019;t answer the question you asked. If this is &#x201C;antagonistic&#x201D; to you, you are, intellectually-speaking, a giant fucking coward, because what you&#x2019;re suggesting is that somebody cannot ask somebody to explain themselves, which is what an interview <em>is.</em></p><p>And I imagine nobody really wants to do this, because if you <strong>actually</strong> put these people on the spot, you&#x2019;d realize the dark truth that I spoke of a few weeks ago: <a href="https://www.wheresyoured.at/the-era-of-the-business-idiot/"><u>that the reason the powerful sound like idiots is because, well, they&#x2019;re idiots</u></a>. They sound like Business Idiots and create products to sell to Business Idiots, because Business Idiots run most companies and buy solutions based on what the last Business Idiot told them.&#xA0;</p><p><a href="https://ludic.mataroa.blog/blog/brainwash-an-executive-today/?ref=wheresyoured.at"><u>To quote the excellent Nik Suresh</u></a>:</p><blockquote><em>While I like Snowflake as a piece of software, it is probably not a high priority to move to it at most large companies for various reasons I won&apos;t get into here. Fine, I&apos;ll get into one of them. It&apos;s just a really good data warehouse, you absolute maniacs, it isn&apos;t the cure for cancer, why the fuck is it valued at $53B?<br><br>Because everyone is buying it, and this has to be driven by non-technical leadership because there aren&apos;t enough technical leaders to drive that sort of valuation. Why would non-technicians be so focused on a database of all things, a concept so dull that it is Effective Communication 101 to try and avoid using the term in front of a lay audience? It&apos;s because if you buy Snowflake then you&apos;re allowed to get onto stages at large venues and talk about how revolutionary Snowflake was for your business, which on the surface looks like a brag about Snowflake, but is actually a brag about the great decisions you&apos;ve been making and the wealth you can deploy if someone becomes your friend. And the audience is full of people that are now thinking &quot;If I buy Snowflake, I can be on that stage, and everyone will finally recognize my brilliance&quot;.</em></blockquote><p>I know some of you might read this and say &#x201C;these people can&#x2019;t be stupid! These people run companies! They make huge deals! They read all these books!&#x201D; and my answer is that some of the stupidest people I&#x2019;ve ever met have read more books than you or I will read in a lifetime. While they might be <em>smart</em> when it comes to corporate chess moves or saying &#x201C;this product category should do this,&#x201D; none of these men &#x2014; not Altman, Pichai or Nadella &#x2014; actually has a hand in the design or creation of any of the things their companies make, and they never, ever have.&#xA0;</p><p>Regardless, I have a larger point: it&#x2019;s time to start mocking these people and tearing down their legends as geniuses of industry. They are not better than us, nor are they responsible for anything that their companies build other than the share price (which is a meaningless figure) and the accumulation of power and resources.&#xA0;</p><p>These men are neither smart nor intellectually superior, and it&#x2019;s time to start treating them as such.</p><hr><p>These people are powerful because they have names that are protected by the press. They are powerful because it is seen as unseemly to mock them because they are rich and &#x201C;running a company,&#x201D; a kind of corporate fealty that I find deeply unbecoming of an adult.&#xA0;</p><p>We are, at most, customers. We do not &#x201C;owe them&#x201D; anything. We are long past the point when any of the people running these companies actually invented anything they sell. iIf anything, they <strong>owe us something</strong>, because they are selling us a product, even if said product is free and monetised by advertising.&#xA0;</p><p>While reporters &#x2014; as anyone &#x2014; should have some degree of professionalism in interviews or covering subjects, there is no reason to treat these people as special, even if they have managed to raise a lot of money or their product is popular, because if that were the case we&#x2019;d have far more coverage of defense contractor Lockheed Martin. It made $1.71 billion in profit last quarter, and hasn&#x2019;t had a single quarter <em>under</em> a billion dollars in the last year.&#xA0;</p><p>I&#x2019;m being a little glib, but the logic behind covering OpenAI is, at this point, &#x201C;it makes a lot of money and its product is popular,&#x201D; which is also a fitting description of Lockheed Martin. The difference is that OpenAI has a consumer product that loses billions of dollars, and Lockheed Martin has products that makes billions of dollars by removing consumers from the Earth. Both of them are environmentally destructive.&#xA0;</p><p>Covering OpenAI sure doesn&#x2019;t seem to be about the tech, because if you looked at the tech you&#x2019;d have to understand the tech, you&#x2019;d see that the user numbers weren&#x2019;t there outside of the 500 million people using ChatGPT, of which very few are actually paying for the product, and that the term &#x201C;user&#x201D; encompasses everything from the most occasional users who log in out of curiosity, to people who are actually using it as part of their daily lives.&#xA0;</p><p>If covering OpenAI was about the tech, you&#x2019;d read about how the tech itself doesn&#x2019;t seem to have a ton of mass-market use cases, and those use cases aren&#x2019;t really the kind of things that you&#x2019;d pay for. If they did, there&#x2019;d be articles that definitively discussed them versus <a href="https://www.nytimes.com/2025/06/16/magazine/using-ai-hard-fork.html?ref=wheresyoured.at"><u>articles in the New York Times</u></a> about &#x201C;everybody using AI&#x201D; that boil down to &#x201C;I use ChatGPT as search now&#x201D; and &#x201C;I heard a guy who asked it to teach him about modern art.&#x201D;</p><p>Yet men like Dario Amodei and Sam Altman continue to be elevated because they are &#x201C;building the future,&#x201D; even if they don&#x2019;t seem to have built it yet, or have the ability to clearly articulate what that future actually looks like.&#xA0;</p><p>Anthropic has <a href="https://fortune.com/2025/06/23/ai-models-blackmail-existence-goals-threatened-anthropic-openai-xai-google/?ref=wheresyoured.at"><u>now put out multiple stories</u></a> suggesting that its generative AI will &#x201C;blackmail&#x201D; people as a means of stopping a user from turning off the system, <strong><em>something which is so obviously the company prompting its models to do so. </em></strong>Every member of the media covering this uncritically should feel ashamed of themselves.</p><p>Sadly, this is all a result of the halo effect of being a Guy Who Raised Money or Guy Who Runs Big Company. We must, as human beings, assume that these people are smart, and that they&#x2019;d never mislead us, because if we accept that they aren&#x2019;t smart and that they <em>willingly mislead us</em>, we&#x2019;d have to accept that the powerful are, well, <em>bad and possibly unremarkable.</em>&#xA0;</p><p>And if they&#x2019;re untrustworthy people that don&#x2019;t seem that smart, we have to accept that the world is deeply unfair, and caters to people like them far more than it caters to people like us.</p><p>We do not owe Satya Nadella any respect because he&#x2019;s the CEO of Microsoft.&#xA0; If anything, we should show him outright scorn for the state of Microsoft products. Microsoft Teams is an insulting mess that only sometimes works, <a href="https://www.theregister.com/2023/05/10/microsoft_work_trend_index/?ref=wheresyoured.at"><u>leaving workers spending 57% of their time either in Teams Chat, Teams Meetings or sending emails according to a Microsoft study</u></a>.</p><p>MSN.com is an abomination read by hundreds of millions of people a month, bloated with intrusive advertisements, attempts to trick you into downloading an app, <a href="https://futurism.com/msn-is-publishing-more-fake-news?ref=wheresyoured.at"><u>and quasi-content that may or may not be AI generated</u></a>. There are few products on the modern internet that show more contempt for the user -- other than, of course, Skype, a product that Microsoft let languish for more than a decade, the product so thoroughly engorged with spam that leaving it unattended for more than a month left you with a hundred unread messages from Eastern European romance scammers. <a href="https://www.pcgamer.com/gaming-industry/skype-dead-at-22/?ref=wheresyoured.at"><u>Microsoft finally killed it in May</u></a>.</p><p>Products like Word and Excel don&#x2019;t need improving, but that doesn&#x2019;t stop Microsoft from trying, bloating them with <a href="https://news.ycombinator.com/item?id=24071085&amp;ref=wheresyoured.at"><u>odd user interface choices</u></a> and forcing users to fight with popups to <a href="https://news.ycombinator.com/item?id=42831281&amp;ref=wheresyoured.at"><u>use an AI-powered Copilot that most of them hate</u></a>.</p><p>Why, exactly, are we meant to show these people respect? Because they run a company that provides a continually-disintegrating service? Because that service has such a powerful monopoly that it&#x2019;s difficult to leave it if you&#x2019;re interacting with other people or businesses?&#xA0;</p><p>I think it&#x2019;s because we <em>live in Hell</em>. The modern tech ecosystem is so utterly vile. Every single day our tech breaks in new and inventive ways, our iPhones resetting at random, random apps not accepting button presses, our Bluetooth disconnecting, our word processors harassing us to &#x201C;try and use AI&#x201D; <a href="https://support.google.com/docs/thread/259770316/spell-check-and-spelling-suggestions-not-working-when-working-absolutely-useless?hl=en&amp;ref=wheresyoured.at"><u>while no longer offering us suggestions for typos</u></a>, and our useful products replaced with useless shit, like&#xA0; how <a href="https://blog.google/products/gemini/google-assistant-gemini-mobile/?ref=wheresyoured.at"><u>Google&#x2019;s previously-functional assistants were replaced</u></a><a href="https://www.reddit.com/r/GooglePixel/comments/1kqteac/gemini_still_sucks_and_it_has_sabotaged_the/?ref=wheresyoured.at"><u>with generative AI that makes them tangibly worse</u></a><a href="https://www.theverge.com/google/654641/google-reveals-gemini-ai-has-350-million-monthly-active-users?ref=wheresyoured.at"><u>so that Google can claim it has 350 million monthly active Gemini users</u></a>.&#xA0;</p><p>Yet the tech and business media acts as if everything is <em>fine</em>.&#xA0;</p><p><em>It isn&#x2019;t fine! It&#x2019;s all really fucked!</em> You can call me a cynic or a pessimist or every name under the sun, but the stakes have never been higher, and the damage never more wide-spread. <em>Everything</em> feels broken, and covering these companies as if it isn&#x2019;t is insulting to your readers and your own intelligence.</p><p>Look at the state of your computer or phone and tell me anything feels congruent or intentional rather than an endless battle of incentives. Look at the <em>notifications on your phone</em> and count the number of them that have absolutely nothing to do with information you actively need. As we speak, I have a notification from Adobe Lightroom, an app I use occasionally to edit photos, that tells me &#x201C;Elevate any scene - now enhance people, sky, water and more with Quick Actions.&#x201D; Zerocam, an app that brands itself &#x201C;the first anti-AI camera app&#x201D; where you &#x201C;capture moments, not megapixels,&#x201D; gave me a notification asking if I took a photo today. Amazon notified me that there is a deal picked just for me &#x2014; a battery pack that I bought several months ago.</p><p>Every single company that sends notifications like these should be mocked, but we have accepted such vile conditions as the norm. Apple should be tarred and feathered for <em>allowing</em> companies to send spam notifications, and yet it isn&#x2019;t&#xA0; because, by and large, Apple is <em>less</em> vile and <em>less</em> exploitative than Microsoft, Google or Amazon.</p><p>If you are reading this as a member of the tech press, <em>seriously, please look at your daily experience with tech.</em> Count the number of times that your day or a task is interrupted by poorly-designed software or hardware (such as the many, many times Zoom or Teams has a problem with Bluetooth, or a website just doesn&#x2019;t load, or you type something into your browser and it just doesn&#x2019;t do anything), or when the software you use either actively impedes you (hey, did you want to use AI? No? You sure?) or refuses to work in a logical way (see: Google Drive). There are tens of thousands of stories like this every day, and if you talked to people, you&#x2019;d see how widespread it is&#x2026;or maybe, I dunno, see that it&#x2019;s happening to you too?</p><p>There are people responsible, and the tech media writes about them every day. I realize it seems weird to constantly write that a company is releasing broken, convoluted software, but hey, if we can write 300,000 stories about how crime-ridden New York City is, why can&#x2019;t we write three of them about how fucked Microsoft Office or Google Search have become?</p><p>And why can&#x2019;t we <em>talk to the people in power about it?</em> Is it because the questions are too hard to ask? Is it because it feels icky to <a href="https://www.bloomberg.com/news/features/2025-05-15/microsoft-ceo-satya-nadella-on-his-ai-efforts-and-openai-partnership?ref=wheresyoured.at"><u>interrupt Satya Nadella as he waffles on about using Copilot all the time</u></a> by saying &#x201C;hey man, Microsoft Teams is broken, tons of people feel this way, why?&#x201D; or &#x201C;why have you let <a href="http://msn.com/?ref=wheresyoured.at"><u>MSN.com</u></a> turn into a hub of <a href="http://ore-fake-news/?ref=wheresyoured.at"><u>AI slop</u></a> and <a href="https://futurism.com/microsoft-pumping-internet-full-garbage-ai-news?ref=wheresyoured.at"><u>outright disinformation</u></a>?&#x201D;</p><p>Oh no! You won&#x2019;t get your access! Wahh!</p><p>Who cares? Write a story about how Microsoft has become so unbelievably profitable as its products get worse, and talk about how weird and bad that is for the world! Ask Nadella those tough questions, or publish that Microsoft&#x2019;s PR wouldn&#x2019;t let you!&#xA0;</p><p>These people are neither articulate nor wise, and whatever &#x201C;intelligence&#x201D; they may claim to have doesn&#x2019;t seem to manifest in good products or intelligent statements. So why treat them like they&#x2019;re smart? Why show them deference or pleasantries? These people have crapped up our digital lives at scale, and they deserve <strong>contempt</strong>, or <em>at the very least a stern fucking reception.</em></p><p>I realize I&#x2019;m repeating points I&#x2019;ve made again and again, but why is there such a halo around these fucking bozos? I&#x2019;m serious! Why are we so protective of these guys? We&#x2019;re more than happy to criticise celebrities, musicians, professional sports players, and politicians (fucking barely), but the business class is somehow protected outside of the occasional willingness to say that Elon Musk might have sort have done something wrong.</p><p>I&#x2019;m not denying there are critics. We have <a href="https://www.mollywhite.net/?ref=wheresyoured.at"><u>Molly White</u></a>, <a href="https://thetechbubble.substack.com/?ref=wheresyoured.at"><u>Edward Ongweso Jr</u></a>, <a href="https://www.bloodinthemachine.com/?ref=wheresyoured.at"><u>Brian Merchant</u></a> and &#x2014; at a major outlet like CNN, no less! &#x2014; <a href="https://www.cnn.com/profiles/allison-morrow?ref=wheresyoured.at"><u>one of the greatest living business writers in Allison Morrow</u></a>. I believe that tech criticism is a barely-explored and hugely-profitable industry if we treated tech journalism less like the society pages and more like a force to hold the most powerful people in the world accountable as they continually harm billions of people in subtle ways. People are angry, and they aren&#x2019;t stupid, and they want to see that anger reflected in the stories they read &#x2014; and the meek deference we show to dumb fucking tech leaders is the opposite of that.&#xA0;</p><p>As I&#x2019;ve said before: we live in an era of digital tinnitus, nagged by notifications, warring with software ostensibly built for us that acts as if we&#x2019;re the enemy. And if we&#x2019;re the enemy, we should treat those building this software as the enemy in return. We are their customers, and they have failed us.</p><p>The entire approach to business owners, especially in tech, is ridiculous. These people are selling us a product and the product fucking stinks! Put aside however you feel about generative AI for a second and face one very simple point: it doesn&#x2019;t do enough, it&#x2019;s really not cool at all, and we&#x2019;re being forced to use it.&#xA0;</p><p>I realize that some of you may want them to succeed, or want to be the person who tells everybody that they did so. I get that there are rewards for you &#x2014; promotions, new positions, TV appearances repeating exactly what the powerful did and why they did it, or a plush role as that company&#x2019;s head of communications &#x2014; but <em>I am telling you, your readers and viewers are waking up to it, and they feel like you have contempt for them and contempt for the truth.</em>&#xA0;</p><p>It&#x2019;s easy &#x2014; and common! &#x2014; to try and dismiss my work as some sort of hater&#x2019;s screed, a &#x201C;cynical&#x201D; approach to a tech industry that&#x2019;s trying &#x201C;brave new things&#x201D; or whatever.&#xA0;</p><p>In my opinion, there&#x2019;s nothing more cynical than watching billions of people get shipped increasingly-shitty and expensive solutions and then <strong>get defensive of the people shipping them, </strong>and hostile to the people who are complaining that the products they use suck<strong>.</strong>&#xA0;</p><p>I am angry at these companies because they have, at scale, torn down a tech industry that allowed me to be who I am today, and their intentional and disgraceful moves fill me full of disgust. I have watched the tech media move away from covering &#x201C;technology&#x201D; and more toward covering <em>the people behind it</em>, to the point that the actual outputs &#x2014; the software and hardware we use every day &#x2014; have taken a backseat to stories <a href="https://www.yahoo.com/news/elon-musk-lawyers-claim-doesn-130000418.html?ref=wheresyoured.at"><u>about whether Elon Musk does or doesn&#x2019;t use a computer</u></a>, which is meaningless, empty gossip journalism built to be shared by peers and nothing else.</p><p>And please, <em>please</em> do not talk about <em>optimism.</em> If you are blindly saying that everything OpenAI does is cool and awesome and interesting, you aren&#x2019;t being optimistic &#x2014; you&#x2019;re <strong>telling other people to be optimistic about a company&#x2019;s success</strong>. It isn&#x2019;t &#x201C;optimistic&#x201D; to believe that a company is going to build powerful AI despite it failing to do so. It&#x2019;s propaganda, and yes, this is also the case if you simply don&#x2019;t do the research to form a real opinion.</p><p>I am not a pessimist because I criticize these companies, and framing me as one is cowardly and ignorant. If you are so weak-willed and speciously-informed that you can&#x2019;t see somebody criticise a company without outright dismissing them as &#x201C;a hater&#x201D; or &#x201C;pessimist,&#x201D; you are an insult to journalism or analysis, and you know it in your wretched little heart. My heart sings with a firm belief in the things I think, founded on rigorous structures of knowledge that I&#x2019;ve gained from reading things and talking to people, because something in me is incapable of being swayed by something just because everybody else is.&#xA0;</p><p>You are assuming people are right because it is inconvenient and uncomfortable to accept they may not be, because doing so requires you to reckon with <a href="https://www.wheresyoured.at/rotcombubble/"><u>a market-wide hysteria founded on desperation and a lack of hyper-growth markets left in the tech industry</u></a>.&#xA0;</p><p>Worse still, in engaging with faux-optimism, you are failing to protect your readers and the general public.&#xA0;&#xA0;</p><p>And if that&#x2019;s what you want to do, ask yourself why! Why do you want these companies to win? What is it you want them to win? Do you want them to be rich? Do you want to be the person that told people they would be first? What is the world you want, and what does it look like, and how does doing your job in this way work toward creating that world?</p><p>This isn&#x2019;t optimism &#x2014; it&#x2019;s horse-trading, or strategic alignment behind powerful entities. It is choosing a side, because your side isn&#x2019;t with the reader or the truth. If it was &#x2014; even if you <em>believed</em> generative AI was powerful and that they simply didn&#x2019;t understand &#x2014; your duty would be to educate the reader in a clear-set and obvious way, and if you can&#x2019;t find a way to do so, acknowledging that and explaining why.</p><p>True optimism requires you to have a deep, meaningful understanding of things so that you can engage in real hope &#x2014; a magical feeling, one that can buoy you in the most challenging times.</p><p>What many claim is &#x201C;optimism&#x201D; is actually <em>blind faith, </em>the likes of which you&#x2019;ll see at a roulette table. Or, of course, knowingly peddling propaganda.</p><hr><p>Let&#x2019;s even take a different tact: say you actually want these companies to &#x201C;build powerful AI,&#x201D; and believe they&#x2019;re smart enough to do so. Say that, somehow, looking at their decaying finances, the lack of revenue, the lack of growth, and the remarkable lack of use cases, you still come out of it saying &#x201C;sure, I think they&#x2019;re going to do this!&#x201D;</p><p>How? Why haven&#x2019;t they done it yet? Why, three years in, are we still unable to describe what ChatGPT actually does, and why we need it? Take away how much money OpenAI makes for a second (and, indeed, how much it loses). Does this product actually really inspire anything in you? What is it that&#x2019;s magical about this?&#xA0;</p><p>And, on a business level, what is it I&#x2019;m meant to be impressed by, exactly? OpenAI has &#x2014; allegedly &#x2014; hit &#x201C;$<a href="https://www.cnbc.com/2025/06/09/openai-hits-10-billion-in-annualized-revenue-fueled-by-chatgpt-growth.html?ref=wheresyoured.at"><u>10 billion in annualized revenue</u></a>&#x201D; (essentially the biggest month it can find, multiplied by 12), which is&#x2026;not that much, really, considering it&#x2019;s the most prominent company in the software world, with the biggest brand, and with the attention of the entirety of the world&#x2019;s media.&#xA0;</p><p>It has, allegedly, 500 million weekly active users &#x2014; and, by the last count, only <a href="https://www.theinformation.com/articles/chatgpt-subscribers-nearly-tripled-to-15-5-million-in-2024?rc=kz8jh3&amp;ref=wheresyoured.at"><u>15.5 million paying subscribers</u></a>, an absolutely putrid conversion rate even before you realize that the <em>actual</em> conversion rate would be monthly active subscribers. That&#x2019;s how any real software company actually defines its metrics, by the fucking way.&#xA0;</p><p>Why is this impressive? Because it grew fast? It literally had more PR and more marketing and more attention and more opportunities to sell to more people than any company has ever had in the history of anything. Every single industry has been told to think about AI for three years, and they&#x2019;ve been told to do so because of a company called OpenAI. There isn&#x2019;t a single god damn product since Google or Facebook that has had this level of media pressure, and both of those companies launched without the massive amount of media (and social media) that we have today.&#xA0;</p><p>Having literally everybody talking about your product all the time for years is pretty useful! Why isn&#x2019;t it making more money?&#xA0;</p><p>Why are we taking any of these people seriously? <a href="https://www.wheresyoured.at/whatre-we-even-doing/"><u>Mark Zuckerberg paid $14.3 billion for Scale AI, an AI data company, as a means of hiring its CEO Alexandr Wang to run his &#x201C;superintelligence&#x201D; team</u></a>, <a href="https://techcrunch.com/2025/06/17/sam-altman-says-meta-tried-and-failed-to-poach-openais-talent-with-100m-offers/?ref=wheresyoured.at"><u>has been offering random OpenAI employees $100 million to join Meta</u></a>, thought about <a href="https://www.cnbc.com/2025/06/20/meta-perplexity-scale-ai-deal.html?ref=wheresyoured.at"><u>buying both AI search company Perplexity</u></a> and <a href="https://www.benzinga.com/markets/equities/25/06/46070157/meta-reportedly-tried-to-buy-ai-video-startup-runway-before-14-billion-scale-ai-bet-report?ref=wheresyoured.at"><u>generative video company Runway</u></a><em></em>and <a href="https://www.cnbc.com/2025/06/19/meta-tried-to-buy-safe-superintelligence-hired-ceo-daniel-gross.html?ref=wheresyoured.at"><em><u>even tried to buy OpenAI co-founder Ilya Sutskever&#x2019;s pre-product &#x201C;$32bn valuation&#x201D; non-company Safe Superintelligence</u></em></a><em>, </em>settling instead on hiring its CEO Daniel Gross and buying his venture fund <em>for some fucking reason.</em></p><p>When you put aside the big numbers, these are the actions of a desperate dimwit with a failing product trying to buy his way to making generative AI into a &#x201C;superintelligence,&#x201D; <a href="http://youtube.com/watch?v=4__gg83s_Do&amp;ref=wheresyoured.at"><u>something that <em>Meta&#x2019;s own Chief AI scientist Yan LeCun says isn&#x2019;t going to work</em></u></a><em>.</em></p><p>By assuming that there is some sort of grand strategy behind these moves beyond &#x201C;if we get enough smart people together something will happen,&#x201D; you help boost the powerful&#x2019;s messaging and buoy their stock valuations. You are not educating anybody by humouring these goofballs. In fact, the right way to approach this would be to ask why Meta, a multi-trillion dollar market cap company with a near-monopoly over all social media, is spending billions of dollars in what appears to be a totally irresponsible way. Instead, <a href="https://www.axios.com/2025/06/20/meta-zucker-berg-ai-daniel-gross?ref=wheresyoured.at"><u>people are suggesting this is Mark Zuckerberg&#x2019;s genius at work</u></a><em>.&#xA0;</em></p><p>Anyway, putting that aside, what exactly is the impressive part of generative AI again? The fucking code? Enough about the code, I&#x2019;m tired of hearing about the code, I swear to god you people think that being a software engineer is only coding and that it&#x2019;s fine if you ship &#x201C;<a href="https://fly.io/blog/youre-all-nuts/?ref=wheresyoured.at"><u>mediocre code</u></a>,&#x201D; as if bad code can&#x2019;t bring down entire organizations. What do you think a software engineer does? Is all they do code? If you think the answer is yes, you are <em>wrong!</em></p><p>Human beings may make mistakes in writing code, but they at least know what a mistake looks like, which a generative AI does not, because a generative AI doesn&#x2019;t know what anything is, or anything at all, because it is a probabilistic model.&#xA0;</p><p>Congratulations! You made another way in which software engineers can automate <em>parts</em> of their jobs &#x2014; stop being so fucking excited about the idea that people are going to lose their livelihoods! It&#x2019;s nasty, and founded on <strong>absolutely nothing other than your adulation for the powerful!</strong></p><p>These models are dangerous and chaotic, built with little intention or regard for the future, just like the rest of big tech&#x2019;s products. ChatGPT would&#x2019;ve been a much smaller deal if Google had any interest in turning Google Search into a product that truly answered a query (as opposed to generating more of them to show more impressions to advertisers) &#x2014; a nuanced search engine that took a user&#x2019;s query and spat out a series of websites that might help answer said question rather than just summarising a few of them for an answer.&#xA0;</p><p>And if you ever need proof that Google just doesn&#x2019;t know how to fucking innovate anymore, look at AI Summaries, a product that both misunderstands search and why people use ChatGPT as a search replacement. While OpenAI may &#x201C;summarise&#x201D; stuff to give an answer, it at the very least gives something approximating a true answer, rather than a summary that feels like an absentee parent trying to get rid of you and then throwing you $20 in the hopes you&#x2019;ll leave them alone. If Google Search truly evolved, ChatGPT wouldn&#x2019;t really matter, because the idea of a machine that can theoretically answer a question is kind of why people used fucking Google in the fucking first place.</p><p>Again, why are we not describing this company as the business equivalent of a banana republic? It&#x2019;s actively making its shit worse to juice growth, and it&#x2019;s really obvious how badly it sucks.&#xA0;</p><p>Why doesn&#x2019;t the state of Google dominate tech news, just like how random ketamine-fuelled tweets from Elon Musk do? Why aren&#x2019;t we, collectively, repulsed by Google as a company? Why aren&#x2019;t we, collectively, repulsed by OpenAI?&#xA0;</p><p>No matter how big ChatGPT is, the fact that there&#x2019;s a product out there with hundreds of millions of users that constantly gets answers wrong is a genuinely worrying thing for society, and that&#x2019;s before you get to the environmental damage, the fact it trained its models on millions of people&#x2019;s art and writing, and oh, I dunno, the fact it plans to lose over a hundred billions of dollars before becoming profitable?&#xA0;</p><p>Why are we not more horrified? Why are we not more forlorn that this is where hundreds of billions of dollars are being forced? The most prominent company in the tech industry is an unstable monolith with a vague product that can only make $10 billion a year (revenue, not profit) as the very fabric of its existence is shoved down the throat of every executive in the world at once. Also, if it&#x2019;s not fed $20 billion to $40 billion a year, it will die.&#xA0;</p><p>Give me a fucking break.</p><p>I don&#x2019;t know, I sound pretty ornery, I get accused of being a hater or missing the grand mystery of this bullshit every few minutes by somebody with an AI avatar of a guy who looks like he&#x2019;s banned from multiple branches of Best Buy, I understand there&#x2019;s things that people do with Large Language Models, I am aware, but none of it matters because the way they&#x2019;re being discussed is like we&#x2019;re two steps from digitally replacing hundreds of millions of people.</p><p>The reality is far simpler: we have an industry that has spent nearly half a trillion dollars between its capital expenditures and venture capital funding to create another industry with the combined revenue of the fucking smartwatch industry. What I&#x2019;m writing isn&#x2019;t inflammatory &#x2014; in fact, it&#x2019;s far more deeply rooted in reality than those claiming that OpenAI is building the future.</p><p><strong><em>Let&#x2019;s do some fucking mathematics!</em></strong></p><p><strong>Projected Big Tech Capital Expenditures in 2025 and revenue from AI:</strong></p><ul><li><a href="https://www.cnbc.com/2025/02/24/microsoft-reiterates-plan-to-invest-80-billion-in-ai-.html?ref=wheresyoured.at#:~:text=Microsoft%20reiterates%20plan%20to%20invest%20%2480%20billion%20in%20AI%2C%20but,our%20infrastructure%20in%20some%20areas&apos;&amp;text=Microsoft%20said%20it%20might%20make,year%2C%20which%20ends%20in%20June."><u>Microsoft: $80 billion.</u></a><ul><li><a href="https://www.theinformation.com/articles/microsoft-bets-agents-fuel-next-chapter-ai-growth?rc=kz8jh3&amp;ref=wheresyoured.at"><u>The Information reported in early June that Microsoft is projected to make $13 billion in annual revenue this year from AI</u></a>. Microsoft has not updated its annualized revenue publicly since January, <a href="https://www.geekwire.com/2025/microsoft-earnings-2/?ref=wheresyoured.at"><u>when they said it was projected to be $13 billion this year</u></a>, suggesting it&#x2019;s stalled. Also, this is not profit, and $10 billion of that comes from OpenAI&#x2019;s compute spend on Azure. So, uhh. $3 billion? Jesus christ.</li></ul></li><li><a href="https://www.datacenterdynamics.com/en/news/meta-raises-ai-data-center-capex-forecast-to-up-to-72bn-blames-trump-tariffs-for-increased-cost/?ref=wheresyoured.at#:~:text=The%20US%20trade%20war%20against,%2C%20market%20reports%2C%20and%20more."><u>Meta: $72 billion</u></a>.<ul><li>Meta is not making any money from generative AI. If we include Meta&#x2019;s Ray Bans, which have <a href="https://www.theverge.com/news/613292/meta-ray-ban-2-million-10-million-capacity-subscription-essilor-luxottica-earnings?ref=wheresyoured.at"><u>&#xA0;sold 2 million units in the last two years, we&#x2019;re left with around $600 million in revenue</u></a> &#x2014; though that isn&#x2019;t profit, and Meta hasn&#x2019;t said if they&#x2019;re profitable. None of its data center expansion has anything to do with this.</li></ul></li><li><a href="https://finance.yahoo.com/news/amazon-stock-falls-as-raymond-james-downgrades-shares-citing-tariff-headwinds-and-limited-ai-monetization-144747355.html?ref=wheresyoured.at"><u>Amazon: $100 billion</u></a>.<ul><li>An analyst speaking to Yahoo! Finance in the above link believes Amazon will make $5 billion in revenue from AI in 2025.</li></ul></li><li><a href="https://www.reuters.com/technology/alphabet-ceo-reaffirms-planned-75-billion-capital-spending-2025-2025-04-09/?ref=wheresyoured.at"><u>Google: $75 billion.</u></a><ul><li>Google does not break out AI revenue, and the media helped push the narrative that AI helped it increase revenue because <a href="https://www.reuters.com/business/google-parent-alphabet-beats-quarterly-revenue-estimates-2025-04-24/?ref=wheresyoured.at"><u>Sundar Pichai mentioned</u></a> in a statement that &#x201C;search saw continued strong growth, boosted by the engagement we&#x2019;re seeing with features like AI Overviews, which now has 1.5 billion users a month&#x201D; because Google forced billions of users to use it. Also, &#x201C;AI&#x201D; can mean all sorts of things outside of generative AI.</li></ul></li></ul><p>That&#x2019;s $327 billion <em>this year</em>, with a total revenue of&#x2026;what, $18 billion of revenue? And that&#x2019;s not profit! And that&#x2019;s if we include OpenAI&#x2019;s spend on Azure. Even if every single one of these companies was making $18 billion in revenue a year from this it <em>wouldn&#x2019;t be great</em>, but it&#x2019;s more than likely that these chunderfucks can&#x2019;t even pull together the projected revenue (<a href="https://www.statista.com/outlook/hmo/digital-health/digital-fitness-well-being/fitness-trackers/smartwatches/worldwide?ref=wheresyoured.at"><u>$32 billion</u></a>) of the global smartwatch industry! What a joke!&#xA0;</p><p>&#x201C;Wuhh, but what about OpenAI?&#x201D;&#xA0;</p><p>What <em>about</em> OpenAI? <a href="https://www.wheresyoured.at/openai-is-a-systemic-risk-to-the-tech-industry-2/"><u>I&#x2019;ve written about this so much</u></a>. So what, OpenAI makes $12.7 billion this year, but loses $14 billion, what does that mean to you, exactly? What&#x2019;re you going to say? The cost of inference is coming down? No, <em>the cost that people are being charged is going down, <strong>we have no firm data on the actual costs because the companies don&#x2019;t want to talk about it</strong>, and yes, it will absolutely lower prices to compete with other companies. </em><a href="https://www.theinformation.com/articles/openai-starts-selling-chatgpt-discount-hurting-microsoft?rc=kz8jh3&amp;ref=wheresyoured.at"><em><u>The Information just reported that OpenAI was doing this to compete with Microsoft last week!</u></em></a></p><p>Hey, quick question &#x2014; <a href="https://group.softbank/en/news/press/20250203_0?ref=wheresyoured.at"><u>wasn&#x2019;t SoftBank meant to spend $3 billion annually on OpenAI&#x2019;s software?</u></a> Did that happen?&#xA0;&#xA0;</p><p>Anyway, even if we add OpenAI&#x2019;s revenue to the pot, we are at $30.7 billion. <a href="https://www.theinformation.com/articles/little-known-startup-surged-past-scale-ai-without-investors?rc=kz8jh3&amp;ref=wheresyoured.at"><u>If we add the supposed $1 billion in revenue from training data startup Surge</u></a>, <a href="https://www.businesswire.com/news/home/20250128158063/en/Turing-Annual-Revenue-Runrate-Nearly-Triples-to-%24300M-in-Profitable-Year-as-Company-Sets-Stage-for-AGI-Advancements-in-2025?ref=wheresyoured.at"><u>$300 million in &#x201C;annualized revenue&#x201D; from Turing</u></a>, <em>optimistically </em>assume that Perplexity will have $100 million (<a href="https://www.theinformation.com/articles/google-challenger-perplexity-growth-comes-high-cost?rc=kz8jh3&amp;ref=wheresyoured.at"><u>up from $34 million in 2024, where it burned $65 million</u></a>) in revenue in 2025, and <a href="https://www.theinformation.com/briefings/cursor-hits-200-million-annual-recurring-revenue?rc=kz8jh3&amp;ref=wheresyoured.at"><u>assume that Anysphere&#x2019;s (which makes Cursor) $200 million run rate stays consistent through 2025</u></a>, we are at&#x2026;$32.3 billion.&#xA0;</p><p>But I&apos;m not being fair, am I? I didn&#x2019;t include many of the names from <a href="https://www.theinformation.com/projects/generative-ai?rc=kz8jh3&amp;ref=wheresyoured.at"><u>The Information&#x2019;s generative AI database</u></a>. Prepare yourself, this is gonna be annoying!  </p><p>So let&apos;s add some more. We&#x2019;ve got $3 billion from Anthropic, $870 million from Scale (now part of Meta), another alleged $300 million for Anysphere (The Information claims $500 million in ARR), we consider Neo4j&#x2019;s &#x201C;&gt;$200 million ARR&#x201D; to mean &#x201C;$200 million,&#x201D; Midjourney&#x2019;s &#x201C;&gt;$200 million ARR&#x201D; to mean $200m, Ironclad&#x2019;s &#x201C;&gt;$150 million ARR&#x201D; to mean $150 million ARR, Glean&#x2019;s $103 million ARR, Together AI&#x2019;s $100 million ARR, Moveworks&#x2019; $100 million ARR, Abridge&#x2019;s $100 million ARR, Synthesia&#x2019;s $100 million ARR, WEKA&#x2019;s &#x201C;&gt;$100 million ARR&#x201D; to mean $100m ARR, Windsurf&#x2019;s $100m ARR, Runway&#x2019;s $84 million ARR, Elevenlabs&#x2019; &#x201C;&gt;$100m ARR&#x201D; to mean $100m ARR, Cohere&#x2019;s $70m ARR, Jasper&#x2019;s &#x201C;&gt;$60m ARR&#x201D; to mean $60m, Harvey&#x2019;s $50m ARR, Ada&#x2019;s &#x201C;&gt;$50m ARR&#x201D; to mean $50m, Photoroom&#x2019;s $50m ARR&#x2026;and then assumed the combined ARR of the remainders are somewhere in the region of a <em>very generous </em>$200m, we get&#x2026;</p><p><strong><em>Less than $39 billion dollars of total revenue in the entire generative AI industry. <u>Jesus fucking christ!</u></em></strong>&#xA0;</p><p>According to The Information, generative AI companies have raised more than $18.8 billion in the first quarter of 2025, after investing $21 billion in Q4 2024 and $4 billion in Q3 2024 for a grand total of $43.8 billion, or <strong>a total of $370.8 billion of investment and capital expenditures for an industry that, despite being the single-most talked about thing on the planet, cannot even create a tenth of the dollars it requires to make it work.</strong></p><p>These companies are predominantly unprofitable, perpetually searching for product-market fit, and even when they find it, seem incapable of generating revenue numbers that remotely justify their valuations.&#xA0;</p><p>If I&#x2019;m honest, I think the truly radical position here is the one taken by most tech reporters that would rather take the lazy position of &#x201C;well Uber lost a lot of money!&#x201D; than think for two seconds about whether we&#x2019;re all being sold a line of shit.</p><p>What we&#x2019;re watching is a mountain of waste perpetuated by the least-charming failsons of our generation. Nobody should be giving Satya Nadella or Sam Altman a glossy profile &#x2014; they should be asking direct, brutal questions, much like Joanna Stern just did of Apple&#x2019;s Craig Federighi, who had absolutely fucking nothing to share because he has never been pushed like this.&#xA0;</p><p>Put aside the money for a second and be honest: these men are pathetic, unimpressive, uninventive, and dreadfully, dreadfully boring. Anthropic&#x2019;s Wario (Sorry, Dario) Amodei and OpenAI&#x2019;s Sam Altman have far more in common with televangelist Joel Olstein than they&#x2019;ll ever have with Steve Jobs or any number of people that have actually invented things, and they got that way because we took them seriously instead of saying &#x201C;wait, what do you mean?&#x201D; To a single one of their wrongheaded, oafish and dim-witted hype-burps.&#xA0;</p><p>It&#x2019;s boring! I&#x2019;m terribly, horribly bored, and if you&#x2019;re interested in this shit I am genuinely curious why, especially if you&#x2019;re a reporter, because right now the &#x201C;innovation&#x201D; happening in AI is, at best, further mutations of the Software As A Service business model, providing far less value than previous innovations at a calamitous cost.&#xA0;</p><p>Reasoning models don&#x2019;t even reason, <a href="https://x.com/RubenHssd/status/1931389580105925115?ref=wheresyoured.at"><u>as proven by an Apple paper released a few weeks ago</u></a>, and agents as a concept are fucked because large language models are inherently unreliable &#x2014; and yes, <a href="https://www.reddit.com/r/BetterOffline/comments/1l6wdwb/salesforce_research_ai_customer_support_agents/?ref=wheresyoured.at"><u>a study out of fucking Salesforce found that agents began to break down when given multi-step tasks, such as &#x201C;any task you&#x2019;d want to have an agent automate.&#x201D;&#xA0;</u></a></p><p>So, here&#x2019;s my radical suggestion: start making fun of these people.</p><p>They are not charming. They are not building anything. They have scooted along amassing billions of dollars promising the world and delivering you a hill of dirt. They deserve our derision &#x2014; or, at the very least, our deep, unerring suspicion, if not for what they&#x2019;ve done, but for what they&#x2019;ve not done. Sam Altman is nowhere near delivering a functioning agent, let alone anything approaching intelligence, and really only has one skill: making other companies risk a bunch of money on his stupid ideas.</p><p>No, really! <a href="https://www.reuters.com/business/oracle-buy-40-billion-nvidia-chips-openais-us-data-center-ft-reports-2025-05-23/?ref=wheresyoured.at"><u>He convinced Oracle to buy $40 billion of NVIDIA chips to put in the Abilene Texas &#x201C;Stargate&#x201D; data center</u></a>, despite the fact that the Stargate organization has yet to be formed (<a href="https://www.theinformation.com/briefings/oracle-ceo-says-openais-stargate-venture-formed-yet?rc=kz8jh3&amp;ref=wheresyoured.at"><u>as reported by The Information</u></a>). SoftBank and Microsoft pay all of OpenAI&#x2019;s bills, and the media does his marketing for him.&#xA0;</p><p>OpenAI is, as I said, quite literally a banana republic. It requires the media and the markets to make up why it has to exist, it requires other companies to pump it full of money and build its infrastructure, and it doesn&#x2019;t even make products that matter, with Sam Altman constantly talking about all the exciting shit <em>other people will build</em>.&#xA0;</p><p>You can keep honking about how &#x201C;it built the API that will power the future,&#x201D; but if that&#x2019;s the case, where&#x2019;s the fucking future, exactly? Where is it? What am I looking at here? Where&#x2019;s the economic activity? Where&#x2019;s the productivity? The returns suck! The costs are too high!&#xA0;</p><p>Why am I the radical person for saying this? This entire situation is absolutely god damn ridiculous, an incomparable waste even if it somehow went in the green. For the horrendous amounts of capital invested in generative AI to make sense, the industry would have to have revenue that dwarfed the smartphone and enterprise SaaS market combined, rather than<a href="https://www.globenewswire.com/news-release/2024/12/06/2992938/28124/en/Growth-Trends-in-the-Mobile-Gaming-Industry-2024-2029.html?ref=wheresyoured.at"><u>less than half of that of the mobile gaming industry</u></a>.</p><p>Satya Nadella, Sam Altman, Wario Amodei, Tim Cook, Andy Jassy &#x2014; they deserve to be laughed at, mocked, or at the very least interrogated vigorously, because their combined might has produced no exciting or interesting products outside of, at best, what will amount to a productivity upgrade for integrated development environments and faster ways to throw out code that may or may not be reliable. These things aren&#x2019;t nothing, but they&#x2019;re nowhere near the something that we&#x2019;re being promised.</p><p>So I put it to you, dear reader: why are we taking them seriously? What is there to take seriously other than their ability to force stuff on people?</p><p>And I&#x2019;ll leave you with a question: how do they manage to keep doing this, exactly? They always seem to find new growth, every single quarter, without fail? Is it because they keep coming up with new ideas? Or is it because they come up with new ideas to get more money, a vastly different choice that involves increasing the prices of products or making them worse so that they can show you more advertisements.</p><p>My positions are not radical, and if you believe they are, your deference to the powerful disgusts me.</p><hr><p>In any case, I want to end this with something inspirational, because I believe that things change when regular people feel stronger and more capable.</p><p>I want you to know that you are fully capable of understanding all of this. I don&#x2019;t care if you &#x201C;aren&#x2019;t a numbers person&#x201D; or &#x201C;don&#x2019;t get business.&#x2019; I don&#x2019;t have a single iota of economics training, and everything you&#x2019;ve ever read me write has been something I&#x2019;ve had to learn. I was a layperson right up until I learned the stuff, then I became a stuff-knower, just like you can be.</p><p>The tech industry, the finance industry, the entire mechanisms of capitalism want you to believe that everything they do is magical and complex, when it&#x2019;s all far more obvious than you&#x2019;d believe. You don&#x2019;t have to understand the entire fundamentals of finance to know how venture capital works &#x2014; they buy percentages of companies at a valuation that they hope is much lower than the company would be worth in the future. You don&#x2019;t need to be technical to know that Large Language Models generate a response based on billions of pieces of training data, and by guessing at what the next bit of text in a line should be based on what it&#x2019;s seen previously.&#xA0;</p><p>These people love to say &#x201C;ah, but didn&#x2019;t you see-&#x201D; and present an anecdote, when no anecdote will ever defeat the basics of &#x201C;your business doesn&#x2019;t make any money, the software doesn&#x2019;t do the things you claim it&#x2019;s meant to, and you have no path to profitability.&#x201D; They can yammer at you all they want about &#x201C;lots of people using ChatGPT,&#x201D; but that doesn&#x2019;t change the fact that ChatGPT just isn&#x2019;t that revolutionary, and <strong>their only play here is to make you feel stupid rather than actually showing you why it&#x2019;s so fucking revolutionary.</strong></p><p>This is the argument of a manipulator and a coward, and you are above such things.</p><p>You don&#x2019;t really have to be a specialist in anything to pry this shit apart, which is why so much of my work is either engaging to those who learn something from it or frustrating to those that intentionally deceive others through gobbledygook hype-schpiel. I will sit here and explain every fucking part of this horrid chain of freaks, and break it down into whatever pieces it takes to educate as many people as I have to to make things <em>change.</em></p><p>I also must be clear that <strong><em>I am nobody.</em></strong> I started writing this newsletter with 300 subscribers and no reason other than the fact I wanted to, and four years later I have nearly 64,000 subscribers and <a href="http://betteroffline.com/?ref=wheresyoured.at"><u>an award-winning podcast</u></a>.&#xA0; I have no economics training, no special access, no deep sources, just the ability to look at things that are happening and say stuff. I taught myself everything I know about this industry, and there is nothing stopping you from doing the same. </p><p>I was convinced I was stupid until around two years ago, though if I&#x2019;m honest it might have been last year. I have felt othered the majority of my life, convinced by people that I am incapable or unwelcome, and as I&#x2019;ve become more articulate and confident in who I am and what I believe in, I have noticed that the only people that seek to degrade or suppress are those of weak minds and weaker wills &#x2014; <a href="https://www.wheresyoured.at/the-era-of-the-business-idiot/"><u>Business Idiots</u></a> in different forms and flavors. I have learned to accept who I am &#x2014; that I am not like most people &#x2014; and people conflate my passion and vigor with anger or hate, when what they&#x2019;re experiencing is somebody different who deeply resents what the powerful have done to the computer.&#xA0;&#xA0;</p><p>And while I complain about the state of media, what I&#x2019;ve seen in the last year is that there are many, many people like me &#x2014; both readers and peers &#x2014; that resent things in the same way. I conflated being different with being alone, and I couldn&#x2019;t be more wrong. For those of you that don&#x2019;t wish to lick the boots of the people fucking up every tech product, the tent is large, it&#x2019;s a big club, and you&#x2019;re absolutely in it.</p><p>A better tech industry is one where the people writing about it hold it accountable, pushing it toward creating the experiences and connectivity that truly change the world rather than repeating and reinforcing the status quo.&#xA0;</p><p>Don&#x2019;t watch the mouth, watch the hands. These companies will <em>tell you</em> that they&#x2019;re amazing as many times as they want, but you don&#x2019;t need to prove that &#x2014; <strong>they do</strong>. I don&#x2019;t care if you tell a single human soul about my work, but if it helps you understand these people better, use it to teach other people.&#xA0;</p><p>These people may seem all-powerful, but they&#x2019;ve built <a href="https://www.wheresyoured.at/the-rot-economy/"><u>the Rot Economy</u></a> on a combination of anonymity and a placant press, but pressure against them starts with you and those you know understanding how their businesses work, and <strong>trusting that you can understand <u>because you absolutely can</u></strong>. Millions of people understanding how these people run their companies and how poorly they&#x2019;ve built their software will stop people like Sundar Pichai from being able to quietly burn Google Search to the ground.&#xA0;</p><p>People like Sam Altman are gambling that you are easily-confused, easily-defeated and incurious, when you could be writing thousands of words on a newsletter that you never, ever edit for brevity. You can understand every fucking part of their business &#x2014; the economics of OpenAI, the flimsy promises of Salesforce, the destruction of Google Search &#x2014; and you can tell everybody you know about it, and suddenly it won&#x2019;t be so easy for these wretched creeps to continue thriving.</p><p>I know it sounds small, and like your role is even smaller, <strong>but the reason they&#x2019;ve grown so rapaciously is driven by the sense that the work they do is some sort of black magic, when it&#x2019;s really fucking stupid and boring finance stapled onto </strong><a href="https://www.wheresyoured.at/rotcombubble/"><strong><u>a tech industry that&#x2019;s run out of ideas</u></strong></a><strong>.&#xA0;</strong></p><p>You are more than capable of understanding this entire world &#x2014; including the technology, along with the finances that ultimately decide what technology gets made next.</p><p>These people have got rich and famous and escaped all blame by casting themselves as somehow above us, when if I&#x2019;m honest, I&#x2019;ve never looked down on somebody quite as much as I do the current gaggle of management consultant fucks that have driven Silicon Valley into the ground.</p>]]>
			</content:encoded>
		</item>
		<item>
			<title>
				<![CDATA[Why Did Microsoft Invest In OpenAI?]]>
			</title>
			<description>
				<![CDATA[<p><a href="https://www.youtube.com/watch?v=V-Cj_ZLGVdY&amp;list=RDV-Cj_ZLGVdY&amp;start_radio=1&amp;ref=wheresyoured.at"><strong><u>Soundtrack: Queens of the Stone Age - Era Vulgaris</u></strong></a></p><p>As ever, thank you for subscribing to Where&apos;s Your Ed At Premium. Email me at ez@betteroffline.com with the subject header &quot;Premium&quot; sometime if you have a question. Please ask your friends to subscribe too. </p><hr><p>Based</p>]]>
			</description>
			<link>https://www.wheresyoured.at/why-did-microsoft-invest-in-openai/</link>
			<guid isPermaLink="false">685da07b4fda1e000130657d</guid>
			<dc:creator>
				<![CDATA[Edward Zitron]]>
			</dc:creator>
			<pubDate>Fri, 27 Jun 2025 13:28:24 GMT</pubDate>
			<content:encoded>
				<![CDATA[<p><a href="https://www.youtube.com/watch?v=V-Cj_ZLGVdY&amp;list=RDV-Cj_ZLGVdY&amp;start_radio=1&amp;ref=wheresyoured.at"><strong><u>Soundtrack: Queens of the Stone Age - Era Vulgaris</u></strong></a></p><p>As ever, thank you for subscribing to Where&apos;s Your Ed At Premium. Email me at ez@betteroffline.com with the subject header &quot;Premium&quot; sometime if you have a question. Please ask your friends to subscribe too. </p><hr><p>Based on recent reporting by<a href="https://www.theinformation.com/articles/openai-microsoft-duel-agi-high-stakes-negotiation?rc=kz8jh3&amp;ref=wheresyoured.at"><u>The Information</u></a> and the<a href="https://www.wsj.com/tech/ai/openai-microsoft-rift-hinges-on-how-smart-ai-can-get-82566509?mod=tech_feat1_ai_pos1&amp;ref=wheresyoured.at"><u>Wall Street Journal</u></a>, some very specific facts have been established:</p><ul><li>OpenAI is the largest customer of Microsoft Azure, where it pays &quot;favorable server rental rates compared to other customers.&quot;</li><li>Per The Information (emphasis mine),<strong> &quot;several top Microsoft executives [during the period where they invested $10 billion in OpenAI] told colleagues they thought OpenAI&#x2019;s business would eventually fail</strong>, even if its technology was good, according to a former manager who discussed it with them.&quot;</li></ul><p><a href="https://www.wheresyoured.at/could-microsoft-kill-openai/"><u>As I discussed in last week&apos;s Friday premium column</u></a>, OpenAI and Microsoft are currently negotiating over the terms under which it would allow OpenAI to convert to a for-profit entity, in which OpenAI is offering Microsoft...a reduction in its revenue share (down to 10%), less stock (33%, down from 49%, though The Wall Street Journal reports that &quot;Microsoft has indicated that it is willing to accept an equity stake of about 35% in the new for-profit company,&quot; though that could easily be a leak from OpenAI), and cutting it off from future intellectual property.</p><p>Hell of a deal! Please read that piece if you want to break down how the non-profit works, because it was a pain in the ass to write.</p><p>In any case, this negotiation is &quot;high stakes&quot; because OpenAI <strong>needs</strong> Microsoft to agree to terms, otherwise OpenAI can&apos;t become a for-profit entity, and thus can never go public. Furthermore, the Wall Street Journal reports that the companies are at odds over the term AGI:</p><p>Many AI experts see AGI as the point at which generative AI systems achieve humanlike intelligence, but OpenAI and Microsoft are at odds over the issue. OpenAI executives including Sam Altman believe they are close to being able to declare that their AI tools have achieved the AGI level of proficiency, according to people familiar with the matter.</p><p>I&apos;ll get into the nitty gritty shortly, but the term &quot;AGI&quot; would allow OpenAI to stop sharing IP with Microsoft.</p><p>That, however, is not what&apos;s making me think.</p><p><a href="https://www.ft.com/content/072e90fe-1c8c-415c-8024-5996b1ebb3cb?ref=wheresyoured.at"><u>The Financial Times reported last week</u></a> that Microsoft was prepared to walk away from its &quot;high-stakes&quot; talks with OpenAI, and closed their piece with this quote:</p><p>A Silicon Valley veteran close to Microsoft said the software giant &#x201C;knows that this is not their problem to figure this out, technically, it&#x2019;s OpenAI&#x2019;s problem to have the negotiation at all&#x201D;.</p><p>When referring to &quot;their problem,&quot; the source is talking about OpenAI&apos;s conversion to a for-profit. Walking away from these negotiations would effectively end OpenAI&apos;s ability to become a for-profit, cutting its recent $40 billion round to $20 billion, make it impossible to take the company public, and likely make it much harder &#x2014; if not impossible &#x2014; for OpenAI to raise further funds.</p><p>To be clear,<a href="https://bsky.app/profile/edzitron.com/post/3lret4tfzoc2i?ref=wheresyoured.at"><u>OpenAI plans to raise another $17 billion in 2027</u></a>, and investors generally invest in a company because they believe they&apos;ll receive a return. The current only way that investors or employees of OpenAI have been able to liquidate their shares has been to other people.<a href="https://www.theinformation.com/articles/openai-employees-cashed-3-billion-shares?rc=kz8jh3&amp;ref=wheresyoured.at"><u>OpenAI employees have cashed out $3 billion so far</u></a>, mostly to SoftBank.</p><p>In simpler terms:</p><ul><li><strong>OpenAI is Microsoft&apos;s biggest Azure customer, providing a projected $10 billion in revenue in 2025, just under 77% of Microsoft&apos;s $13 billion in projected annual revenue</strong> (not profit) from AI<a href="https://www.theinformation.com/articles/microsoft-bets-agents-fuel-next-chapter-ai-growth?rc=kz8jh3&amp;ref=wheresyoured.at"><u>according to The Information</u></a>, who also note that Microsoft made $4.7 billion from AI in 2024, with $2.7bn (57%) of that coming from OpenAI. This means that, outside of OpenAI, Microsoft made $2 billion on AI in 2024.<ul><li>This also means that Microsoft is reporting OpenAI&apos;s compute spend as pure revenue.</li></ul></li><li>Top executives at Microsoft believed OpenAI would die when they gave it $10 billion in funding in 2023.</li><li>Microsoft is directly representing in leaks to the media that it is willing to block OpenAI&apos;s conversion, and knows that this would potentially kill OpenAI &#x2014; and, indeed, previously believed the company would fail.</li><li>The real argument here is over the intellectual property, and neither side wants to budge, with OpenAI making noises that suggest it would pull bullshit games over the definition of AGI.</li></ul><p>So, Microsoft funded and built the infrastructure of its biggest customer, which it also allowed to expand by doing business with Microsoft&#x2019;s competitors in cloud, and now appears to be willing to let it die.</p><p>Why would Microsoft do that?</p><p><a href="https://www.youtube.com/watch?v=-Ps4HarpIJk&amp;ref=wheresyoured.at"><u>What&apos;s going on in Redmond</u></a>?</p>]]>
			</content:encoded>
		</item>
		<item>
			<title>
				<![CDATA[Did Sam Altman and Jony Ive Steal Another Company's Idea?]]>
			</title>
			<link>https://www.wheresyoured.at/ioandiyo/</link>
			<guid isPermaLink="false">6858c3ed2842e800010e5167</guid>
			<dc:creator>
				<![CDATA[Edward Zitron]]>
			</dc:creator>
			<pubDate>Mon, 23 Jun 2025 17:59:10 GMT</pubDate>
			<content:encoded/>
		</item>
		<item>
			<title>
				<![CDATA[Could Microsoft Kill OpenAI?]]>
			</title>
			<link>https://www.wheresyoured.at/could-microsoft-kill-openai/</link>
			<guid isPermaLink="false">6855805b00b0e40001d3788d</guid>
			<dc:creator>
				<![CDATA[Edward Zitron]]>
			</dc:creator>
			<pubDate>Fri, 20 Jun 2025 17:15:44 GMT</pubDate>
			<content:encoded/>
		</item>
		<item>
			<title>
				<![CDATA[Sincerity Wins The War]]>
			</title>
			<description>
				<![CDATA[<p><strong><em>Hello Where&#x2019;s Your Ed At Subscribers! I&#x2019;ve started a premium version of this newsletter with a weekly Friday column where I go over the most meaningful news and give my views, which I guess is what you&#x2019;d expect. Anyway, it&#x2019;s $7 a</em></strong></p>]]>
			</description>
			<link>https://www.wheresyoured.at/sic/</link>
			<guid isPermaLink="false">68502d260c260a0001003d72</guid>
			<dc:creator>
				<![CDATA[Edward Zitron]]>
			</dc:creator>
			<pubDate>Mon, 16 Jun 2025 14:50:13 GMT</pubDate>
			<content:encoded>
				<![CDATA[<p><strong><em>Hello Where&#x2019;s Your Ed At Subscribers! I&#x2019;ve started a premium version of this newsletter with a weekly Friday column where I go over the most meaningful news and give my views, which I guess is what you&#x2019;d expect. Anyway, it&#x2019;s $7 a month or $70 a year, and helps support the newsletter. I will continue to do my big free column too! Thanks.</em></strong></p><hr><p>What wins the war is sincerity.</p><p>What wins the war is accountability.</p><p>And we do not have to buy into the inevitability of this movement.</p><p>Nor do we have to cover it in the way it has always been covered. Why not mix emotion and honesty with business reporting? Why not pry apart the narrative as you tell the story rather than hoping the audience works it out? Forget &#x201C;hanging them with their own rope&#x201D; &#x2014; describe what&#x2019;s happening and hold these people accountable in the way you would be held accountable at your job.&#xA0;</p><p>Your job is not to report &#x201C;the facts&#x201D; and let the readers work it out. To quote my buddy Kasey, if you&apos;re not reporting the context, you&apos;re not reporting the story. Facts without context aren&#x2019;t really facts. Blandly repeating what an executive or politician says and thinking that appending it with &#x201C;...said [person]&#x201D; is sufficient to communicate their biases or intentions isn&#x2019;t just <em>irresponsible, </em>it&#x2019;s actively rejecting your position as a journalist.</p><p>You don&#x2019;t even have to say somebody is lying when they say they&#x2019;re going to do something &#x2014; but the word &#x201C;allegedly&#x201D; is powerful, reasonable and honest, and is an objective way of calling into question a narrative.&#xA0;</p><p>Let me give you a few examples.</p><p>A few weeks ago, multiple outlets reported that Meta would partner with Anduril, the military contractor founded by Palmer Luckey, the former founder of VR company Oculus which<a href="https://about.fb.com/news/2014/03/facebook-to-acquire-oculus/?ref=wheresyoured.at"><u>Meta acquired in 2014</u></a>, only to <a href="https://www.wsj.com/articles/why-did-facebook-fire-a-top-executive-hint-it-had-something-to-do-with-trump-1541965245?ref=wheresyoured.at"><u>oust Luckey four years later for donating $10,000 to an anti-Hilary Clinton group</u></a>. In 2024, Meta CTO Andrew &#x201C;Boz&#x201D; Bosworth, famous for saying that Facebook&#x2019;s growth is necessary and good, even if it leads to bad things like cyberbullying and&#xA0; terror attacks, <a href="https://www.roadtovr.com/metas-apologizes-oculus-founder-palmer-luckey-ousting/?ref=wheresyoured.at"><u>publicly apologized to Luckey</u></a>.&#xA0;</p><p>Now the circle is completing, with <a href="http://www.businessinsider.com/zuckerberg-luckey-end-feud-develop-ai-powered-military-tech-2025-5?ref=wheresyoured.at"><u>Luckey sort-of-returning to Meta to work with the company</u></a> on some sort of helmet called &#x201C;Eagle Eye.&#x201D;&#xA0;</p><p>One might think at this point the media would be a little more hesitant in how they cover anything Zuckerberg-related after he completely lied to them about the metaverse, and one would be wrong.</p><p><a href="https://www.washingtonpost.com/technology/2025/05/29/meta-us-military-technology-defense-contract/?ref=wheresyoured.at"><u>The Washington Post reported</u></a> that, and I quote:</p><p><em>To aid the collaboration, Meta will draw on its hefty investments in AI models known as Llama and its virtual reality division, Reality Labs. The company has built several iterations of immersive headsets aimed at blending the physical and virtual worlds &#x2014; a concept known as the metaverse.</em></p><p>Are you <em>fucking kidding me?</em></p><p>The metaverse was a joke! It never existed! Meta bought a company that made VR headsets &#x2014; a technology so old, they <a href="https://www.youtube.com/watch?v=Ur-5WCtSl10&amp;ref=wheresyoured.at"><u>featured in an episode of <em>Murder She Wrote</em></u></a> &#x2014; and an online game that could best be described as &#x201C;Second Life, but sadder.&#x201D; <a href="https://www.washingtonpost.com/technology/2021/12/30/metaverse-definition-facebook-horizon-worlds/?ref=wheresyoured.at"><u>Here&#x2019;s a piece from the Washington Post agreeing with me</u></a>! The metaverse never really had a product of any kind, and <a href="https://www.cnbc.com/2025/01/29/metas-reality-labs-posts-5-billion-loss-in-fourth-quarter.html?ref=wheresyoured.at"><u>lost tens of billions of dollars for no reason</u></a>! <a href="https://www.businessinsider.com/metaverse-dead-obituary-facebook-mark-zuckerberg-tech-fad-ai-chatgpt-2023-5?ref=wheresyoured.at"><u>Here&#x2019;s a whole thing I wrote about it years ago</u></a>! To still bring up the metaverse in the year of our lord 2025 is ridiculous!</p><p>But even putting that aside&#x2026; wait, Meta&#x2019;s going to put <em>its </em>AI <em>inside</em> of this headset? Palmer Luckey claims that, according to the Post, this headset will be &#x201C;combining an AI assistant with communications and other functions.&#x201D; Llama? That assistant?&#xA0;</p><p><a href="http://gizmodo.com/meta-cheated-on-ai-benchmarks-and-its-a-glimpse-into-a-new-golden-age-2000586433?ref=wheresyoured.at"><u>You mean the one that it had to rig to cheat on LLM benchmarking tests</u></a>? The one that will, as reported by the Wall Street Journal, <a href="https://www.wsj.com/tech/ai/meta-ai-chatbots-sex-a25311bf?ref=wheresyoured.at"><u>participate in vivid and gratuitous sexual fantasies <em>with children</em></u></a>? The one using generative AI models that hallucinate, like every other LLM? That&#x2019;s the one that you&#x2019;re gonna put in the helmet for the military? How is the helmet going to do that exactly? What will an LLM &#x2014; an inconsistent and unreliable generative AI system &#x2014; do in a combat situation, and will a soldier trust it again after its first fuckup?</p><p>Just to be clear, and I quote Palmer Luckey, the helmet that will feature an &#x201C;ever-present companion who can operate systems, who can communicate with others, who you can off-load tasks onto &#x2026; that is looking out for you with more eyes than you could ever look out for yourself right there right there in your helmet.&#x201D; <strong>This is all going to be powered by Llama?&#xA0;</strong></p><p><strong>Really? <em>Are we all really going to accept that? Does nobody actually think about the words they&#x2019;re writing down?</em></strong></p><p>Here&#x2019;s the thing about military tech: the US DOD tends to be fairly conservative when it comes to the software it uses, and has high requirements for reliability and safety. I could talk about these for hours &#x2014; from coding guidelines, to the ADA programming language, which was designed to be highly crash-resistant and powers everything from guided missiles to F-15 fighter jet &#x2014; but suffice it to say that it&#x2019;s highly doubtful that the military is going to rely on an LLM that hallucinates a significant portion of the time.&#xA0;</p><p>To be clear, I&#x2019;m not saying we have to reject every single announcement that comes along, but can we just <em>for one second</em> think <em>critically</em> about what it is we are <em>writing down.</em></p><p>We do not have to buy into every narrative, nor do we have to report it as if we do so. We do not have to accept anything based on the fact someone says it emphatically, or because they throw a number at us to make it sound respectable.&#xA0;</p><p>Here&#x2019;s another example. A few weeks ago, <a href="http://www.axios.com/2025/05/28/ai-jobs-white-collar-unemployment-anthropic?ref=wheresyoured.at"><u>Axios had a miniature shitfit</u></a> after Anthropic CEO said that &#x201C;AI could wipe out half of all entry-level white-collar jobs and spike unemployment to 10-20% in the next one to five years.&#x201D;&#xA0;</p><p>What data did Mr. Amodei use to make this point? Who knows! Axios simply accepted that he said something and wrote it down, because why <em>think</em> when you could <em>write.</em></p><p>This is extremely stupid! This is so unbelievably stupid that it makes me question the intelligence of literally anybody that quotes it! Dario Amodei provided <em>no</em> sourcing, <em>no</em> data, <em>nothing</em> other than a vibes-based fib specifically engineered to alarm hapless journalists. Amodei hasn&#x2019;t done any kind of study or research. He&#x2019;s just saying stuff, and that&#x2019;s all it takes to get a headline when you&#x2019;re the CEO of one of the top two big AI companies.</p><p>It is, by the way, easy to cover this ethically, <a href="https://www.cnn.com/2025/05/30/business/anthropic-amodei-ai-jobs-nightcap?ref=wheresyoured.at"><u>as proven by Allison Morrow of CNN</u></a>, who, engaging her critical thinking, correctly stated that &#x201C;Amodei didn&#x2019;t cite any research or evidence for that 50% estimate,&#x201D; that &#x201C;Amodei is a salesman, and it&#x2019;s in his interest to make his product appear inevitable and so powerful it&#x2019;s scary,&#x201D; and that &#x201C;little of what Amodei told Axios was new, but it was calibrated to sound just outrageous enough to draw attention to Anthropic&#x2019;s work.&#x201D;</p><p>Morrow&#x2019;s work is compelling because it&#x2019;s sincere, and is proof that there is absolutely nothing stopping mainstream press from covering this industry honestly. Instead, <a href="https://www.businessinsider.com/anthropic-ceo-warning-ai-could-eliminate-jobs-2025-5?ref=wheresyoured.at"><u>Business Insider</u></a> (which just laid off a ton of people and <a href="https://www.semafor.com/article/06/01/2025/business-insider-recommended-nonexistent-books-to-staff-as-it-leans-into-ai?ref=wheresyoured.at"><u>lazily recommended their workers read books that don&#x2019;t exist because they can&#x2019;t even write their own emails without AI</u></a>), <a href="https://fortune.com/2025/05/28/anthropic-ceo-warning-ai-job-loss/?ref=wheresyoured.at"><u>Fortune</u></a>, <a href="https://in.mashable.com/tech/94886/anthropic-ceo-claims-ai-will-wipe-out-50-of-entry-level-white-collar-jobs-soon-mark-cuban-disagrees?ref=wheresyoured.at"><u>Mashable</u></a> and many other outlets blandly covered a man&#x2019;s completely made up figure as if it was fact.&#xA0;</p><p>This <strong>isn&#x2019;t a story.</strong> It is &#x201C;guy said thing,&#x201D; and &#x201C;guy&#x201D; happens to be &#x201C;billionaire behind multi-billion dollar Large Language Model company,&#x201D; and said company has made exactly jack shit as far as software that can actually replace workers.&#xA0;</p><p>While there are absolutely <em>some</em> jobs being taken by AI, there is, to this point, little or no research that suggests that it&#x2019;s happening at scale, mostly because <em>Large Language Models don&#x2019;t really do the things that you need them to do to take someone&#x2019;s job at scale.</em> Nor is it clear that those jobs were lost because AI &#x2014; specifically genAI &#x2014; can actually do them as well, or better, than a person, or because an imbecile CEO bought into the hype and decided to fire up the pink slip printer, and when those LLMs inevitably shit the bed, those people will be hired back.&#xA0;</p><p>You know, like <a href="https://www.ibtimes.co.uk/klarna-slashed-40-its-staff-ai-now-theyre-scrambling-rehire-humans-after-customer-backlash-1734771?ref=wheresyoured.at"><u>Klarna</u></a> literally just had to.&#xA0;</p><p>These scare tactics exist to do one thing: increase the value of companies like Anthropic, OpenAI, Microsoft, Salesforce, and anybody else outright lying about how &#x201C;agents&#x201D; will do our jobs, and to make it easier for the startups making these models to raise funds, kind-of how a pump-and-dump scammer will hype up a doomed penny stock by saying how it&#x2019;s going to the moon, not disclosing that they themselves own a stake in the business.</p><p>Let&#x2019;s look at another example. A <a href="https://www.oxfordeconomics.com/resource/educated-but-unemployed-a-rising-reality-for-us-college-grads/?ref=wheresyoured.at"><u>recent report</u></a> from Oxford Economics talked about how entry-level workers were facing a job crisis, and vaguely mentioned <em>in the preview of the report </em>that &#x201C;there are signs that entry-level positions are being displaced by artificial intelligence at higher rates.&#x201D;&#xA0;</p><p>One might think the report says much more than that, and one would be wrong. On the very first page, it says that &#x201C;there are signs that entry-level positions are being displaced by artificial intelligence at higher rates.&#x201D; On page 3, it claims that the &#x201C;high adoption rate by information companies along with the sheer employment declines in [some roles] since 2022 suggested some displacement effect from AI&#x2026;[and] digging deeper, the largest displacement seems to be entry-level jobs normally filled by recent graduates.&#x201D;&#xA0;</p><p><strong><em><u>In fact, fuck it, take a look.</u></em></strong></p><figure class="kg-card kg-image-card"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXeFId7Pw-eshuxlEIyD0KVDIViOSEbDJ-5KT1nCz56t9JrCqWftcf9ilZFtD2vxY7J5l3rus7G8pkSpnjBUo81QAznkkoban6Lx1XcclaWgA5dlso9TZOF3iYWy_rxHg2-KTaoV2Q?key=S-RwnAa_YEk3wulbsqjzcg" class="kg-image" alt loading="lazy" width="624" height="483"></figure><p>That&#x2019;s it! That&#x2019;s the entire extent of its proof! <strong>The argument is that because companies are getting AI software and there&#x2019;s employment declines, it must be AI.</strong> There you go! Case closed.&#xA0;</p><p>This report has now been quoted as gospel. <a href="https://www.axios.com/2025/05/29/ai-college-grads-work-jobs?ref=wheresyoured.at"><u>Axios claimed that Oxford Economics&#x2019; report provided &#x201C;hard evidence&#x201D; that &#x201C;AI is displacing white-collar workers.&#x201D;</u></a><a href="https://www.usatoday.com/story/graphics/2025/05/29/job-market-2025-college-graduates/83884373007/?ref=wheresyoured.at"><u>USA Today said that positions in computer and mathematical sciences have been the first affected as companies increasingly adopt artificial intelligence systems</u></a>.&#x201D;</p><p>And <a href="https://www.nytimes.com/2025/05/30/technology/ai-jobs-college-graduates.html?ref=wheresyoured.at"><u>Anthropic marketing intern/New York Times columnist Kevin Roose</u></a> claimed that this was only the tip of the iceberg, because, and I shit you not, he had talked to some guys who said some stuff.</p><p>No, really.</p><blockquote><em>In interview after interview, I&#x2019;m hearing that firms are making rapid progress toward automating entry-level work, and that A.I. companies are racing to build &#x201C;virtual workers&#x201D; that can replace junior employees at a fraction of the cost. Corporate attitudes toward automation are changing, too &#x2014; some firms have encouraged managers to become &#x201C;A.I.-first,&#x201D; testing whether a given task can be done by A.I. before hiring a human to do it.<br><br>One tech executive recently told me his company had stopped hiring anything below an L5 software engineer &#x2014; a midlevel title typically given to programmers with three to seven years of experience &#x2014; because lower-level tasks could now be done by A.I. coding tools. Another told me that his start-up now employed a single data scientist to do the kinds of tasks that required a team of 75 people at his previous company.</em></blockquote><p>Yet Roose&#x2019;s most egregious bullshit came after he admitted that these don&#x2019;t prove anything:</p><blockquote><em>Anecdotes like these don&#x2019;t add up to mass joblessness, of course. Most economists believe there are multiple factors behind the rise in unemployment for college graduates, including a hiring slowdown by big tech companies and broader uncertainty about President Trump&#x2019;s economic policies.<br><br>But among people who pay close attention to what&#x2019;s happening in A.I., alarms are starting to go off.</em></blockquote><p>That&#x2019;s right, anecdotes don&#x2019;t prove his point, but what if <em>other</em> anecdotes proved his point? Because Roose goes on to quote Amodei&#x2019;s 50% quote, and say that they now claim its Claude Opus 4 model can &#x201C;code for several hours without stopping,&#x201D; a statement that Roose calls &#x201C;a tantalizing possibility if you&#x2019;re a company accustomed to paying six-figure engineer salaries for that kind of productivity&#x201D; without thinking &#x201C;does that mean the code is good?&#x201D; or &#x201C;what does it do for those hours?&#x201D;</p><p>Roose spends the rest of the article clearing his throat, adding that &#x201C;even if AI doesn&#x2019;t take all entry-level jobs right away&#x201D; that &#x201C;two trends concern [him],&#x201D; namely that he worries companies are &#x201C;turning to AI too early, before the tools are robust enough to handle full entry-level workloads,&#x201D; and that executives believing that entry-level jobs are short-lived will &#x201C;underinvest in job training, mentorship and other programs aimed at entry-level workers.&#x201D;&#xA0;</p><p>Kevin, have you ever considered checking <a href="https://www.wheresyoured.at/the-myth-of-mentorship-and-how-weve/"><u>whether that actually happens</u></a>?</p><p>Nah! Why would he? Kevin&#x2019;s job is to be a greasy pawn of the AI industry and the markets at large. An interesting &#x2014; and sincere! &#x2014; version of this piece would&#x2019;ve intelligently humoured the idea then attempted to actually prove it, and then failed because there is no proof that this is actually happening other than that which the media drums up.</p><p>It&#x2019;s the same craven, insincere crap we saw with the return to office &#x201C;debate&#x201D; which was far more about bosses pretending that the office was good than it was about productivity or any kind of work. <a href="https://www.wheresyoured.at/privilege-and-pro-office-pablum/"><u>I wrote about this almost every week for several years</u></a>, and every single media outlet participated, on some level, in pushing a completely fictitious world where in-office work was &#x201C;better&#x201D; due to &#x2018;serendipity,&#x201D; that the boss was right, and that we all had to come back to the office.&#xA0;</p><p>Did they check with the boss about how often they were in the office? Nope! Did they give equal weight to those who disagreed with management &#x2014; namely those doing the actual work? No. But they did <a href="https://www.wheresyoured.at/quiet-quitting-is-hustle-cultures/"><u>get really concerned about quiet quitting for some reason</u></a>, even though it wasn&#x2019;t real, because the bosses that don&#x2019;t seem to actually do any work had demanded that it was.</p><blockquote>Anyway, <a href="https://www.nytimes.com/2020/03/10/technology/working-from-home.html?ref=wheresyoured.at"><u>Kevin Roose was super ahead of the curve on that one</u></a>. He wrote that &#x201C;working from home is overrated&#x201D; and that &#x201C;home-cooked lunches and no commuting&#x2026;can&#x2019;t compensate for what&#x2019;s lost in creativity&#x201D; in <em>March, 2020.</em> My favourite quote is when he says &#x201C;...research also shows that what remote workers gain in productivity, they often miss in harder-to-measure benefits like creativity and innovative thinking,&#x201D; before mentioning some studies about &#x201C;team cohesion,&#x201D;<a href="https://www.theatlantic.com/magazine/archive/2017/11/when-working-from-home-doesnt-work/540660/?ref=wheresyoured.at"><u> linking to an article from The Atlantic from 2017</u></a> that does not appear to include a study other than the Nicholas Bloom study that Roose himself linked that showed remote work was productive and another about &#x201C;proximity boosting productivity&#x201D; that it does not link to, adding that &#x201C;the data tend to talk past each other.&#x201D;<br><br>I swear to god I am not trying to personally vilify Kevin Roose &#x2014; it&#x2019;s just that he appears to have backed up every single boss-coddling market-driven hype cycle with a big smile, every single time. If he starts writing about Quantum Computing, it&#x2019;s tits up for AI.</blockquote><p>This is the same thing that happened when corporations were raising prices and <a href="https://www.npr.org/2022/11/29/1139342874/corporate-greed-and-the-inflation-mystery?ref=wheresyoured.at"><u>the media steadfastly claimed</u></a><a href="https://www.cnn.com/2024/05/15/business/inflation-biden-rate-fed/index.html?ref=wheresyoured.at"><u>that inflation had nothing to do with corporate greed</u></a> (once again, CNN&#x2019;s Allison Morrow was one of the few mainstream media reporters willing to just say &#x201C;<a href="https://www.cnn.com/2023/03/08/business/nightcap-food-inflation/index.html?ref=wheresyoured.at"><u>yeah corporations actually are raising prices and blaming it on inflation</u></a>&#x201D;), <a href="https://finance.yahoo.com/news/evidence-of-food-price-gouging-is-hard-to-find-181613112.html?guccounter=1&amp;ref=wheresyoured.at"><u>desperately clinging to whatever flimsy data might prove that corporations weren&#x2019;t price gouging</u></a><a href="https://apnews.com/article/pepsi-earnings-prices-6a625f7e61425028975c94dff98a5f2e?ref=wheresyoured.at"><u>even as corporations talked about doing so publicly</u></a>.</p><p>It&#x2019;s all so deeply insincere, and all so deeply ugly &#x2014; a view from nowhere, one that seeks not to tell anyone anything other than that whatever the rich or powerful is worried or excited about is true, and that the evidence, no matter how flimsy, always points in the way they want it to.&#xA0;</p><p>It&#x2019;s lazy, brainless, and suggests either a complete rot in the top of editorial across the entire&#xA0; business and tech media or a consistent failure by writers to do basic journalism, and as forgiving I want to be, there are enough of these egregious issues that I have to begin asking if anybody is actually fucking <em>trying</em>.&#xA0;</p><p>It&#x2019;s the same thing every time the powerful have an idea &#x2014; <a href="https://www.wheresyoured.at/the-upcoming-remote-work-company/"><u>remote work is bad for companies and we must return to the office</u></a>, <a href="https://www.wheresyoured.at/the-malevolence-of-the-metaverse/"><u>the metaverse is here</u></a> and <a href="https://www.wheresyoured.at/i-dont-want-to-go-to-work-in-the/"><u>we&#x2019;re all gonna work in it</u></a>, <a href="https://www.wheresyoured.at/lost-in-the-future/#:~:text=Case%20in%20point,that%20it%20was."><u>prices are higher and it&#x2019;s due to inflation rather than anything else</u></a>, <a href="https://www.wheresyoured.at/wheres-the-money/"><u>AI is so powerful and strong and will take all of our jobs</u></a>, or whatever it is &#x2014; and that idea immediately become the media&#x2019;s talking points. Real people in the real world, experiencing a different reality, watch as the media repeatedly tells them that their own experiences are wrong. Companies can raise their prices specifically to raise their profits, <a href="https://www.scmp.com/comment/opinion/article/3211121/metaverse-has-failed-it-never-even-took?ref=wheresyoured.at"><u>Meta can literally not make a metaverse</u></a>, <a href="https://fortune.com/2025/05/18/ai-chatbots-study-impact-earnings-hours-worked-any-occupation/?ref=wheresyoured.at"><u>AI can do very little to actually automate your real job</u></a>, and the <a href="https://www.nytimes.com/2020/03/10/technology/working-from-home.html?ref=wheresyoured.at"><u>media</u></a><a href="https://www.coindesk.com/podcasts/coindesks-money-reimagined/media-in-the-metaverse-nyts-kevin-roose-on-the-future-of-crypto?ref=wheresyoured.at"><u>will</u></a><a href="https://www.nytimes.com/2022/02/06/technology/helium-cryptocurrency-uses.html?ref=wheresyoured.at"><u>still</u></a><a href="https://www.msnbc.com/msnbc-podcast/demystifying-nfts-kevin-roose-n1286481?ref=wheresyoured.at"><u>tell</u></a><a href="https://www.nytimes.com/2025/03/14/technology/why-im-feeling-the-agi.html?ref=wheresyoured.at"><u>you</u></a> to shut the fuck up and eat their truth-slop.</p><p>You want an <em>actual</em> conspiracy theory? How about a real one: that the media works together with the rich and powerful to directly craft &#x201C;the truth,&#x201D; even if it runs contrary to reality. The Business Idiots that rule our economy &#x2014; <a href="https://www.wheresyoured.at/the-era-of-the-business-idiot/"><u>work-shy executives and investors with no real connection to any kind of actual production</u></a> &#x2014; are the true architects of what&#x2019;s &#x201C;real&#x201D; in our world, and their demands are simple: &#x201C;make the news read like we want it to.&#x201D;</p><p>Yet when I say &#x201C;works together,&#x201D; I don&#x2019;t even mean that they get together in a big room and agree on what&#x2019;s going to be said. Editors &#x2014; and writers &#x2014; eagerly await the chance to write something following a trend or a concept that their bosses (or other writers&#x2019; bosses) come up with and are ready to go. I don&#x2019;t want to pillory too many people here, but go and look at who covered the metaverse, cryptocurrency, remote work, NFTs and now generative AI in gushing terms. </p><p>Okay, but seriously, how is it every time with <a href="https://www.theverge.com/2022/1/28/22906010/web3-nft-internet-history-video-platformer?ref=wheresyoured.at"><u>Casey</u></a> and <a href="https://www.nytimes.com/2021/08/12/technology/penguin-nft-club.html?ref=wheresyoured.at"><u>Kevin</u></a>?&#xA0;</p><p>The illuminati doesn&#x2019;t need to exist. We don&#x2019;t need to talk about the Bilderberg Group, or Skull and Bones, or reptilians, or <a href="https://www.youtube.com/watch?v=NapHiWsoFXI&amp;ref=wheresyoured.at"><u>wheel out David Icke and his turquoise shellsuit</u></a>. The media has become more than willing to follow whatever it needs to once everybody agrees on the latest fad or campaign, to the point that they&#x2019;ll repeat nonsensical claim after nonsensical claim.</p><p>The cycle repeats because our society &#x2014; and yes, our editorial class too &#x2014; is controlled by people who don&#x2019;t actually interact with it. They have beliefs that they want affirmed, ideas that they want spread, and they don&#x2019;t even need to work that hard to do so, because the editorial rails are already in place to accept whatever the next big idea is. They&#x2019;ve created editorial class structures to make sure writers will <em>only</em> write what&#x2019;s assigned, pushing back on anything that steps too far out of everybody&#x2019;s agreed-upon comfort zone.</p><p>The &#x201C;AI is going to eliminate half of white collar jobs&#x201D; story is one that&#x2019;s taken hold because it gets clicks and appeals to a fear that everyone, particularly those in the knowledge economy who have long enjoyed protection from automation, has. Nobody wants to be destitute. Nobody with six figures of college debt wants to be stood in a dole queue.&#xA0;&#xA0;</p><p>It&#x2019;s a sexy headline, one that scares the reader into clicking, and when you&#x2019;re doing a half-assed job at covering a study, you can very easily just say &#x201C;there&#x2019;s evidence this is happening.&#x201D; It&#x2019;s scary. People are scared, and want to know more about the scary subject, so reporters keep covering it again and again, repeating a blatant lie sourced using flimsy data, pandering to those fears rather than addressing them with reality.</p><p>It feels like the easiest way to push back on these stories is fairly simple: ask reporters to show the companies that have actually done this.</p><p>No, I don&#x2019;t mean &#x201C;show me a company that did layoffs and claims they&#x2019;re bringing in new efficiencies with AI.&#x201D; I mean actually show me a company that has laid off, say, 10 people, and how those people have been replaced by AI. What does the AI do? How does it work? How do you quantify the work it&#x2019;s replaced? How does it compare in quality? Surely with <em>all these headlines</em> there&#x2019;s got to be <em>one company</em> that can show you, right?</p><p>No, no, I really don&#x2019;t mean &#x201C;we&#x2019;re saying this is the reason,&#x201D; I mean show me the actual job replacement happening and how it works. We&#x2019;re three years in and we&#x2019;ve got headlines talking about AI replacing jobs. Where? Christopher Mims of the Wall Street Journal <a href="https://www.wsj.com/tech/ai/ai-replace-freelance-jobs-51807bc7?gaa_at=eafs&amp;gaa_n=ASWzDAhPFILp_QJdg8e2HySCu7FREZp9Bn-xM1Z5pDPehUUQXknA9YBWCjlFR8FUZzk%3D&amp;gaa_ts=683f2b5e&amp;gaa_sig=8UjKXTFLwc_3cMuk0T9YLFTJEM53Ky5N68NOpzV6nlUdBlWX0ueDWFgUjkhrIWDh0FUgp0L-PDdQ6tZz1Bo_jA%3D%3D&amp;ref=wheresyoured.at"><u>had a story from June 2024</u></a> that talked about freelance copy editors and concept artists being replaced by generative AI, but I can find no stories about <em>companies replacing employees.&#xA0;</em></p><p>To be clear, I am not advocating for this to happen. I am simply asking that the media, which seems obsessed with &#x2014; even <em>excited by</em> &#x2014; the prospect of imminent large-scale job loss, goes out and finds a <em>business</em> (not a freelancer who has lost work, not a company that has laid people off with a statement about AI) that has <em>replaced workers with generative AI.</em>&#xA0;</p><p>They can&#x2019;t, because it isn&#x2019;t happening at scale, <strong><em>because generative AI does not have the capabilities that people like Dario Amodei and Sam Altman repeatedly act like they do, yet the media continues to prop up the story because they don&#x2019;t have the basic fucking curiosity to learn about what they&#x2019;re talking about.</em></strong></p><p>Hell, I&#x2019;ll make it easier for you. Why don&#x2019;t you find me the product, the actual thing, that can do someone&#x2019;s job? Can you replace an accountant? No. A doctor? No. A writer? Not if you want good writing. An artist? Not if you want to actually copyright the artwork, and that&#x2019;s before you get to how weird and soulless the art itself feels. Walk into your place of work tomorrow and look around you and start telling me how you would replace each and every person in there <strong>with the technology that exists today, <u>not the imaginary stuff that Dario Amodei and Sam Altman want you to think about.</u></strong></p><p>Outside of coding &#x2014; which, by the way, <em>is not the majority of a software engineer&#x2019;s fucking job, if you&#x2019;d take the god damn time to actually talk to one! </em>&#x2014; what are the actual capabilities of a Large Language Model today? What can it actually do?&#xA0;</p><p>You&#x2019;re gonna say &#x201C;it can do deep research,&#x201D; <a href="https://www.wheresyoured.at/longcon/#:~:text=Wait!%20Wait!%20OpenAI%20released%20a%20new%20product!%20It%27s%20called%20Deep%20Research%2C%20which%20lets%20you%20ask%20ChatGPT%20to%20generate%20a%20report%20by%20browsing%20the%20web.%20This%20is%20almost%20a%20cool%20idea.%20I%20sure%20hope%20that%20it%20doesn%27t%20make%20glaring%20mistakes%20and%20cost%20a%20shit%2Dton%20of%20money!"><u>by which you mean a product that doesn&#x2019;t really work.</u></a> What else? Generate videos that sometimes look okay? &#x201C;Vibe code&#x201D;? Bet you&#x2019;re gonna say something about AI being used in the sciences to &#x201C;discover new materials&#x201D; which proved AI&#x2019;s productivity benefits. Well, <a href="https://gizmodo.com/mit-backs-away-from-paper-claiming-scientists-make-more-discoveries-with-ai-2000603790?ref=wheresyoured.at"><u>MIT announced that it has &#x201C;no confidence in the provenance, reliability or validity of the data, and [has] no confidence in the validity of the research contained in the paper.&#x201D;</u></a>&#xA0;</p><p>I&#x2019;m not even being facetious: show me something! Show me something that actually matters. Show me the thing that will replace white collar workers &#x2014; or even, honestly, &#x201C;reduce the need for them.&#x201D; Find me someone who said &#x201C;with a tool like this I won&#x2019;t need this many people&#x201D; who actually fired them and then replaced them with the tool and the business keeps functioning. Then find me two or three more. Actually, make it ten, because this is apparently replacing half the white collar workforce.</p><p>There are some answers, by the way. Generative AI has sped up transcription and translation, which are useful for quick references but <a href="https://perkinscoie.com/insights/update/rise-popularity-ai-transcription-services-brings-litigation-and-disclosure-risks?ref=wheresyoured.at"><u>can cause genuine legal risk</u></a>. Generative AI-based video editing tools are gaining in popularity, though it&#x2019;s unclear by how much. Seemingly every app that connects to generative AI can summarise a message. Software engineers using LLM tools &#x2014; <a href="https://www.iheart.com/podcast/1119-better-offline-150284547/episode/the-truth-about-software-development-with-279034504/?ref=wheresyoured.at"><u>as I talked about on a recent episode of Better Offline</u></a> &#x2014; are finding some advantages, but LLMs are far from a panacea. <a href="https://www.rollingstone.com/culture/culture-features/ai-spiritual-delusions-destroying-human-relationships-1235330175/?ref=wheresyoured.at"><u>Generative AI chatbots are driving people insane by providing them an endlessly-configurable pseudo-conversation</u></a> too, though that&#x2019;s less of a &#x201C;use case&#x201D; and more of a &#x201C;text-based video game launched at scale without anybody thinking about what might happen.&#x201D;&#xA0;</p><p>Let&#x2019;s be real: none of this is transformative. None of this is futuristic. It&#x2019;s stuff we already do, done faster, though &#x201C;faster&#x201D; doesn&#x2019;t mean better, or even that the task is done properly, and obviously, it doesn&#x2019;t mean removing the human from the picture. Generative AI is best at, it seems, doing very specific things in a very generic way, none of which are truly life-changing. Yet that&#x2019;s how the media discusses it.&#xA0;</p><blockquote><strong>An aside about software engineering</strong>: I actually believe LLMs have some value here. LLMs can generate outputs to generate and evaluate code, as well as handle distinct functions within a software engineering environment. It&#x2019;s pretty exciting for some software engineers - they&#x2019;re able to get a lot of things done much faster! - though they&#x2019;d never trust it with things launched in production. These LLMs also have &#x201C;agents&#x201D; - but for the sake of argument, I&#x2019;d like to call them &#x201C;bots.&#x201D; Bots, because the term &#x201C;agent&#x201D; is bullshit and used to make things sound like they can do more than they can. Anyway, bots can, to quote <a href="http://fly.io/blog/youre-all-nuts/?ref=wheresyoured.at"><u>Thomas Ptacek</u></a>, &#x201C;poke around your codebase on their own&#x2026;author files directly&#x2026;run tools&#x2026;compile code&#x2026;run tests&#x2026;and iterate on the results,&#x201D; to name a few things.&#x201D; These are all things - under the watchful eye of an actual person - that can speed up <em>some </em>software engineers&#x2019; work.&#xA0;<br><br>(<strong>A note from my editor, Matt Hughes, who has been a software engineer for a long time:</strong> I&#x2019;m not sure how persuasive this stuff is. Coders have been automating things like tests, code compilation, and the general mechanics of software engineering long before AI and LLMs were the hot thing du jour. You can do so many of the things that Ptacek mentioned with cronjobs and shell scripts &#x2014; and, undoubtedly, with greater consistency and reliability.)Ptacek also adds that &#x201C;if truly mediocre code is all we ever get from LLM, that&#x2019;s still huge, [as] it&#x2019;s that much less mediocre code humans have to write.&#x201D;&#xA0;&#xA0;<br><br><strong>Back to Ed: </strong>In a conversation with <a href="https://www.youtube.com/@InternetOfBugs?ref=wheresyoured.at"><u>The Internet of Bugs&#x2019; (and veteran software engineer) Carl Brown</u></a> as I was writing this newsletter, he recommended I exercise caution with how I discussed LLMs and software engineering, saying that &#x201C;...there are situations at the moment (unusual problems, or little-used programming languages or frameworks) where the stuff is absolutely useless, and is likely to be for a long time.&#x201D;In a previous draft, I&#x2019;d written that mediocre code was &#x201C;fine if you knew what to look for,&#x201D; but even then, Brown added that &#x201C;...the idea that a human can &#x2018;know what code is supposed to look like&#x2019; is truly problematic.&#xA0; A lot of programmers believe that they can spot bugs by visual inspection, but I know I can&apos;t, and I&apos;d bet large sums of money they can&apos;t either &#x2014; and I have a ton of evidence I would win that bet.&#x201D;<br><br>Brown continued: &#x201C;In an offline environment, mediocre code may be fine when you know what good code looks like, but if the code might be exposed to hackers, or you don&apos;t know what to look for, you&apos;re gonna cause bugs, and there are more bugs than ever in today&apos;s software, and that is making everyone on the Internet less secure.&#x201D;<br><br>He also told me the story of <a href="https://www.heartbleed.com/?ref=wheresyoured.at"><u>the famed Heartbleed bug</u></a>, a massive vulnerability in a common encryption library that millions of smart, professional security experts and developers looked at for over two years before someone saw a single error &#x2014; one single statement &#x2014; that somebody didn&#x2019;t check that led to a massive, internet-wide panic leaving hundreds of millions of websites vulnerable.<br><br>So, yeah, I dunno man. On one hand, there are clearly software developers that benefit from using LLMs, but it&#x2019;s complicated, much like software engineering itself. You cannot just &#x201C;replace a coder,&#x201D; because &#x201C;coder&#x201D; isn&#x2019;t really the job, and while this might affect entry-level software engineers <em>at some point</em>, there&#x2019;s yet to be proof it&#x2019;s actually happening, or that AI&#x2019;s taking these jobs and not, say, outsourcing. <br><br>Perhaps there&#x2019;s a simpler way to put it: software engineering is not just writing code, and if you think that&#x2019;s the case, you do not write software or talk to software engineers about what it is they do.&#xA0;</blockquote><p>Seriously, put aside the money, the hype, the pressure, the media campaigns, the emotions you have, everything, and just focus on <em>the product as it is today.</em> What is it that generative AI does, today, for you? Don&#x2019;t say &#x201C;AI could&#x201D; or &#x201C;AI will,&#x201D; tell me what &#x201C;AI does.&#x201D; Tell me what has changed about your life, your job, your friends&#x2019; jobs, or the world around you, other than that you heard a bunch of people got rich.</p><p><a href="https://www.androidpolice.com/google-ai-edge-gallery-experimental-appi/?ref=wheresyoured.at"><u>Yet</u></a><a href="https://www.nytimes.com/2025/05/05/technology/ai-hallucinations-chatgpt-google.html?ref=wheresyoured.at"><u>the</u></a><a href="https://www.engadget.com/ai/googles-most-powerful-ai-tools-arent-for-us-134657007.html?ref=wheresyoured.at"><u>media</u></a><a href="https://fortune.com/2025/05/22/anthropic-new-models-ai-openai-google/?ref=wheresyoured.at"><u>continually</u></a><a href="https://www.cnbc.com/2025/05/22/claude-4-opus-sonnet-anthropic.html?ref=wheresyoured.at"><u>calls</u></a><a href="https://www.bloomberg.com/news/articles/2025-05-22/ai-startup-anthropic-releases-more-powerful-opus-model-after-delay?ref=wheresyoured.at"><u>it</u></a> &#x201C;powerful AI.&#x201D; Powerful how? Explain the power! What is the power? The word &#x201C;powerful&#x201D; is a marketing term that the media has adopted to describe something it doesn&#x2019;t understand, along with the word &#x201C;agent,&#x201D; which <em>means</em> &#x201C;autonomous AI that can do things for you&#x201D; but is used, at this point, to describe any Large Language Model doing anything.&#xA0;</p><p>But the <em>intention</em> is to frame these models as &#x201C;powerful&#x201D; and to use the term &#x201C;agents&#x201D; to make this technology seem bigger than it is, and the people that control those terms are the AI companies themselves.</p><p>It&#x2019;s at best lazy and at worst actively deceitful, a failure of modern journalism to successfully describe the moment outside of what they&#x2019;re told to, or the &#x201C;industry standards&#x201D; they accept, such as &#x201C;a Large Language Model is powerful and whatever Anthropic or OpenAI tells me is true.&#x201D;</p><p>It&#x2019;s a disgrace, and I believe it either creates distrust in the media or drives people insane as they look at reality - where generative AI doesn&#x2019;t really seem to be doing much - and get told something entirely different by the media.</p><hr><p>When I read a lot of modern journalism, I genuinely wonder what it is the reporter wants to convey. A thought? A narrative? A story? Some sort of regurgitated version of &#x201C;the truth&#x201D; as justified by what everybody else is writing and how your editor feels, or what the markets are currently interested in? What is it that writers want readers to come away with, exactly?</p><p>It reminds me a lot of a term that Defector&#x2019;s David Roth once used to describe CNN&#x2019;s Chris Cilizza &#x2014; &#x201C;<a href="https://archive.is/M9Hmr?ref=wheresyoured.at"><u>politics, noticed</u></a>&#x201D;:</p><blockquote><em>This feels, from one frothy burble to the next, like a very specific type of fashion writing, not of the kind that an astute critic or academic or even competent industry-facing journalist might write, but of the kind that you find on social media in the threaded comments attached to photos of Rihanna. Cillizza does not really appear to follow any policy issue at all, and evinces no real insight into electoral trends or political tactics. He just sort of notices whatever is happening and cheerfully announces that it is very exciting and that he is here for it. The slugline for his blog at CNN&#x2014;it is, in a typical moment of uncanny poker-faced maybe-trolling, called The Point&#x2014;is &#x201C;Politics, Explained.&#x201D; That is definitely not accurate, but it does look better than the more accurate &#x201C;Politics, Noticed.&#x201D;</em></blockquote><p>Whether Roth would agree or not, I believe that this paragraph applies to a great deal of modern journalism. <em>Oh! Anthropic launched a new model! Delightful. What does it do? Oh they told me, great, I can write it down. It&#x2019;s even better at coding now! Wow! Also, Anthropic&#x2019;s CEO said something, which I will also write down. The end!</em></p><p>I&#x2019;ll be blunt: making no attempt to give actual context or scale or consideration to the larger meaning of the things said makes the purpose of journalism moot. Business and tech journalism has become &#x201C;technology, noticed.&#x201D; While there are forays out of this cul-de-sac of credulity &#x2014; and exceptions at many mainstream outlets &#x2014; there are so many more people who will simply hear that there&#x2019;s a guy who said a thing, and that guy is rich and runs a company people respect, and thus that statement is now news to be reported without commentary or consideration.</p><p>Much of this can be blamed on the editorial upper crust that continually refuses to let writers critique their subject matter, and wants to &#x201C;play it safe&#x201D; by basically doing what everybody else does. What&#x2019;s crazy to me is that many of the problems with the AI bubble &#x2014; as with the metaverse, as with the return to office, as with inflation and price gouging &#x2014; are obvious if you actually use the things or participate in reality, but such things do not always fit with the editorial message.</p><p>But honestly, there are plenty of writers who just don&#x2019;t give a shit. They don&#x2019;t really care to find out what AI can (or can&#x2019;t) do. They&#x2019;ve come to their conclusion (it&#x2019;s powerful, inevitable, and already doing amazing things) and thus will write from that perspective. It&#x2019;s actually pretty nefarious to continually refer to this stuff as &#x201C;powerful,&#x201D; because you <em>know</em> their public justification is how this stuff uses a bunch of GPUs, and you <em>know</em> their private justification is that they <em>have never checked and don&#x2019;t really care to.</em> It&#x2019;s much easier to follow the pack, because everybody &#x201C;needs to cover AI&#x201D; and AI stories, I assume, get clicks.</p><p>That, and their bosses, who don&#x2019;t really know anything other than that &#x201C;AI will be big,&#x201D; don&#x2019;t want to see anything else. Why argue with the powerful? They have all the money.</p><p>But even then&#x2026;can you try using it? Or talking to people that use it? Not &#x201C;AI experts&#x201D; or &#x201C;AI scientists,&#x201D; but real people in the real world? Talk to some of those software engineers! Or I dunno, <em>learn about LLMs yourself and try them out?</em>&#xA0;</p><p>Ultimately, a business or tech reporter should ask themselves: what is your job? Who do you serve? It&#x2019;s perfectly fine to write relatively straightforward and positive stuff, but you have to be clear that that&#x2019;s what you&#x2019;re doing and why you&#x2019;re doing it.&#xA0;</p><p>And you know what, if all you want to do is report what a company does, fine! I have no problem with that, but at least report it truthfully. <a href="https://www.nytimes.com/2025/05/30/technology/ai-jobs-college-graduates.html?ref=wheresyoured.at"><u>If you&#x2019;re going to do an opinion piece suggesting that AI will take our jobs</u></a>, at least live in reality, and put even the smallest amount of thought into what you&#x2019;re saying and what it actually means.&#xA0;</p><p>This isn&#x2019;t even about opinion or ideology, this is basic fucking work.&#xA0;</p><p>And it is fundamentally insincere. Is any of this what you truly believe? Do you know what you believe? I don&#x2019;t mean this as a judgment or an attack &#x2014; many people go through their whole lives with relatively flimsy reasons for the things they believe, especially in the case of commonly-held beliefs like &#x201C;AI is going to be big&#x201D; or &#x201C;Meta is a successful company.&#x201D;&#xA0;</p><p>If I&#x2019;m honest, I really don&#x2019;t mind if you don&#x2019;t agree with something I say, as long as you have a fundamentally-sound reason for doing so. <a href="https://www.wheresyoured.at/core-incompetency/"><u>My CoreWeave analysis</u></a> may seem silly to some because its value has quadrupled &#x2014; and that&#x2019;s why I didn&#x2019;t write that I believed the stock would crater, or really anything about the stock. Its success does not say much about the AI bubble other than it continues, and even if I am wrong, somehow, long term, at least I was wrong for reasons I could argue versus the general purpose sense that &#x201C;AI is the biggest thing ever.&#x201D;&#xA0;</p><p>I understand formats can be constraining &#x2014; many outlets demand an objective tone &#x2014; but this is where words like &#x201C;allegedly&#x201D; come in. For example, The Wall Street Journal recently said that <a href="https://www.wsj.com/tech/ai/what-sam-altman-told-openai-about-the-secret-device-hes-making-with-jony-ive-f1384005?ref=wheresyoured.at"><u>Sam Altman had claimed, in a leaked recording, that buying Jony Ive&#x2019;s pre-product hardware startup would add &#x201C;$1 trillion in market value</u></a>&#x201D; to OpenAI. As it stands, a reader &#x2014; especially a <a href="https://www.wheresyoured.at/the-era-of-the-business-idiot/"><u>Business Idiot</u></a> &#x2014; could be forgiven for thinking that OpenAI was now worth, or could be worth, over a trillion dollars, which is an egregious editorial failure.</p><p>One could easily add that &#x201C;...to this date, there have been no consumer hardware launches at this scale outside of major manufacturers like Apple and Google, and these companies had significantly larger research and development budgets and already-existent infrastructure relationships that OpenAI lacks.&#x201D;</p><p>Nothing about what I just said is opinion. Nothing about what I just said is an attack, or a sleight, and if you think it&#x2019;s &#x201C;undermining&#x201D; the story, you yourself are not thinking objectively. These are all true statements, and are necessary to give the full context of the story.&#xA0;&#xA0;</p><p>That, to me, is sincerity. Constrained by an entirely objective format, a reporter makes the effort to get across the context in which a story is happening, rather than just reporting exactly the story and what the company has said about it. By not including the context, you are, on some level, not being objective: you are saying that everything that&#x2019;s happening here isn&#x2019;t just possible, but rational, despite the ridiculous nature of Altman&#x2019;s comment.&#xA0;</p><p>Note that these are subjective statements. They are also the implication of simply stating that Sam Altman believes acquiring Jony Ive&#x2019;s company will add $1 trillion dollars in value to OpenAI. By not saying how unlikely it is &#x2014; again, without even saying the word &#x201C;unlikely,&#x201D; but allowing the audience to come to that conclusion by having the whole story &#x2014; you give the audience the truth.</p><p>It really is that simple.</p><hr><p>The problem, ultimately, is that everybody is aware that they&#x2019;re being constantly conned, but they can&#x2019;t always see where and why. Their news oscillates from aggressively dogmatic to a kind of sludge-like objectivity, and oftentimes feels entirely disconnected from their own experiences other than in the most tangential sense, giving them the feeling that their actual lives don&#x2019;t really matter to the world at large.&#xA0;</p><p>On top of that, the basic experience of <a href="https://www.wheresyoured.at/never-forgive-them/"><u>interacting with technology</u></a>, <a href="https://www.wheresyoured.at/lost-in-the-future/"><u>if not the world at large</u></a>, kind of fucking sucks now. We go on Instagram or Facebook to see our friends and battle through a few ads and recommended content, we see things from days ago until we click stories, and we hammer past a few more ads to get a few glimpses of our friends. We log onto Microsoft Teams, it takes a few seconds to go through after each click, and then it asks why we&#x2019;re not logged in, a thing that we don&#x2019;t need to be able to do to make a video call.&#xA0;</p><p>Our email accounts are clogged with legal spam &#x2014; marketing missives, newsletters, summaries from news outlets, notifications from UPS that require us to log in, notifications that our data has been leaked, payment reminders, receipts, and even occasionally emails from real people. <a href="https://www.wheresyoured.at/the-men-who-killed-google/"><u>Google Search is broken</u></a>, but then again, so is searching on basically any platform, be it our emails, workspaces or social networks.&#xA0;</p><p>At scale, we as human beings are continually reminded that we do not matter, that any experiences of ours outside of what the news say makes us &#x201C;different&#x201D; or a &#x201C;cynic,&#x201D; that our pain points are only as relevant as those that match recent studies or reports, and that the people that actually matter are either the powerful or considered worthy of attention. News rarely feels like it appeals to the listener, reader or viewer, just an amorphous generalized &#x201C;thing&#x201D; of a person imagined in the mind of a Business Idiot. The news doesn&#x2019;t feel the need to explain why AI is powerful, just that it is, in the same way that &#x201C;we all knew&#x201D; that being back in the office was better, even if there were far more people who disagreed than didn&#x2019;t.</p><p>As a result of <em>all </em>of these things, people are desperate for sincerity. They&#x2019;re desperate to be talked to as human beings, their struggles validated, their pain points confronted and taken seriously. They&#x2019;re desperate to have things explained to them with clarity, and to have it done by somebody who doesn&#x2019;t feel chained by an outlet.&#xA0;</p><p>This is something that right wing media caught onto and exploited, leading to the rise of Donald Trump and the obsession with creating the &#x201C;Joe Rogan of the Left,&#x201D; an inherently ridiculous position based on his own popularity with young men (<a href="https://www.splinter.com/the-manosphere-is-not-popular-with-young-men-they-barely-know-who-they-are?ref=wheresyoured.at"><u>which is questionable based on recent reports</u></a>) and its total misunderstanding of what actually makes his kind of media popular.&#xA0;</p><p>However you may feel about Rogan, what his show <em>sells on</em> is that he&#x2019;s a kind of sincere, pliant and amicable oaf. He does not seem condescending or judgmental to his audience, because he himself sits, slack-jawed, saying &#x201C;yeah I knew a guy who did that&#x201D; and genuinely seems to like them. While you (as I do) may deeply dislike everything on that show, you can&#x2019;t deny that they seem to at least enjoy themselves, or feel engaged and accepted.&#xA0;</p><p>The same goes for Theo Von (real name: Theodor Capitani von Kurnatowski III, and <a href="https://en.wikipedia.org/wiki/Theo_Von?ref=wheresyoured.at#:~:text=Theodor%20Capitani%20von%20Kurnatowski%20III,stand%2Dup%20comedian%20and%20podcaster."><u>no, really!</u></a>), whose whole affable doofus motif disarms guests and listeners.&#xA0;</p><p>It works! And he&#x2019;s got a whole machine that supports him, just like Rogan, money, real promotion, and real production value. They are given the bankroll and the resources to make a high-end production and a studio space and infrastructural support and then they get a bunch of marketing and social push too. There&#x2019;s entire operations behind them, other than the literal stuff they do on the set, because, shocker, the audience actually wants to see them not have a boxed lunch with &#x201C;THE THINGS TO BELIEVE&#x201D; written on it by a management consultant.&#xA0;</p><p>This is in no way a political statement, because my answer to this entire vacuous debate is to &#x201C;give a diverse group of people that you agree with the beliefs of the actual promotional and financial backing and then let them create something with their honest-to-god friendships.&#x201D; Bearing witness to actual love and solidarity is what will change the hearts of young people, not <a href="https://www.rollingstone.com/politics/politics-features/democrats-young-voters-speaking-with-american-men-million-1235349919/?ref=wheresyoured.at"><u>endless McKinsey gargoyles with multi-million-dollar budgets for &#x201C;data.&#x201D;&#xA0;</u></a></p><p>I should be clear that this isn&#x2019;t to say every single podcast should be in the format I suggest, but that if you want whatever &#x201C;The Joe Rogan Of The Left&#x201D; is, the answer is &#x201C;a podcast with a big audience where the people like the person speaking and as a result are compelled by their message.&#x201D;&#xA0;</p><p>It isn&#x2019;t even about politics, it&#x2019;s that when you cram a bunch of fucking money into something it tends to get big, and if that thing you create is a big boring piece of shit that&#x2019;s clearly built to be &#x2014; and even signposted in the news as built to be &#x2014; manipulative, it is in and of itself sickening.</p><p>I&#x2019;m gonna continue clearing my throat: the trick here is not to lean right, nor has it ever been. Find a group of people who are compelling, diverse and genuinely enjoy being around each other and shove a whole bunch of advertising dollars into it and give it good production values to make it big, and then watch in awe as suddenly lots of people see it and your message spreads. Put a fucking trans person in there &#x2014; <a href="https://podcasts.apple.com/us/podcast/western-kabuki/id1647062210?ref=wheresyoured.at"><u>give Western Kabuki real money</u></a>, for example &#x2014; and watch as people suddenly get used to seeing a trans person because you intentionally chose to do so, but didn&#x2019;t make it weird or get upset when they don&#x2019;t immediately vote your way.&#xA0;</p><p>Because guess what &#x2014; what people are hurting for right now is actual, real sincerity. Everybody feels like something is wrong. The products they use every day are increasingly-broken, pumped full of generative AI features that literally get in the way of what they&#x2019;re trying to do, which already was made more difficult because companies like <a href="https://www.wheresyoured.at/killingfacebook/"><u>Meta</u></a> and <a href="https://www.wheresyoured.at/the-men-who-killed-google/"><u>Google</u></a> intentionally make their products harder to use as a means of making more money.&#xA0; And, let&#x2019;s be clear, people are well aware of the billions in profits that these companies make at the customer&#x2019;s expense.&#xA0;</p><p>They feel talked down to, tricked, conned, abused and abandoned, both parties&#x2019; representatives operating in terms almost as selfish as the markets that they also profit from. They read articles that blandly report illegal or fantastical things as permissible and rational and think, for a second, &#x201C;am I wrong? Is this really the case? This doesn&#x2019;t feel the case?&#x201D; while somebody tells them that despite the fact that they have less money and said money doesn&#x2019;t go as far, they&#x2019;re actually experiencing the highest standard of living in history.&#xA0;</p><p>Ultimately, regular people are repeatedly made to feel like they don&#x2019;t matter. Their products are overstuffed with confusing menus, random microtransactions, the websites they read full of advertisements disguised as stories and actual advertisements built to trick them, their social networks intentionally separating them from the things they want to see.&#xA0;</p><p>And when you feel like you don&#x2019;t matter, you look to other human beings, and other human beings are terrified of sincerity. They&#x2019;re terrified of saying they&#x2019;re scared, they&#x2019;re angry, they&#x2019;re sad, they&#x2019;re lonely, they&#x2019;re hurting, they&#x2019;re constantly on a fucking tightrope, every day feels like something weird or bad is going to happen either on the news (which for no reason other than it helps rich people constantly tries to scare them that AI will take their jobs), and they just want someone to talk to, but everybody else is fucking unwilling to let their guard down after a decade-plus of media that valorized snark and sarcasm, because the lesson they learned about being emotionally honest was that it&#x2019;s weird or they&#x2019;re too much or it&#x2019;s feminine for guys or it&#x2019;s too feminine for women.</p><p>Of course people feel like shit, so of course they&#x2019;re going to turn to media that feels like real people made it, and they&#x2019;ll turn to the media they&#x2019;ll see the easiest, such as that given to them by the algorithm, or that which they are made to see by advertisement, or, of course, word of mouth. And if you&#x2019;re sending someone to listen to something, and someone describes it in terms that sound like they&#x2019;re hanging out with a friend, you&#x2019;d probably give it a shot.</p><p>Outside of podcasting, people&#x2019;s options for mainstream (and an alarming amount of industry) news are somewhere between &#x201C;I&#x2019;m smarter than you,&#x201D; &#x201C;something happened!&#x201D; &#x201C;sneering contempt,&#x201D; &#x201C;a trip to the principal&#x2019;s office,&#x201D; or &#x201C;here&#x2019;s who you should be mad at,&#x201D; which I realize also describes the majority of the New York Times opinion page.&#xA0;</p><p>While &#x201C;normies&#x201D; of whatever political alignment might want exactly the slop they get on TV, that slop is only slop because the people behind it believe that regular people will only accept the exact median person&#x2019;s version of the world, even if they can&#x2019;t really articulate it beyond &#x201C;whatever is the least-threatening opinion&#x201D; (or the opposite in Fox News&#x2019; case).</p><p>Really, I don&#x2019;t have a panacea for what ails media, but what I do know is that in my own life I have found great joy in sincerity and love. In the last year I have made &#x2014; and will continue to make, as it&#x2019;s my honour to &#x2014; tremendous effort to get to know the people closest to me, to be there for them if I can, to try and understand them better and to be my authentic and honest self around them, and accept and encourage them doing the same. Doing so has improved my life significantly, made me a better, more confident and more loving person, and I can only hope I provide the same level of love and acceptance to them as they do to me.</p><p>Even writing that paragraph I felt the urge to pare it back, for fear that someone would accuse me of being insincere, for &#x201C;speaking in therapy language,&#x201D; for &#x201C;trying to sound like a hero,&#x201D; not that I am doing so, but because there are far more people concerned with moderating how emotional and sincere there are than those willing to stop actual societal harms.</p><p>I think it&#x2019;s partly because people see emotions as weakness. I don&#x2019;t agree. I have never felt stronger and more emboldened than I have as I feel more love and solidarity with my friends, a group that I try to expand at any time I can. I am bolder, stronger (both physically and mentally), and far happier, as these friendships have given me the confidence to be who I am, and I offer the same aggressive advocacy to my friends in being who they are as they do to me.&#xA0;</p><p>None of what I am saying is a one-size-fits-all solution. There is so much room for smaller, more niche projects, and I both encourage and delight in them. There is also so much more attention that can be given to these niche projects, and things are only &#x201C;niche&#x201D; until they are given the time in the light to become otherwise. There is also so much more that can be done within the mainstream power structures, if only there is the boldness to do so.</p><p>Objective reporting is necessary &#x2014; crucial, in fact! &#x2014; to democracy, but said objectivity cannot come at the cost of context, and every time it does so, the reader is failed and the truth is suffocated. And I don&#x2019;t believe objective reporting should be separated from actual commentary. In fact, if someone is a reporter on a particular beat, their opinion is likely significantly more-informed than that of someone &#x201C;objective&#x201D; and &#x201C;outside of the coverage,&#x201D; based on stuff like &#x201C;domain expertise.&#x201D;&#xA0;</p><p>The true solution, perhaps, is more solidarity and more sincerity. It&#x2019;s media outlets that back up their workers, with editorial missions that aggressively fight those who would con their readers or abuse their writers, focusing on the incentives and power of those they&#x2019;re discussing rather than whether or not &#x201C;the markets&#x201D; agree with their sentiment. </p><p>In any case, the last 15+ years of the media has led to a flattening of journalism, constantly swerving toward whatever the next big trend is &#x2014; the pivot to video, contorting content to &#x201C;go viral&#x201D; on social media, SEO, or whatever big coverage area (AI, for example) everybody is chasing instead of focusing on making good shit people love. Years later, <a href="https://www.nytimes.com/2023/10/19/technology/news-social-media-traffic.html?ref=wheresyoured.at"><u>social networks have effectively given up on sending traffic to news</u></a>, and <a href="https://www.wsj.com/tech/ai/google-ai-news-publishers-7e687141?gaa_at=eafs&amp;gaa_n=ASWzDAiEP82ho_yb7natm-xxbKMsjzxqWhEUX75FSkJtSxgUvUd0pn9C7nK9iXQTsFs%3D&amp;gaa_ts=68489da1&amp;gaa_sig=D6sxozvJRrq3FicMZLQ-4Ar4qEa5vvmNKCtATe2twlozHM9HRz6tEjWLXX6MLjOKxwLvKSJk0D5vemHsBs-8Eg%3D%3D&amp;ref=wheresyoured.at"><u>now Google&#x2019;s AI summaries are ripping away large chunks of the traffic of major media outlets</u></a> that decided the smartest way to do their jobs was &#x201C;make content for machines to promote,&#x201D; never thinking for a second that those who owned the machines were never to be trusted.</p><p>Worse still, outlets have drained the voices from their reporters, punishing them for having opinions, ripping out anything that might resemble a personality from their writing to meet some sort of vague &#x201C;editorial voice&#x201D; despite readers and viewers again and again showing that they <strong><em>want to read the news from a human being not an outlet.</em></strong></p><p>I maintain that things can change for the better, and it starts with a fundamental acceptance that those running the vast majority of media outlets aren&#x2019;t doing so for their readers&#x2019; benefit. Once that happens, we can rebuild around distinct voices, meaningful coverage and a sense of sincerity that the mainstream media seems to consider the enemy.&#xA0;</p>]]>
			</content:encoded>
		</item>
		<item>
			<title>
				<![CDATA[What're We Even Doing?]]>
			</title>
			<link>https://www.wheresyoured.at/whatre-we-even-doing/</link>
			<guid isPermaLink="false">684c73ca0c260a000100264f</guid>
			<dc:creator>
				<![CDATA[Edward Zitron]]>
			</dc:creator>
			<pubDate>Fri, 13 Jun 2025 19:59:58 GMT</pubDate>
			<content:encoded/>
		</item>
		<item>
			<title>
				<![CDATA[Never Forget What They've Done]]>
			</title>
			<description>
				<![CDATA[<p>Soundtrack: <a href="https://www.youtube.com/watch?v=EwsSpfDaLVo&amp;ref=wheresyoured.at"><u>Queens of the Stone Age - Villains of Circumstance</u></a>&#xA0;</p><p>Listen to my podcast <a href="http://linktr.ee/betteroffline?ref=wheresyoured.at" rel="noreferrer">Better Offline</a> if you haven&apos;t already.</p><hr><p>I want my fucking tech industry back.&#xA0;</p><p>Maybe you think I sound insane, but technology means a lot to me. It&#x2019;s the way that</p>]]>
			</description>
			<link>https://www.wheresyoured.at/never-forget-what-theyve-done/</link>
			<guid isPermaLink="false">68471d9ec2272d00016b2fac</guid>
			<dc:creator>
				<![CDATA[Edward Zitron]]>
			</dc:creator>
			<pubDate>Mon, 09 Jun 2025 18:07:01 GMT</pubDate>
			<content:encoded>
				<![CDATA[<p>Soundtrack: <a href="https://www.youtube.com/watch?v=EwsSpfDaLVo&amp;ref=wheresyoured.at"><u>Queens of the Stone Age - Villains of Circumstance</u></a>&#xA0;</p><p>Listen to my podcast <a href="http://linktr.ee/betteroffline?ref=wheresyoured.at" rel="noreferrer">Better Offline</a> if you haven&apos;t already.</p><hr><p>I want my fucking tech industry back.&#xA0;</p><p>Maybe you think I sound insane, but technology means a lot to me. It&#x2019;s the way that I speak to most of my friends. It&#x2019;s my lifeline when I&#x2019;m hurting or when those close to me hurt, and it&#x2019;s the way I am able to make a living and be a creative &#x2014; something I only was able to become because of technology. Social networks have been a huge part of me being able to become a functional human being, and you can judge me for that all you want, but you are a coward and a hypocrite for doing so, and you&#x2019;re going to read to the end of this blog anyway.</p><p>Really, seriously, honestly &#x2014; the Ed Zitron you know was and is only possible because of my deep connection to technology. This was how I made friends. This was how I got the confidence to meet real people. This was how I started my company. This was how I met the people closest to me, people I love with all my heart. I was only able to do any of this because I was able to get on the computer.&#xA0;</p><p>I am bombastic and frankly a little much today, and was the literal opposite less than 5 years ago, and I was even more reserved 10 years before that. Technology allowed me to find a way to be human on my terms, in ways that I don&#x2019;t think are possible anymore because most of the interconnecting fabric that I used has been interfered with by bad actors and the rest with slop and SEO.</p><p>I think there are far more people out there like me than will admit to it. I think more people miss the past, or at least realize now what they lost.</p><p>There was a time this didn&#x2019;t suck, when it wasn&#x2019;t a struggle to do basic things, when my world was not a constant war with my god damn apps, when things weren&#x2019;t necessarily turn-key but my phone wasn&#x2019;t randomly burning through half of its battery life in an hour and a half because one app on the App Store is poorly configured. I swear to god, back in like, 2019, Zoom just fucking connected. I remember things being better, and on top of that, I see how much better things could be.</p><p>But that&#x2019;s not the tech industry we&#x2019;re allowed to have, because the people that run the tech industry do not give a shit.</p><p>It&#x2019;s not enough to have your data, <a href="https://www.techzine.eu/news/privacy-compliance/126600/microsoft-denies-its-collecting-user-data-in-word-and-excel/?ref=wheresyoured.at"><u>your work</u></a>, <a href="https://www.bloodinthemachine.com/p/openai-and-googles-dark-new-campaign?ref=wheresyoured.at"><u>your art</u></a>, <a href="https://qz.com/reddit-anthropic-claude-ai-lawsuit-data-siphoning-1851783685?ref=wheresyoured.at"><u>your posts</u></a>, <a href="https://www.wsj.com/tech/ai/mark-zuckerberg-ai-digital-future-0bb04de7?gaa_at=eafs&amp;gaa_n=ASWzDAiCfNLP8ORza9vvohNV3KkSmP5lzX-LXBUOD85__llF09m2vOp85kqJUp6f7JI%3D&amp;gaa_ts=6841d0c8&amp;gaa_sig=is8NTEtQZtJRwAvFbtsbaCsEUwy30W62Igz1RzR3iVX1n-69lq0Qst9ELe0hOgK2EmHnqtlx3gtam2ZXt2Up4g%3D%3D&amp;ref=wheresyoured.at"><u>your friends</u></a>, <a href="https://www.fastcompany.com/91132854/instagram-training-ai-on-your-data-its-nearly-impossible-to-opt-out?ref=wheresyoured.at"><u>the things you&#x2019;ve taken photos</u></a> of, and <a href="https://www.theinformation.com/briefings/google-used-search-data-train-ai-models?rc=kz8jh3&amp;ref=wheresyoured.at"><u>the things you&#x2019;ve searched for</u></a>. <a href="https://www.nytimes.com/2025/05/02/technology/google-gemini-ai-chatbot-kids.html?ref=wheresyoured.at"><u>The industry must have that of your children</u></a>, and <em>their children</em>, as early as possible, <a href="http://www.tomsguide.com/ai/google-gemini-could-soon-help-your-kids-with-their-homework-heres-what-we-know?ref=wheresyoured.at"><u>even if it means helping them cheat on their homework</u></a> so that they too can live a life where they&#x2019;ve skipped having any responsibility or learning anything about the world other than how one can extract as much as possible without having to give anything in return.&#xA0;</p><p>Big tech is sociopathic and directionless, swinging wildly to try and find new ways to drag any kind of interaction out of a customer they&#x2019;ve grown to loathe for their unwillingness to be more profitable. Decades of powerful Big Tech <a href="https://www.wheresyoured.at/the-era-of-the-business-idiot/"><u>Business Idiots</u></a> have chased out true value-creation in Silicon Valley in favour of growth economics, sending edict after edict down to the markets and the media about what&#x2019;s going to be &#x201C;hot&#x201D; next, inventing business trends rather than actual solutions to problems. After all, that might involve &#x2014; eugh! &#x2014; experiencing the real world rather than authoring a new version of it every few years.</p><p>Apple barely escapes the void because its principle value proposition has, on some level, always been &#x201C;our stuff works.&#x201D; The problem is that Apple needs to grow, and thus its devices are slowly but surely becoming mired in sludge. The <a href="https://www.wheresyoured.at/never-forgive-them/#:~:text=Tim%20Cook%20is,much%20easier%20time."><u>App Store is an abomination, your iPhone settings look like a fucking Escher painting, and in its desperation to follow the pack it shoved Apple Intelligence out the door</u></a> &#x2014; <a href="https://www.bloomberg.com/news/features/2025-05-18/how-apple-intelligence-and-siri-ai-went-so-wrong?ref=wheresyoured.at"><u>one of the most invasive and annoying pieces of software to ever grace a computer</u></a>.&#xA0;</p><p>Apple&#x2019;s willingness to do this shows that it&#x2019;s rotten just like the rest of them &#x2014; it&apos;s just better at hiding it. After all, look at the way in which it <a href="https://www.reuters.com/sustainability/boards-policy-regulation/us-judge-rules-apple-violated-order-reform-app-store-2025-04-30/?ref=wheresyoured.at"><u>flaunted court orders</u></a> telling it to open up third-party payments as a means of squeezing every penny out of the App Store. Loathsome. <a href="https://www.cnbc.com/2025/06/04/apple-appeal-epic-games-app-store.html?ref=wheresyoured.at"><u>And it still ended up losing</u></a>.</p><p>I adore tech. Tech made me who I am today. I use and love technology for hours a day, yet that experience is constantly mangled by the warring intentions of almost every product I use. I&#x2019;m forced to log into the newspaper website and back into Google Calendar multiple times a week, my phone randomly resets &#x2014; as every single iPhone has for multiple years &#x2014; at least twice a week, my Apple Watch stops being willing to read my heart rate, websites I want to read sometimes simply do not load, and sometimes when I load websites on an iPad they just won&#x2019;t scroll.&#xA0;</p><p>Everything feels like a fucking chore, but I love the actual things that technology does for me, like letting me take notes with ease, like building and maintaining my fitness through a series of connected products like <a href="http://www.tonal.com/?ref=wheresyoured.at"><u>Tonal</u></a> and <a href="https://joinfightcamp.com/?ref=wheresyoured.at"><u>Fight Camp</u></a>, like using Signal to talk to friends hundreds or thousands of miles away, like posting dumb stuff on Bluesky and interacting with my followers, like recording a podcast wherever I am in the world because USB-C mics are cheap and easy to use and sound great.&#xA0;</p><p>There are so many great things about technology, things I fucking love, and Large Language Models do not resemble their form or intention. There is nothing about an LLM that feels like it&#x2019;s built to provide a real service, other than some sort-of fraudulent copy of something else lacking its soul or utility. Those that actually use them in their daily work talk about them as exciting tools that help them improve workflows - <em>not </em>like they&apos;re the next big thing.</p><p>The original iPhone, even in its initial form, promised a world where two or three devices became one, where your music and a camera were always on you, and where you could do your banking and grocery shopping while sitting in the back of a taxi. It promised access to the world&#x2019;s knowledge from a slab of glass in your pocket.&#xA0; If i&#x2019;m honest, the smartphone has absolutely delivered on those promises &#x2014; and more.&#xA0;</p><p>Where do we extrapolate from LLMs? What am I meant to be seeing in ChatGPT?&#xA0;</p><p>The &#x201C;iPhone moment&#x201D; wasn&#x2019;t a result of one thing, but a collection of different bits that formed an obvious whole &#x2014; one device that did a bunch of things really, really well.</p><p>LLMs have no such moment, nor do they have any one thing they do well, let alone really well. LLMs are famous not for their efficacy, but their inconsistency, with even ardent AI cultists warning people not to trust their output. What am I meant to see from here? They&#x2019;re not autonomous, and have shown no proof that they can be, and in fact kind of feel antithetical to autonomy itself, which requires consistency, reliability and replicability, more things that LLMs cannot do.</p><p>And that, ultimately, was what made the smartphone amazing too. Within a few years, phones were competent web browsers. The mobile web took a minute to catch up, sure, but you could see it taking form immediately, as you could with the App Store. They immediately made sense as a way to listen to music, because they were effectively an iPod, a beloved MP3 player, and the iPhone&#x2019;s camera was good enough for most people at the time, and quickly became better than most of the point-and-shoots that people used to take on vacations and to parties. Now, most people are pretty happy with their phone cameras regardless of who makes them.&#xA0;</p><p>All of this made total sense from the very beginning the moment you picked one up. <em>What if the camera was better</em>? It happened. <em>What if the screen was bigger</em>? It happened. There were immediate signs the iPhone&#xA0; would improve.&#xA0; It wasn&#x2019;t fantastical to believe that in 10-to-20 years you&#x2019;d have a bigger, faster and thinner iPhone with a camera that produced shots alarmingly close to what you&#x2019;d capture with a DSLR.&#xA0;</p><p>It makes sense that Google freaked out the second it picked one up. It was fucking wild what it could do, even in its first form. Each iteration and improvement &#x2014; as with other smartphones &#x2014; offers a new twist on a formula you already know works, and sometimes &#x201C;better&#x201D; means something different. For example, I don&#x2019;t use Android, but I think the foldable Motorola phones are cool as shit.<a href="https://www.techradar.com/news/how-palm-pre-and-webos-inspired-the-modern-smartphone?ref=wheresyoured.at"><u> Palm&#x2019;s WebOS was a stroke of UI genius</u></a>, and it&#x2019;s criminal to see <a href="https://daringfireball.net/2011/08/hp_apotheker?ref=wheresyoured.at"><u>how HP mishandled the company after its acquisition</u></a>, ultimately killing one of the earliest and most iconic mobile brands.</p><blockquote><strong>Sidenote</strong>: In anticipation of a &#x201C;<em>well, akchually</em>&#x201D; from the peanut gallery, different can also mean bad. 3D phones were portable migraine-causers. The BlackBerry Storm&#x2019;s weird SurePress technology &#x2014; where the touchscreen screen kind-of &#x2018;clicked&#x2019; through haptic feedback whenever you pressed something &#x2014; was an abomination that put RIM on a terminal trajectory. And Samsung&#x2019;s decision to include a built-in firelighter in the Samsung Galaxy Note 7 will remain one of the most expensive errors in mobile hardware history. It really blew up, but not in the way they wanted it to.&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;</blockquote><p>What does the &#x201C;better&#x201D; version of ChatGPT look like, exactly? What&#x2019;s <em>cool about ChatGPT?</em> Where&#x2019;s that &#x201C;oooh&#x201D; moment? Are you going to tell me you&#x2019;re that impressed by the pictures and the words? Is it in the resemblance of its outputs to human beings? Because the actual answer is &#x201C;a ChatGPT that actually works.&#x201D; One that you can just ask to do some shit and know it&#x2019;ll do it, and it&#x2019;d also be very obvious what it could actually do, which is not the case right now. A better ChatGPT would quite literally be a different product.&#xA0;</p><p>What&#x2019;s particularly horrifying about the AI bubble is that it&#x2019;s shown that when they decide to, <a href="https://www.wsj.com/tech/ai/tech-giants-double-down-on-their-massive-ai-spending-b3040b33?gaa_at=eafs&amp;gaa_n=ASWzDAi25kNjRUngfWhT--ySdjLC6E5vawxKLV6xnrhg6Tywzwktjr7ED0eUxvNfMUU%3D&amp;gaa_ts=6841d35e&amp;gaa_sig=cyh8qfE9-SxIUrLEzRJhIJQ-fxON3LaMb71Gr9baWmsmR02vYwzioXACP0QIGWioUe023cbc7HCfKTWouJs91g%3D%3D&amp;ref=wheresyoured.at"><u>big tech can put hundreds of billions behind whatever the fuck they want</u></a>. They are able to mobilize incredible amounts of capital and the industrial might of multiple companies with multi-trillion dollar market capitalisations to build entire infrastructure dedicated to <em>one thing</em>, and the <em>one thing they are choosing</em> is generative AI.</p><p>They&#x2019;re all fully capable of uniting around an ideal &#x2014; it&#x2019;s just that said ideal exists entirely to automate human beings out of the picture, and even more offensively, it doesn&#x2019;t seem to be able to do so, and the more obvious that becomes, the more obvious the powerful&#x2019;s hunger becomes for a world where they never see or talk to us, and they get all of our money and attention.&#xA0;</p><p>And it&#x2019;s not just their greed &#x2014; it&#x2019;s how obviously they love the idea of automating human beings away, and creating a world where we&#x2019;re increasingly disconnected and beholden to technology that they entirely control. No creators, no connections, and best of all, no customers &#x2014; just people cranking <a href="https://www.technologyreview.com/2025/05/20/1116327/ai-energy-usage-climate-footprint-big-tech/?ref=wheresyoured.at"><u>a giant, energy-guzzling slot machine</u></a> and maybe getting the thing they wanted at the end.</p><p>Except it doesn&#x2019;t work. <em>It obviously doesn&#x2019;t work</em>. It hasn&#x2019;t ever worked, and there&#x2019;s never really been a sign of it working other than people very confidently saying &#x201C;this will eventually work.&#x201D;&#xA0;</p><p>They now need this to be several echelons <strong>BIGGER</strong> than the iPhone to be worth it. Hundreds of billions of capital expenditures and endless media attention are begging for an actual payoff &#x2014; something truly amazing and societally relevant other than the amount of investment and attention it&#x2019;s getting. They need this to be the single biggest consumer tech phenomenon <em>ever</em> while <em>also</em> being the panacea to the dwindling growth of the Software as a Service and enterprise IT markets, and it needs to start doing that within the next 12 months, without fail, if it even has that long.</p><p>You can fight with me on semantics, on claiming valuations are high and how many users ChatGPT has, but look at the products and tell me any of this is really the future.&#xA0;</p><p>Imagine if they&#x2019;d done something else.</p><p>Imagine if they&#x2019;d done <em>anything</em> else.</p><p>Imagine if they&#x2019;d have decided to unite around something other than the idea that they needed to continue growing.</p><p>Imagine, because right now that&#x2019;s the closest you&#x2019;re going to fucking get.</p><hr><p>Mid-break Soundtrack: <a href="https://www.youtube.com/watch?v=yW6bF7xVbl0&amp;ref=wheresyoured.at"><u>Spinerette - A Prescription For Mankind</u></a></p><p>We all feel like we&#x2019;re at war right now. Every person I know, on some level, feels like they&#x2019;re in their own battle, their own march toward something, or against something, or away from something. It&#x2019;s constant, a drumbeat, a war song, a funeral dirge, and so rarely an anthem.&#xA0;</p><p>All of us feel like we&#x2019;re individually suffering. We echo with conflict and we reverberate with our own doubts, even the most confident and successful of us. Even our devices are wars within themselves &#x2014; wars within software that is built to interfere with its own purpose, our ability to connect with others, or find the things we. This suffering is often an unfortunate byproduct of an advertising channel that makes Sundar Pichai or Mark Zuckerberg a hundred million dollars or more.&#xA0;</p><p>We struggle to do the things we need to do, as we do with the things we want to do, because there are so many warring incentives that it <em>literally</em> slows our mobile browsers down because they all want to shove a fucking cookie into our phones, or a page has to phone home to a hundred different tracking services. And we fail to see the big picture, how this is literally robbing us of the one thing we know to be finite &#x2014; time.&#xA0;</p><p>We tell ourselves these problems are minor, because if we accept how frustrating they are, we must accept how frustrating <em>all</em> of them are, and how many of them there are, and that we&#x2019;re surrounded by digital ants biting us with little or no rhyme or reason other than their thirst for their queen&#x2019;s growth.&#xA0;</p><p>While we may feel increasingly divided, these problems unite us. Everybody faces them mostly in equal measure, though the poorer you are, the more likely you&#x2019;re burdened by a cheap, shitty laptop like <a href="https://www.wheresyoured.at/never-forgive-them/"><u>the ACER Aspire 1 that I used last year that took over an hour to set up and took forever to do anything in its advertisement-filled litterbox of an operating system</u></a>. The more likely you&#x2019;re unable to afford the subscriptions that afford you a bit of dignity in the digital world, like YouTube Premium, which saves you from having to see five minutes of advertising for every 10-minutes of video you watch.</p><p>We all use social networks that actively experiment on us to see how much advertising we&#x2019;ll take, what content we might engage with &#x2014; not like, enjoy &#x2014; and we all have the same fucking awful version of Google Search. Even expensive iPhones are plagued with the cursed Apple Intelligence software, and even if you turn it off, you still deal with Apple&#x2019;s actively evil App Store and a mobile internet full of websites that are effectively impossible to browse on a mobile.</p><p>We ache not so much for the old world of the computer, but the world we know is possible if these fucking bastards wouldn&#x2019;t keep ruining it. It&#x2019;s magical that we can have a video chat with someone halfway across the world, or play a fast-paced videogame with them, watch the same movies that we both stream, casually looking something up on a search engine, or looking at a friend&#x2019;s photos they posted on a social network. Even if it&#x2019;s for work, it&#x2019;s kind of amazing that we can take big files and send them across the internet. The cameras in our phones are truly incredible. Connected fitness has changed my entire life. Handheld gaming PCs are cool as shit.&#xA0;</p><p>We live in the future, and the future is cool.</p><p>Or it would be cool, if it wasn&#x2019;t for all <em>these fucking bastards.</em></p><p>Even for those of us too young to remember a less-algorithmic internet, we can all see the potential. We see what technology can do. We see what the remarkable advances in smaller chips and batteries and processors have allowed us to do. We know what&#x2019;s possible, but we see &#x2014; whether we acknowledge it or just feel its sheer force shearing off bits of our fucking soul &#x2014; what these companies are choosing to do to us.&#xA0;</p><p>There is nothing making Mark Zuckerberg force algorithmic Instagram and Facebook feeds upon people by default other than sheer, unadulterated greed and the growth-at-all-costs rot economics that have made him a multi-billionaire. We know what we want from his network, he knows what value we get out of it, but unlike Mark Zuckerberg, we have no voice in the conversation other than choosing to accept whatever punishment he offers. We know exactly what it is we want to do, and for some reason we rarely talk about the man responsible for getting in our way.&#xA0;</p><p>I don&#x2019;t know, maybe you think I&#x2019;m being dramatic, but I feel like shit about this, because I know it doesn&#x2019;t have to be this way. I have spent the last year of my life cataloguing why companies like Google (<a href="https://www.wheresyoured.at/the-men-who-killed-google/"><u>Prabhakar Raghavan</u></a>) and Facebook (<a href="https://www.wheresyoured.at/killingfacebook/"><u>Zuckerberg, Gleit, Mosseri, Backstrom, Sandberg, Bosworth</u></a>) make their products worse, and I don&#x2019;t know why more people don&#x2019;t talk about the scale of these harms, and the unbelievable, despicable intentionality behind their decision making. Sundar Pichai and Mark Zuckerberg have personally overseen the destruction of society&#x2019;s access to readily-available information. You can dance around it all you want, you can claim these things aren&#x2019;t a big deal, but you&#x2019;re fucking wrong.</p><p>Google and Facebook were, on some level, truly societal marvels, and they have been poisoned and twisted into a form of advertising parasite that you choose to let feed on you so that you can speak to your friends or find something out.&#xA0;</p><p>Let me put it in simpler terms: isn&#x2019;t it fucking weird how hard it is to do anything? Don&#x2019;t you remember when it was easier? It&#x2019;s harder now because of Mark Zuckerberg and Sundar Pichai, and the information you look for is worse because of Sam Altman and Satya Nadella, whose deranged attachment to Large Language Models have pumped our internet full of bullshit at a time when Google had actively abandoned any duty to the web or its users.</p><p>This isn&#x2019;t a situation with grey areas, especially when it comes to Mark Zuckerberg, a man who cannot be fired. He <em>chose</em> to make things bad, and he <em>chooses</em> to keep them this bad every day. Sundar Pichai is responsible for the destruction of Google Search along with the now-deposed Prabhakar Raghavan.&#xA0;</p><p>Sam Altman is a con artist that worked studiously for over a decade to accumulate power and connections until he found a technology and a time when the tech industry was out of ideas, and from everything I&#x2019;ve read, it feels like he fell ass-backwards into ChatGPT and was surprised by how much everybody else liked it.&#xA0;</p><p>In any case, he is a great salesman to a legion of <a href="https://www.wheresyoured.at/the-era-of-the-business-idiot/"><u>Business Idiots</u></a> that had run out of growth ideas &#x2014; <a href="https://www.wheresyoured.at/rotcombubble/"><u>the Rot-Com Bubble I discussed a year ago</u></a> &#x2014; and would take something, anything, even if it was horrifyingly expensive, even if it wasn&#x2019;t clear if it would work, because Sam Altman could spin a fucking yarn, and he&#x2019;d spent a long time investing in media relationships to make sure that he&#x2019;d have their buy in.</p><p>And honestly, the tech media was ready for a fun new story. I heard people saying in 2022 that it was &#x201C;nice to get excited about something again,&#x201D; and in many ways Altman gave hope to an industry that felt fucking bleak after getting hoodwinked twice by crypto and the metaverse, by which I mean a far more convincing story with an actual product to look at, sold by a guy the media already liked who had convinced everybody he was very smart.</p><p>Then Satya Nadella, a management consultant<a href="https://www.wheresyoured.at/the-cult-of-microsoft/"><u> cultist of the growth mindset</u></a>, lost, realizing there were no more growth markets, decided that he <em>must</em> have ChatGPT in Bing, and then Sundar Pichai chose to follow too. At any point these men could&#x2019;ve looked ahead and seen exactly what would happen, but they chose not to, because there was nowhere else to shove their money, and both the markets and the media yearned for good news.</p><p>Notice how none of this &#x2014; from the media to the executive sect &#x2014; is about you or me. None of this is about products, or the future, or even the present, just whatever &#x201C;the next big thing&#x201D; might be that will keep <a href="https://www.wheresyoured.at/the-rot-economy/"><u>the Rot Economy&#x2019;s growth-at-all-costs party</u></a> going.&#xA0;</p><p>Nowhere along the line did anyone actually see an opportunity to sell people something they wanted or needed. Large Language Models were able to generate a lot of text or generate pictures, and that barely approximated a thing that society wanted or needed other than it was something that people used to be willing to pay more for &#x2014; and businesses had been interested in doing these things cheaper, usually by offshoring or underpaying contractors, and this allowed them to potentially reduce costs further.&#xA0;</p><p>The fact that three years later we still have trouble describing why these things exist is enough of a sign that the tech industry has no real interest in building artificial intelligence at all &#x2014; because AI is, at least based on the time before ChatGPT, meant to be about doing stuff for us, which Large Language Models are pretty fucking poor at, because the idea of getting something &#x201C;done for you&#x201D; is that you&#x2019;re outsourcing both the production and the quality control.&#xA0;</p><p>In any case, it&#x2019;s enough to make anyone feel crazy. Over the last decade we&#x2019;ve watched &#x2014; and while I&#x2019;m talking about the tech industry, I think we can all say it&#x2019;s been everywhere else too &#x2014; the things we love get distanced from us so that somebody else can get unbelievably rich, the things we used to do easily made more difficult, confusing and/or expensive, and the ways we used to connect with people become increasingly abstracted and exploitative.&#xA0;</p><p>I don&#x2019;t know what to tell you about these people other than the fact that you should know that they are responsible for the world around you feeling like it&#x2019;s in fucking ruins. I cannot give you a plan for the future, I cannot tell you what will fix things, but however things get fixed starts with people knowing who these people are and what they have done.&#xA0;</p><p>I can give you their names. Mark Zuckerberg. Sam Altman. Sundar Pichai. Satya Nadella. Tim Cook. Sheryl Sandberg. Adam Mosseri. Prabhakar Raghavan. There are others, many others, and they are fully responsible for how broken everything feels.</p><p>And some of the guilty aren&#x2019;t tech CEOs, or fabulously wealthy, but rather their collaborators in the tech media that have carried water for the sociopaths ruining our digital &#x2014; and, often, physical &#x2014; world.&#xA0;</p><p>The reason I am so hard on my peers in the media is that it has never been more urgent that we hold these people accountable. Their ability to act both unburdened by regulation and true criticism has emboldened them to cause harm to billions of people so that they may continue to make billions of dollars, in part because the media continually congratulates them for doing so.&#xA0;</p><p>And let&#x2019;s be honest, what they&#x2019;re doing is horribly, awfully wrong.&#xA0;</p><p>Fighting back starts with the truth, said regularly, said boldly and clearly with emotion and sincerity. I don&#x2019;t have other answers. I don&#x2019;t have bold plans. I don&#x2019;t know what to do, other than to explain how I feel, and if you feel the same, at the very least make you feel less afraid.&#xA0;</p><p>If you ever need to talk, email me at ez@betteroffline.com. I don&#x2019;t care. I have cracked myself open and spilled myself onto my podcast and newsletter for no reason other than the fact that I feel more alive doing so, and have become a stronger and happier person doing so.&#xA0;</p><p>All this is possible thanks to technology, and while I have no plan, I know I feel more free and alive when I write and speak about this stuff. I write this knowing that speaking in this way feels &#x201C;too much&#x201D; or some other way of attacking me for experiencing emotion, and if you&#x2019;re feeling that way reading this, look deep within yourself and see if you&#x2019;re simply uncomfortable with somebody capable of feeling things.</p><p>We die alone, but we choose whether we live that way. Remember that billions of us are suffering in the same way, and remember who to fucking thank for doing it to us.</p>]]>
			</content:encoded>
		</item>
	</channel>
</rss>